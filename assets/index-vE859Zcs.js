(function(){const c=document.createElement("link").relList;if(c&&c.supports&&c.supports("modulepreload"))return;for(const d of document.querySelectorAll('link[rel="modulepreload"]'))p(d);new MutationObserver(d=>{for(const m of d)if(m.type==="childList")for(const v of m.addedNodes)v.tagName==="LINK"&&v.rel==="modulepreload"&&p(v)}).observe(document,{childList:!0,subtree:!0});function l(d){const m={};return d.integrity&&(m.integrity=d.integrity),d.referrerPolicy&&(m.referrerPolicy=d.referrerPolicy),d.crossOrigin==="use-credentials"?m.credentials="include":d.crossOrigin==="anonymous"?m.credentials="omit":m.credentials="same-origin",m}function p(d){if(d.ep)return;d.ep=!0;const m=l(d);fetch(d.href,m)}})();var Qs={exports:{}},Tr={},Ks={exports:{}},ie={};/**
 * @license React
 * react.production.min.js
 *
 * Copyright (c) Facebook, Inc. and its affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 */var ou;function Dp(){if(ou)return ie;ou=1;var s=Symbol.for("react.element"),c=Symbol.for("react.portal"),l=Symbol.for("react.fragment"),p=Symbol.for("react.strict_mode"),d=Symbol.for("react.profiler"),m=Symbol.for("react.provider"),v=Symbol.for("react.context"),A=Symbol.for("react.forward_ref"),k=Symbol.for("react.suspense"),b=Symbol.for("react.memo"),I=Symbol.for("react.lazy"),T=Symbol.iterator;function R(g){return g===null||typeof g!="object"?null:(g=T&&g[T]||g["@@iterator"],typeof g=="function"?g:null)}var q={isMounted:function(){return!1},enqueueForceUpdate:function(){},enqueueReplaceState:function(){},enqueueSetState:function(){}},J=Object.assign,j={};function L(g,M,re){this.props=g,this.context=M,this.refs=j,this.updater=re||q}L.prototype.isReactComponent={},L.prototype.setState=function(g,M){if(typeof g!="object"&&typeof g!="function"&&g!=null)throw Error("setState(...): takes an object of state variables to update or a function which returns an object of state variables.");this.updater.enqueueSetState(this,g,M,"setState")},L.prototype.forceUpdate=function(g){this.updater.enqueueForceUpdate(this,g,"forceUpdate")};function H(){}H.prototype=L.prototype;function te(g,M,re){this.props=g,this.context=M,this.refs=j,this.updater=re||q}var V=te.prototype=new H;V.constructor=te,J(V,L.prototype),V.isPureReactComponent=!0;var se=Array.isArray,O=Object.prototype.hasOwnProperty,$={current:null},Q={key:!0,ref:!0,__self:!0,__source:!0};function Z(g,M,re){var oe,ue={},de=null,ve=null;if(M!=null)for(oe in M.ref!==void 0&&(ve=M.ref),M.key!==void 0&&(de=""+M.key),M)O.call(M,oe)&&!Q.hasOwnProperty(oe)&&(ue[oe]=M[oe]);var fe=arguments.length-2;if(fe===1)ue.children=re;else if(1<fe){for(var Se=Array(fe),Ze=0;Ze<fe;Ze++)Se[Ze]=arguments[Ze+2];ue.children=Se}if(g&&g.defaultProps)for(oe in fe=g.defaultProps,fe)ue[oe]===void 0&&(ue[oe]=fe[oe]);return{$$typeof:s,type:g,key:de,ref:ve,props:ue,_owner:$.current}}function ne(g,M){return{$$typeof:s,type:g.type,key:M,ref:g.ref,props:g.props,_owner:g._owner}}function ae(g){return typeof g=="object"&&g!==null&&g.$$typeof===s}function Ie(g){var M={"=":"=0",":":"=2"};return"$"+g.replace(/[=:]/g,function(re){return M[re]})}var ye=/\/+/g;function Me(g,M){return typeof g=="object"&&g!==null&&g.key!=null?Ie(""+g.key):M.toString(36)}function le(g,M,re,oe,ue){var de=typeof g;(de==="undefined"||de==="boolean")&&(g=null);var ve=!1;if(g===null)ve=!0;else switch(de){case"string":case"number":ve=!0;break;case"object":switch(g.$$typeof){case s:case c:ve=!0}}if(ve)return ve=g,ue=ue(ve),g=oe===""?"."+Me(ve,0):oe,se(ue)?(re="",g!=null&&(re=g.replace(ye,"$&/")+"/"),le(ue,M,re,"",function(Ze){return Ze})):ue!=null&&(ae(ue)&&(ue=ne(ue,re+(!ue.key||ve&&ve.key===ue.key?"":(""+ue.key).replace(ye,"$&/")+"/")+g)),M.push(ue)),1;if(ve=0,oe=oe===""?".":oe+":",se(g))for(var fe=0;fe<g.length;fe++){de=g[fe];var Se=oe+Me(de,fe);ve+=le(de,M,re,Se,ue)}else if(Se=R(g),typeof Se=="function")for(g=Se.call(g),fe=0;!(de=g.next()).done;)de=de.value,Se=oe+Me(de,fe++),ve+=le(de,M,re,Se,ue);else if(de==="object")throw M=String(g),Error("Objects are not valid as a React child (found: "+(M==="[object Object]"?"object with keys {"+Object.keys(g).join(", ")+"}":M)+"). If you meant to render a collection of children, use an array instead.");return ve}function he(g,M,re){if(g==null)return g;var oe=[],ue=0;return le(g,oe,"","",function(de){return M.call(re,de,ue++)}),oe}function Pe(g){if(g._status===-1){var M=g._result;M=M(),M.then(function(re){(g._status===0||g._status===-1)&&(g._status=1,g._result=re)},function(re){(g._status===0||g._status===-1)&&(g._status=2,g._result=re)}),g._status===-1&&(g._status=0,g._result=M)}if(g._status===1)return g._result.default;throw g._result}var ge={current:null},N={transition:null},K={ReactCurrentDispatcher:ge,ReactCurrentBatchConfig:N,ReactCurrentOwner:$};function B(){throw Error("act(...) is not supported in production builds of React.")}return ie.Children={map:he,forEach:function(g,M,re){he(g,function(){M.apply(this,arguments)},re)},count:function(g){var M=0;return he(g,function(){M++}),M},toArray:function(g){return he(g,function(M){return M})||[]},only:function(g){if(!ae(g))throw Error("React.Children.only expected to receive a single React element child.");return g}},ie.Component=L,ie.Fragment=l,ie.Profiler=d,ie.PureComponent=te,ie.StrictMode=p,ie.Suspense=k,ie.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED=K,ie.act=B,ie.cloneElement=function(g,M,re){if(g==null)throw Error("React.cloneElement(...): The argument must be a React element, but you passed "+g+".");var oe=J({},g.props),ue=g.key,de=g.ref,ve=g._owner;if(M!=null){if(M.ref!==void 0&&(de=M.ref,ve=$.current),M.key!==void 0&&(ue=""+M.key),g.type&&g.type.defaultProps)var fe=g.type.defaultProps;for(Se in M)O.call(M,Se)&&!Q.hasOwnProperty(Se)&&(oe[Se]=M[Se]===void 0&&fe!==void 0?fe[Se]:M[Se])}var Se=arguments.length-2;if(Se===1)oe.children=re;else if(1<Se){fe=Array(Se);for(var Ze=0;Ze<Se;Ze++)fe[Ze]=arguments[Ze+2];oe.children=fe}return{$$typeof:s,type:g.type,key:ue,ref:de,props:oe,_owner:ve}},ie.createContext=function(g){return g={$$typeof:v,_currentValue:g,_currentValue2:g,_threadCount:0,Provider:null,Consumer:null,_defaultValue:null,_globalName:null},g.Provider={$$typeof:m,_context:g},g.Consumer=g},ie.createElement=Z,ie.createFactory=function(g){var M=Z.bind(null,g);return M.type=g,M},ie.createRef=function(){return{current:null}},ie.forwardRef=function(g){return{$$typeof:A,render:g}},ie.isValidElement=ae,ie.lazy=function(g){return{$$typeof:I,_payload:{_status:-1,_result:g},_init:Pe}},ie.memo=function(g,M){return{$$typeof:b,type:g,compare:M===void 0?null:M}},ie.startTransition=function(g){var M=N.transition;N.transition={};try{g()}finally{N.transition=M}},ie.unstable_act=B,ie.useCallback=function(g,M){return ge.current.useCallback(g,M)},ie.useContext=function(g){return ge.current.useContext(g)},ie.useDebugValue=function(){},ie.useDeferredValue=function(g){return ge.current.useDeferredValue(g)},ie.useEffect=function(g,M){return ge.current.useEffect(g,M)},ie.useId=function(){return ge.current.useId()},ie.useImperativeHandle=function(g,M,re){return ge.current.useImperativeHandle(g,M,re)},ie.useInsertionEffect=function(g,M){return ge.current.useInsertionEffect(g,M)},ie.useLayoutEffect=function(g,M){return ge.current.useLayoutEffect(g,M)},ie.useMemo=function(g,M){return ge.current.useMemo(g,M)},ie.useReducer=function(g,M,re){return ge.current.useReducer(g,M,re)},ie.useRef=function(g){return ge.current.useRef(g)},ie.useState=function(g){return ge.current.useState(g)},ie.useSyncExternalStore=function(g,M,re){return ge.current.useSyncExternalStore(g,M,re)},ie.useTransition=function(){return ge.current.useTransition()},ie.version="18.3.1",ie}var su;function ra(){return su||(su=1,Ks.exports=Dp()),Ks.exports}/**
 * @license React
 * react-jsx-runtime.production.min.js
 *
 * Copyright (c) Facebook, Inc. and its affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 */var au;function Rp(){if(au)return Tr;au=1;var s=ra(),c=Symbol.for("react.element"),l=Symbol.for("react.fragment"),p=Object.prototype.hasOwnProperty,d=s.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED.ReactCurrentOwner,m={key:!0,ref:!0,__self:!0,__source:!0};function v(A,k,b){var I,T={},R=null,q=null;b!==void 0&&(R=""+b),k.key!==void 0&&(R=""+k.key),k.ref!==void 0&&(q=k.ref);for(I in k)p.call(k,I)&&!m.hasOwnProperty(I)&&(T[I]=k[I]);if(A&&A.defaultProps)for(I in k=A.defaultProps,k)T[I]===void 0&&(T[I]=k[I]);return{$$typeof:c,type:A,key:R,ref:q,props:T,_owner:d.current}}return Tr.Fragment=l,Tr.jsx=v,Tr.jsxs=v,Tr}var lu;function Np(){return lu||(lu=1,Qs.exports=Rp()),Qs.exports}var x=Np(),_=ra(),qi={},Xs={exports:{}},Je={},Ys={exports:{}},Js={};/**
 * @license React
 * scheduler.production.min.js
 *
 * Copyright (c) Facebook, Inc. and its affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 */var cu;function Lp(){return cu||(cu=1,(function(s){function c(N,K){var B=N.length;N.push(K);e:for(;0<B;){var g=B-1>>>1,M=N[g];if(0<d(M,K))N[g]=K,N[B]=M,B=g;else break e}}function l(N){return N.length===0?null:N[0]}function p(N){if(N.length===0)return null;var K=N[0],B=N.pop();if(B!==K){N[0]=B;e:for(var g=0,M=N.length,re=M>>>1;g<re;){var oe=2*(g+1)-1,ue=N[oe],de=oe+1,ve=N[de];if(0>d(ue,B))de<M&&0>d(ve,ue)?(N[g]=ve,N[de]=B,g=de):(N[g]=ue,N[oe]=B,g=oe);else if(de<M&&0>d(ve,B))N[g]=ve,N[de]=B,g=de;else break e}}return K}function d(N,K){var B=N.sortIndex-K.sortIndex;return B!==0?B:N.id-K.id}if(typeof performance=="object"&&typeof performance.now=="function"){var m=performance;s.unstable_now=function(){return m.now()}}else{var v=Date,A=v.now();s.unstable_now=function(){return v.now()-A}}var k=[],b=[],I=1,T=null,R=3,q=!1,J=!1,j=!1,L=typeof setTimeout=="function"?setTimeout:null,H=typeof clearTimeout=="function"?clearTimeout:null,te=typeof setImmediate<"u"?setImmediate:null;typeof navigator<"u"&&navigator.scheduling!==void 0&&navigator.scheduling.isInputPending!==void 0&&navigator.scheduling.isInputPending.bind(navigator.scheduling);function V(N){for(var K=l(b);K!==null;){if(K.callback===null)p(b);else if(K.startTime<=N)p(b),K.sortIndex=K.expirationTime,c(k,K);else break;K=l(b)}}function se(N){if(j=!1,V(N),!J)if(l(k)!==null)J=!0,Pe(O);else{var K=l(b);K!==null&&ge(se,K.startTime-N)}}function O(N,K){J=!1,j&&(j=!1,H(Z),Z=-1),q=!0;var B=R;try{for(V(K),T=l(k);T!==null&&(!(T.expirationTime>K)||N&&!Ie());){var g=T.callback;if(typeof g=="function"){T.callback=null,R=T.priorityLevel;var M=g(T.expirationTime<=K);K=s.unstable_now(),typeof M=="function"?T.callback=M:T===l(k)&&p(k),V(K)}else p(k);T=l(k)}if(T!==null)var re=!0;else{var oe=l(b);oe!==null&&ge(se,oe.startTime-K),re=!1}return re}finally{T=null,R=B,q=!1}}var $=!1,Q=null,Z=-1,ne=5,ae=-1;function Ie(){return!(s.unstable_now()-ae<ne)}function ye(){if(Q!==null){var N=s.unstable_now();ae=N;var K=!0;try{K=Q(!0,N)}finally{K?Me():($=!1,Q=null)}}else $=!1}var Me;if(typeof te=="function")Me=function(){te(ye)};else if(typeof MessageChannel<"u"){var le=new MessageChannel,he=le.port2;le.port1.onmessage=ye,Me=function(){he.postMessage(null)}}else Me=function(){L(ye,0)};function Pe(N){Q=N,$||($=!0,Me())}function ge(N,K){Z=L(function(){N(s.unstable_now())},K)}s.unstable_IdlePriority=5,s.unstable_ImmediatePriority=1,s.unstable_LowPriority=4,s.unstable_NormalPriority=3,s.unstable_Profiling=null,s.unstable_UserBlockingPriority=2,s.unstable_cancelCallback=function(N){N.callback=null},s.unstable_continueExecution=function(){J||q||(J=!0,Pe(O))},s.unstable_forceFrameRate=function(N){0>N||125<N?console.error("forceFrameRate takes a positive int between 0 and 125, forcing frame rates higher than 125 fps is not supported"):ne=0<N?Math.floor(1e3/N):5},s.unstable_getCurrentPriorityLevel=function(){return R},s.unstable_getFirstCallbackNode=function(){return l(k)},s.unstable_next=function(N){switch(R){case 1:case 2:case 3:var K=3;break;default:K=R}var B=R;R=K;try{return N()}finally{R=B}},s.unstable_pauseExecution=function(){},s.unstable_requestPaint=function(){},s.unstable_runWithPriority=function(N,K){switch(N){case 1:case 2:case 3:case 4:case 5:break;default:N=3}var B=R;R=N;try{return K()}finally{R=B}},s.unstable_scheduleCallback=function(N,K,B){var g=s.unstable_now();switch(typeof B=="object"&&B!==null?(B=B.delay,B=typeof B=="number"&&0<B?g+B:g):B=g,N){case 1:var M=-1;break;case 2:M=250;break;case 5:M=1073741823;break;case 4:M=1e4;break;default:M=5e3}return M=B+M,N={id:I++,callback:K,priorityLevel:N,startTime:B,expirationTime:M,sortIndex:-1},B>g?(N.sortIndex=B,c(b,N),l(k)===null&&N===l(b)&&(j?(H(Z),Z=-1):j=!0,ge(se,B-g))):(N.sortIndex=M,c(k,N),J||q||(J=!0,Pe(O))),N},s.unstable_shouldYield=Ie,s.unstable_wrapCallback=function(N){var K=R;return function(){var B=R;R=K;try{return N.apply(this,arguments)}finally{R=B}}}})(Js)),Js}var uu;function Op(){return uu||(uu=1,Ys.exports=Lp()),Ys.exports}/**
 * @license React
 * react-dom.production.min.js
 *
 * Copyright (c) Facebook, Inc. and its affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 */var du;function Fp(){if(du)return Je;du=1;var s=ra(),c=Op();function l(e){for(var t="https://reactjs.org/docs/error-decoder.html?invariant="+e,n=1;n<arguments.length;n++)t+="&args[]="+encodeURIComponent(arguments[n]);return"Minified React error #"+e+"; visit "+t+" for the full message or use the non-minified dev environment for full errors and additional helpful warnings."}var p=new Set,d={};function m(e,t){v(e,t),v(e+"Capture",t)}function v(e,t){for(d[e]=t,e=0;e<t.length;e++)p.add(t[e])}var A=!(typeof window>"u"||typeof window.document>"u"||typeof window.document.createElement>"u"),k=Object.prototype.hasOwnProperty,b=/^[:A-Z_a-z\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u02FF\u0370-\u037D\u037F-\u1FFF\u200C-\u200D\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD][:A-Z_a-z\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u02FF\u0370-\u037D\u037F-\u1FFF\u200C-\u200D\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD\-.0-9\u00B7\u0300-\u036F\u203F-\u2040]*$/,I={},T={};function R(e){return k.call(T,e)?!0:k.call(I,e)?!1:b.test(e)?T[e]=!0:(I[e]=!0,!1)}function q(e,t,n,r){if(n!==null&&n.type===0)return!1;switch(typeof t){case"function":case"symbol":return!0;case"boolean":return r?!1:n!==null?!n.acceptsBooleans:(e=e.toLowerCase().slice(0,5),e!=="data-"&&e!=="aria-");default:return!1}}function J(e,t,n,r){if(t===null||typeof t>"u"||q(e,t,n,r))return!0;if(r)return!1;if(n!==null)switch(n.type){case 3:return!t;case 4:return t===!1;case 5:return isNaN(t);case 6:return isNaN(t)||1>t}return!1}function j(e,t,n,r,i,o,a){this.acceptsBooleans=t===2||t===3||t===4,this.attributeName=r,this.attributeNamespace=i,this.mustUseProperty=n,this.propertyName=e,this.type=t,this.sanitizeURL=o,this.removeEmptyString=a}var L={};"children dangerouslySetInnerHTML defaultValue defaultChecked innerHTML suppressContentEditableWarning suppressHydrationWarning style".split(" ").forEach(function(e){L[e]=new j(e,0,!1,e,null,!1,!1)}),[["acceptCharset","accept-charset"],["className","class"],["htmlFor","for"],["httpEquiv","http-equiv"]].forEach(function(e){var t=e[0];L[t]=new j(t,1,!1,e[1],null,!1,!1)}),["contentEditable","draggable","spellCheck","value"].forEach(function(e){L[e]=new j(e,2,!1,e.toLowerCase(),null,!1,!1)}),["autoReverse","externalResourcesRequired","focusable","preserveAlpha"].forEach(function(e){L[e]=new j(e,2,!1,e,null,!1,!1)}),"allowFullScreen async autoFocus autoPlay controls default defer disabled disablePictureInPicture disableRemotePlayback formNoValidate hidden loop noModule noValidate open playsInline readOnly required reversed scoped seamless itemScope".split(" ").forEach(function(e){L[e]=new j(e,3,!1,e.toLowerCase(),null,!1,!1)}),["checked","multiple","muted","selected"].forEach(function(e){L[e]=new j(e,3,!0,e,null,!1,!1)}),["capture","download"].forEach(function(e){L[e]=new j(e,4,!1,e,null,!1,!1)}),["cols","rows","size","span"].forEach(function(e){L[e]=new j(e,6,!1,e,null,!1,!1)}),["rowSpan","start"].forEach(function(e){L[e]=new j(e,5,!1,e.toLowerCase(),null,!1,!1)});var H=/[\-:]([a-z])/g;function te(e){return e[1].toUpperCase()}"accent-height alignment-baseline arabic-form baseline-shift cap-height clip-path clip-rule color-interpolation color-interpolation-filters color-profile color-rendering dominant-baseline enable-background fill-opacity fill-rule flood-color flood-opacity font-family font-size font-size-adjust font-stretch font-style font-variant font-weight glyph-name glyph-orientation-horizontal glyph-orientation-vertical horiz-adv-x horiz-origin-x image-rendering letter-spacing lighting-color marker-end marker-mid marker-start overline-position overline-thickness paint-order panose-1 pointer-events rendering-intent shape-rendering stop-color stop-opacity strikethrough-position strikethrough-thickness stroke-dasharray stroke-dashoffset stroke-linecap stroke-linejoin stroke-miterlimit stroke-opacity stroke-width text-anchor text-decoration text-rendering underline-position underline-thickness unicode-bidi unicode-range units-per-em v-alphabetic v-hanging v-ideographic v-mathematical vector-effect vert-adv-y vert-origin-x vert-origin-y word-spacing writing-mode xmlns:xlink x-height".split(" ").forEach(function(e){var t=e.replace(H,te);L[t]=new j(t,1,!1,e,null,!1,!1)}),"xlink:actuate xlink:arcrole xlink:role xlink:show xlink:title xlink:type".split(" ").forEach(function(e){var t=e.replace(H,te);L[t]=new j(t,1,!1,e,"http://www.w3.org/1999/xlink",!1,!1)}),["xml:base","xml:lang","xml:space"].forEach(function(e){var t=e.replace(H,te);L[t]=new j(t,1,!1,e,"http://www.w3.org/XML/1998/namespace",!1,!1)}),["tabIndex","crossOrigin"].forEach(function(e){L[e]=new j(e,1,!1,e.toLowerCase(),null,!1,!1)}),L.xlinkHref=new j("xlinkHref",1,!1,"xlink:href","http://www.w3.org/1999/xlink",!0,!1),["src","href","action","formAction"].forEach(function(e){L[e]=new j(e,1,!1,e.toLowerCase(),null,!0,!0)});function V(e,t,n,r){var i=L.hasOwnProperty(t)?L[t]:null;(i!==null?i.type!==0:r||!(2<t.length)||t[0]!=="o"&&t[0]!=="O"||t[1]!=="n"&&t[1]!=="N")&&(J(t,n,i,r)&&(n=null),r||i===null?R(t)&&(n===null?e.removeAttribute(t):e.setAttribute(t,""+n)):i.mustUseProperty?e[i.propertyName]=n===null?i.type===3?!1:"":n:(t=i.attributeName,r=i.attributeNamespace,n===null?e.removeAttribute(t):(i=i.type,n=i===3||i===4&&n===!0?"":""+n,r?e.setAttributeNS(r,t,n):e.setAttribute(t,n))))}var se=s.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED,O=Symbol.for("react.element"),$=Symbol.for("react.portal"),Q=Symbol.for("react.fragment"),Z=Symbol.for("react.strict_mode"),ne=Symbol.for("react.profiler"),ae=Symbol.for("react.provider"),Ie=Symbol.for("react.context"),ye=Symbol.for("react.forward_ref"),Me=Symbol.for("react.suspense"),le=Symbol.for("react.suspense_list"),he=Symbol.for("react.memo"),Pe=Symbol.for("react.lazy"),ge=Symbol.for("react.offscreen"),N=Symbol.iterator;function K(e){return e===null||typeof e!="object"?null:(e=N&&e[N]||e["@@iterator"],typeof e=="function"?e:null)}var B=Object.assign,g;function M(e){if(g===void 0)try{throw Error()}catch(n){var t=n.stack.trim().match(/\n( *(at )?)/);g=t&&t[1]||""}return`
`+g+e}var re=!1;function oe(e,t){if(!e||re)return"";re=!0;var n=Error.prepareStackTrace;Error.prepareStackTrace=void 0;try{if(t)if(t=function(){throw Error()},Object.defineProperty(t.prototype,"props",{set:function(){throw Error()}}),typeof Reflect=="object"&&Reflect.construct){try{Reflect.construct(t,[])}catch(S){var r=S}Reflect.construct(e,[],t)}else{try{t.call()}catch(S){r=S}e.call(t.prototype)}else{try{throw Error()}catch(S){r=S}e()}}catch(S){if(S&&r&&typeof S.stack=="string"){for(var i=S.stack.split(`
`),o=r.stack.split(`
`),a=i.length-1,u=o.length-1;1<=a&&0<=u&&i[a]!==o[u];)u--;for(;1<=a&&0<=u;a--,u--)if(i[a]!==o[u]){if(a!==1||u!==1)do if(a--,u--,0>u||i[a]!==o[u]){var h=`
`+i[a].replace(" at new "," at ");return e.displayName&&h.includes("<anonymous>")&&(h=h.replace("<anonymous>",e.displayName)),h}while(1<=a&&0<=u);break}}}finally{re=!1,Error.prepareStackTrace=n}return(e=e?e.displayName||e.name:"")?M(e):""}function ue(e){switch(e.tag){case 5:return M(e.type);case 16:return M("Lazy");case 13:return M("Suspense");case 19:return M("SuspenseList");case 0:case 2:case 15:return e=oe(e.type,!1),e;case 11:return e=oe(e.type.render,!1),e;case 1:return e=oe(e.type,!0),e;default:return""}}function de(e){if(e==null)return null;if(typeof e=="function")return e.displayName||e.name||null;if(typeof e=="string")return e;switch(e){case Q:return"Fragment";case $:return"Portal";case ne:return"Profiler";case Z:return"StrictMode";case Me:return"Suspense";case le:return"SuspenseList"}if(typeof e=="object")switch(e.$$typeof){case Ie:return(e.displayName||"Context")+".Consumer";case ae:return(e._context.displayName||"Context")+".Provider";case ye:var t=e.render;return e=e.displayName,e||(e=t.displayName||t.name||"",e=e!==""?"ForwardRef("+e+")":"ForwardRef"),e;case he:return t=e.displayName||null,t!==null?t:de(e.type)||"Memo";case Pe:t=e._payload,e=e._init;try{return de(e(t))}catch{}}return null}function ve(e){var t=e.type;switch(e.tag){case 24:return"Cache";case 9:return(t.displayName||"Context")+".Consumer";case 10:return(t._context.displayName||"Context")+".Provider";case 18:return"DehydratedFragment";case 11:return e=t.render,e=e.displayName||e.name||"",t.displayName||(e!==""?"ForwardRef("+e+")":"ForwardRef");case 7:return"Fragment";case 5:return t;case 4:return"Portal";case 3:return"Root";case 6:return"Text";case 16:return de(t);case 8:return t===Z?"StrictMode":"Mode";case 22:return"Offscreen";case 12:return"Profiler";case 21:return"Scope";case 13:return"Suspense";case 19:return"SuspenseList";case 25:return"TracingMarker";case 1:case 0:case 17:case 2:case 14:case 15:if(typeof t=="function")return t.displayName||t.name||null;if(typeof t=="string")return t}return null}function fe(e){switch(typeof e){case"boolean":case"number":case"string":case"undefined":return e;case"object":return e;default:return""}}function Se(e){var t=e.type;return(e=e.nodeName)&&e.toLowerCase()==="input"&&(t==="checkbox"||t==="radio")}function Ze(e){var t=Se(e)?"checked":"value",n=Object.getOwnPropertyDescriptor(e.constructor.prototype,t),r=""+e[t];if(!e.hasOwnProperty(t)&&typeof n<"u"&&typeof n.get=="function"&&typeof n.set=="function"){var i=n.get,o=n.set;return Object.defineProperty(e,t,{configurable:!0,get:function(){return i.call(this)},set:function(a){r=""+a,o.call(this,a)}}),Object.defineProperty(e,t,{enumerable:n.enumerable}),{getValue:function(){return r},setValue:function(a){r=""+a},stopTracking:function(){e._valueTracker=null,delete e[t]}}}}function Fr(e){e._valueTracker||(e._valueTracker=Ze(e))}function da(e){if(!e)return!1;var t=e._valueTracker;if(!t)return!0;var n=t.getValue(),r="";return e&&(r=Se(e)?e.checked?"true":"false":e.value),e=r,e!==n?(t.setValue(e),!0):!1}function jr(e){if(e=e||(typeof document<"u"?document:void 0),typeof e>"u")return null;try{return e.activeElement||e.body}catch{return e.body}}function eo(e,t){var n=t.checked;return B({},t,{defaultChecked:void 0,defaultValue:void 0,value:void 0,checked:n??e._wrapperState.initialChecked})}function pa(e,t){var n=t.defaultValue==null?"":t.defaultValue,r=t.checked!=null?t.checked:t.defaultChecked;n=fe(t.value!=null?t.value:n),e._wrapperState={initialChecked:r,initialValue:n,controlled:t.type==="checkbox"||t.type==="radio"?t.checked!=null:t.value!=null}}function ha(e,t){t=t.checked,t!=null&&V(e,"checked",t,!1)}function to(e,t){ha(e,t);var n=fe(t.value),r=t.type;if(n!=null)r==="number"?(n===0&&e.value===""||e.value!=n)&&(e.value=""+n):e.value!==""+n&&(e.value=""+n);else if(r==="submit"||r==="reset"){e.removeAttribute("value");return}t.hasOwnProperty("value")?no(e,t.type,n):t.hasOwnProperty("defaultValue")&&no(e,t.type,fe(t.defaultValue)),t.checked==null&&t.defaultChecked!=null&&(e.defaultChecked=!!t.defaultChecked)}function fa(e,t,n){if(t.hasOwnProperty("value")||t.hasOwnProperty("defaultValue")){var r=t.type;if(!(r!=="submit"&&r!=="reset"||t.value!==void 0&&t.value!==null))return;t=""+e._wrapperState.initialValue,n||t===e.value||(e.value=t),e.defaultValue=t}n=e.name,n!==""&&(e.name=""),e.defaultChecked=!!e._wrapperState.initialChecked,n!==""&&(e.name=n)}function no(e,t,n){(t!=="number"||jr(e.ownerDocument)!==e)&&(n==null?e.defaultValue=""+e._wrapperState.initialValue:e.defaultValue!==""+n&&(e.defaultValue=""+n))}var Gn=Array.isArray;function gn(e,t,n,r){if(e=e.options,t){t={};for(var i=0;i<n.length;i++)t["$"+n[i]]=!0;for(n=0;n<e.length;n++)i=t.hasOwnProperty("$"+e[n].value),e[n].selected!==i&&(e[n].selected=i),i&&r&&(e[n].defaultSelected=!0)}else{for(n=""+fe(n),t=null,i=0;i<e.length;i++){if(e[i].value===n){e[i].selected=!0,r&&(e[i].defaultSelected=!0);return}t!==null||e[i].disabled||(t=e[i])}t!==null&&(t.selected=!0)}}function ro(e,t){if(t.dangerouslySetInnerHTML!=null)throw Error(l(91));return B({},t,{value:void 0,defaultValue:void 0,children:""+e._wrapperState.initialValue})}function ma(e,t){var n=t.value;if(n==null){if(n=t.children,t=t.defaultValue,n!=null){if(t!=null)throw Error(l(92));if(Gn(n)){if(1<n.length)throw Error(l(93));n=n[0]}t=n}t==null&&(t=""),n=t}e._wrapperState={initialValue:fe(n)}}function ga(e,t){var n=fe(t.value),r=fe(t.defaultValue);n!=null&&(n=""+n,n!==e.value&&(e.value=n),t.defaultValue==null&&e.defaultValue!==n&&(e.defaultValue=n)),r!=null&&(e.defaultValue=""+r)}function ya(e){var t=e.textContent;t===e._wrapperState.initialValue&&t!==""&&t!==null&&(e.value=t)}function va(e){switch(e){case"svg":return"http://www.w3.org/2000/svg";case"math":return"http://www.w3.org/1998/Math/MathML";default:return"http://www.w3.org/1999/xhtml"}}function io(e,t){return e==null||e==="http://www.w3.org/1999/xhtml"?va(t):e==="http://www.w3.org/2000/svg"&&t==="foreignObject"?"http://www.w3.org/1999/xhtml":e}var zr,wa=(function(e){return typeof MSApp<"u"&&MSApp.execUnsafeLocalFunction?function(t,n,r,i){MSApp.execUnsafeLocalFunction(function(){return e(t,n,r,i)})}:e})(function(e,t){if(e.namespaceURI!=="http://www.w3.org/2000/svg"||"innerHTML"in e)e.innerHTML=t;else{for(zr=zr||document.createElement("div"),zr.innerHTML="<svg>"+t.valueOf().toString()+"</svg>",t=zr.firstChild;e.firstChild;)e.removeChild(e.firstChild);for(;t.firstChild;)e.appendChild(t.firstChild)}});function qn(e,t){if(t){var n=e.firstChild;if(n&&n===e.lastChild&&n.nodeType===3){n.nodeValue=t;return}}e.textContent=t}var Qn={animationIterationCount:!0,aspectRatio:!0,borderImageOutset:!0,borderImageSlice:!0,borderImageWidth:!0,boxFlex:!0,boxFlexGroup:!0,boxOrdinalGroup:!0,columnCount:!0,columns:!0,flex:!0,flexGrow:!0,flexPositive:!0,flexShrink:!0,flexNegative:!0,flexOrder:!0,gridArea:!0,gridRow:!0,gridRowEnd:!0,gridRowSpan:!0,gridRowStart:!0,gridColumn:!0,gridColumnEnd:!0,gridColumnSpan:!0,gridColumnStart:!0,fontWeight:!0,lineClamp:!0,lineHeight:!0,opacity:!0,order:!0,orphans:!0,tabSize:!0,widows:!0,zIndex:!0,zoom:!0,fillOpacity:!0,floodOpacity:!0,stopOpacity:!0,strokeDasharray:!0,strokeDashoffset:!0,strokeMiterlimit:!0,strokeOpacity:!0,strokeWidth:!0},Ou=["Webkit","ms","Moz","O"];Object.keys(Qn).forEach(function(e){Ou.forEach(function(t){t=t+e.charAt(0).toUpperCase()+e.substring(1),Qn[t]=Qn[e]})});function ka(e,t,n){return t==null||typeof t=="boolean"||t===""?"":n||typeof t!="number"||t===0||Qn.hasOwnProperty(e)&&Qn[e]?(""+t).trim():t+"px"}function xa(e,t){e=e.style;for(var n in t)if(t.hasOwnProperty(n)){var r=n.indexOf("--")===0,i=ka(n,t[n],r);n==="float"&&(n="cssFloat"),r?e.setProperty(n,i):e[n]=i}}var Fu=B({menuitem:!0},{area:!0,base:!0,br:!0,col:!0,embed:!0,hr:!0,img:!0,input:!0,keygen:!0,link:!0,meta:!0,param:!0,source:!0,track:!0,wbr:!0});function oo(e,t){if(t){if(Fu[e]&&(t.children!=null||t.dangerouslySetInnerHTML!=null))throw Error(l(137,e));if(t.dangerouslySetInnerHTML!=null){if(t.children!=null)throw Error(l(60));if(typeof t.dangerouslySetInnerHTML!="object"||!("__html"in t.dangerouslySetInnerHTML))throw Error(l(61))}if(t.style!=null&&typeof t.style!="object")throw Error(l(62))}}function so(e,t){if(e.indexOf("-")===-1)return typeof t.is=="string";switch(e){case"annotation-xml":case"color-profile":case"font-face":case"font-face-src":case"font-face-uri":case"font-face-format":case"font-face-name":case"missing-glyph":return!1;default:return!0}}var ao=null;function lo(e){return e=e.target||e.srcElement||window,e.correspondingUseElement&&(e=e.correspondingUseElement),e.nodeType===3?e.parentNode:e}var co=null,yn=null,vn=null;function Sa(e){if(e=gr(e)){if(typeof co!="function")throw Error(l(280));var t=e.stateNode;t&&(t=li(t),co(e.stateNode,e.type,t))}}function ba(e){yn?vn?vn.push(e):vn=[e]:yn=e}function Aa(){if(yn){var e=yn,t=vn;if(vn=yn=null,Sa(e),t)for(e=0;e<t.length;e++)Sa(t[e])}}function Ia(e,t){return e(t)}function _a(){}var uo=!1;function Ea(e,t,n){if(uo)return e(t,n);uo=!0;try{return Ia(e,t,n)}finally{uo=!1,(yn!==null||vn!==null)&&(_a(),Aa())}}function Kn(e,t){var n=e.stateNode;if(n===null)return null;var r=li(n);if(r===null)return null;n=r[t];e:switch(t){case"onClick":case"onClickCapture":case"onDoubleClick":case"onDoubleClickCapture":case"onMouseDown":case"onMouseDownCapture":case"onMouseMove":case"onMouseMoveCapture":case"onMouseUp":case"onMouseUpCapture":case"onMouseEnter":(r=!r.disabled)||(e=e.type,r=!(e==="button"||e==="input"||e==="select"||e==="textarea")),e=!r;break e;default:e=!1}if(e)return null;if(n&&typeof n!="function")throw Error(l(231,t,typeof n));return n}var po=!1;if(A)try{var Xn={};Object.defineProperty(Xn,"passive",{get:function(){po=!0}}),window.addEventListener("test",Xn,Xn),window.removeEventListener("test",Xn,Xn)}catch{po=!1}function ju(e,t,n,r,i,o,a,u,h){var S=Array.prototype.slice.call(arguments,3);try{t.apply(n,S)}catch(C){this.onError(C)}}var Yn=!1,Br=null,$r=!1,ho=null,zu={onError:function(e){Yn=!0,Br=e}};function Bu(e,t,n,r,i,o,a,u,h){Yn=!1,Br=null,ju.apply(zu,arguments)}function $u(e,t,n,r,i,o,a,u,h){if(Bu.apply(this,arguments),Yn){if(Yn){var S=Br;Yn=!1,Br=null}else throw Error(l(198));$r||($r=!0,ho=S)}}function tn(e){var t=e,n=e;if(e.alternate)for(;t.return;)t=t.return;else{e=t;do t=e,(t.flags&4098)!==0&&(n=t.return),e=t.return;while(e)}return t.tag===3?n:null}function Ma(e){if(e.tag===13){var t=e.memoizedState;if(t===null&&(e=e.alternate,e!==null&&(t=e.memoizedState)),t!==null)return t.dehydrated}return null}function Ca(e){if(tn(e)!==e)throw Error(l(188))}function Uu(e){var t=e.alternate;if(!t){if(t=tn(e),t===null)throw Error(l(188));return t!==e?null:e}for(var n=e,r=t;;){var i=n.return;if(i===null)break;var o=i.alternate;if(o===null){if(r=i.return,r!==null){n=r;continue}break}if(i.child===o.child){for(o=i.child;o;){if(o===n)return Ca(i),e;if(o===r)return Ca(i),t;o=o.sibling}throw Error(l(188))}if(n.return!==r.return)n=i,r=o;else{for(var a=!1,u=i.child;u;){if(u===n){a=!0,n=i,r=o;break}if(u===r){a=!0,r=i,n=o;break}u=u.sibling}if(!a){for(u=o.child;u;){if(u===n){a=!0,n=o,r=i;break}if(u===r){a=!0,r=o,n=i;break}u=u.sibling}if(!a)throw Error(l(189))}}if(n.alternate!==r)throw Error(l(190))}if(n.tag!==3)throw Error(l(188));return n.stateNode.current===n?e:t}function Pa(e){return e=Uu(e),e!==null?Ta(e):null}function Ta(e){if(e.tag===5||e.tag===6)return e;for(e=e.child;e!==null;){var t=Ta(e);if(t!==null)return t;e=e.sibling}return null}var Da=c.unstable_scheduleCallback,Ra=c.unstable_cancelCallback,Wu=c.unstable_shouldYield,Hu=c.unstable_requestPaint,Te=c.unstable_now,Vu=c.unstable_getCurrentPriorityLevel,fo=c.unstable_ImmediatePriority,Na=c.unstable_UserBlockingPriority,Ur=c.unstable_NormalPriority,Gu=c.unstable_LowPriority,La=c.unstable_IdlePriority,Wr=null,kt=null;function qu(e){if(kt&&typeof kt.onCommitFiberRoot=="function")try{kt.onCommitFiberRoot(Wr,e,void 0,(e.current.flags&128)===128)}catch{}}var ut=Math.clz32?Math.clz32:Xu,Qu=Math.log,Ku=Math.LN2;function Xu(e){return e>>>=0,e===0?32:31-(Qu(e)/Ku|0)|0}var Hr=64,Vr=4194304;function Jn(e){switch(e&-e){case 1:return 1;case 2:return 2;case 4:return 4;case 8:return 8;case 16:return 16;case 32:return 32;case 64:case 128:case 256:case 512:case 1024:case 2048:case 4096:case 8192:case 16384:case 32768:case 65536:case 131072:case 262144:case 524288:case 1048576:case 2097152:return e&4194240;case 4194304:case 8388608:case 16777216:case 33554432:case 67108864:return e&130023424;case 134217728:return 134217728;case 268435456:return 268435456;case 536870912:return 536870912;case 1073741824:return 1073741824;default:return e}}function Gr(e,t){var n=e.pendingLanes;if(n===0)return 0;var r=0,i=e.suspendedLanes,o=e.pingedLanes,a=n&268435455;if(a!==0){var u=a&~i;u!==0?r=Jn(u):(o&=a,o!==0&&(r=Jn(o)))}else a=n&~i,a!==0?r=Jn(a):o!==0&&(r=Jn(o));if(r===0)return 0;if(t!==0&&t!==r&&(t&i)===0&&(i=r&-r,o=t&-t,i>=o||i===16&&(o&4194240)!==0))return t;if((r&4)!==0&&(r|=n&16),t=e.entangledLanes,t!==0)for(e=e.entanglements,t&=r;0<t;)n=31-ut(t),i=1<<n,r|=e[n],t&=~i;return r}function Yu(e,t){switch(e){case 1:case 2:case 4:return t+250;case 8:case 16:case 32:case 64:case 128:case 256:case 512:case 1024:case 2048:case 4096:case 8192:case 16384:case 32768:case 65536:case 131072:case 262144:case 524288:case 1048576:case 2097152:return t+5e3;case 4194304:case 8388608:case 16777216:case 33554432:case 67108864:return-1;case 134217728:case 268435456:case 536870912:case 1073741824:return-1;default:return-1}}function Ju(e,t){for(var n=e.suspendedLanes,r=e.pingedLanes,i=e.expirationTimes,o=e.pendingLanes;0<o;){var a=31-ut(o),u=1<<a,h=i[a];h===-1?((u&n)===0||(u&r)!==0)&&(i[a]=Yu(u,t)):h<=t&&(e.expiredLanes|=u),o&=~u}}function mo(e){return e=e.pendingLanes&-1073741825,e!==0?e:e&1073741824?1073741824:0}function Oa(){var e=Hr;return Hr<<=1,(Hr&4194240)===0&&(Hr=64),e}function go(e){for(var t=[],n=0;31>n;n++)t.push(e);return t}function Zn(e,t,n){e.pendingLanes|=t,t!==536870912&&(e.suspendedLanes=0,e.pingedLanes=0),e=e.eventTimes,t=31-ut(t),e[t]=n}function Zu(e,t){var n=e.pendingLanes&~t;e.pendingLanes=t,e.suspendedLanes=0,e.pingedLanes=0,e.expiredLanes&=t,e.mutableReadLanes&=t,e.entangledLanes&=t,t=e.entanglements;var r=e.eventTimes;for(e=e.expirationTimes;0<n;){var i=31-ut(n),o=1<<i;t[i]=0,r[i]=-1,e[i]=-1,n&=~o}}function yo(e,t){var n=e.entangledLanes|=t;for(e=e.entanglements;n;){var r=31-ut(n),i=1<<r;i&t|e[r]&t&&(e[r]|=t),n&=~i}}var me=0;function Fa(e){return e&=-e,1<e?4<e?(e&268435455)!==0?16:536870912:4:1}var ja,vo,za,Ba,$a,wo=!1,qr=[],Ot=null,Ft=null,jt=null,er=new Map,tr=new Map,zt=[],ed="mousedown mouseup touchcancel touchend touchstart auxclick dblclick pointercancel pointerdown pointerup dragend dragstart drop compositionend compositionstart keydown keypress keyup input textInput copy cut paste click change contextmenu reset submit".split(" ");function Ua(e,t){switch(e){case"focusin":case"focusout":Ot=null;break;case"dragenter":case"dragleave":Ft=null;break;case"mouseover":case"mouseout":jt=null;break;case"pointerover":case"pointerout":er.delete(t.pointerId);break;case"gotpointercapture":case"lostpointercapture":tr.delete(t.pointerId)}}function nr(e,t,n,r,i,o){return e===null||e.nativeEvent!==o?(e={blockedOn:t,domEventName:n,eventSystemFlags:r,nativeEvent:o,targetContainers:[i]},t!==null&&(t=gr(t),t!==null&&vo(t)),e):(e.eventSystemFlags|=r,t=e.targetContainers,i!==null&&t.indexOf(i)===-1&&t.push(i),e)}function td(e,t,n,r,i){switch(t){case"focusin":return Ot=nr(Ot,e,t,n,r,i),!0;case"dragenter":return Ft=nr(Ft,e,t,n,r,i),!0;case"mouseover":return jt=nr(jt,e,t,n,r,i),!0;case"pointerover":var o=i.pointerId;return er.set(o,nr(er.get(o)||null,e,t,n,r,i)),!0;case"gotpointercapture":return o=i.pointerId,tr.set(o,nr(tr.get(o)||null,e,t,n,r,i)),!0}return!1}function Wa(e){var t=nn(e.target);if(t!==null){var n=tn(t);if(n!==null){if(t=n.tag,t===13){if(t=Ma(n),t!==null){e.blockedOn=t,$a(e.priority,function(){za(n)});return}}else if(t===3&&n.stateNode.current.memoizedState.isDehydrated){e.blockedOn=n.tag===3?n.stateNode.containerInfo:null;return}}}e.blockedOn=null}function Qr(e){if(e.blockedOn!==null)return!1;for(var t=e.targetContainers;0<t.length;){var n=xo(e.domEventName,e.eventSystemFlags,t[0],e.nativeEvent);if(n===null){n=e.nativeEvent;var r=new n.constructor(n.type,n);ao=r,n.target.dispatchEvent(r),ao=null}else return t=gr(n),t!==null&&vo(t),e.blockedOn=n,!1;t.shift()}return!0}function Ha(e,t,n){Qr(e)&&n.delete(t)}function nd(){wo=!1,Ot!==null&&Qr(Ot)&&(Ot=null),Ft!==null&&Qr(Ft)&&(Ft=null),jt!==null&&Qr(jt)&&(jt=null),er.forEach(Ha),tr.forEach(Ha)}function rr(e,t){e.blockedOn===t&&(e.blockedOn=null,wo||(wo=!0,c.unstable_scheduleCallback(c.unstable_NormalPriority,nd)))}function ir(e){function t(i){return rr(i,e)}if(0<qr.length){rr(qr[0],e);for(var n=1;n<qr.length;n++){var r=qr[n];r.blockedOn===e&&(r.blockedOn=null)}}for(Ot!==null&&rr(Ot,e),Ft!==null&&rr(Ft,e),jt!==null&&rr(jt,e),er.forEach(t),tr.forEach(t),n=0;n<zt.length;n++)r=zt[n],r.blockedOn===e&&(r.blockedOn=null);for(;0<zt.length&&(n=zt[0],n.blockedOn===null);)Wa(n),n.blockedOn===null&&zt.shift()}var wn=se.ReactCurrentBatchConfig,Kr=!0;function rd(e,t,n,r){var i=me,o=wn.transition;wn.transition=null;try{me=1,ko(e,t,n,r)}finally{me=i,wn.transition=o}}function id(e,t,n,r){var i=me,o=wn.transition;wn.transition=null;try{me=4,ko(e,t,n,r)}finally{me=i,wn.transition=o}}function ko(e,t,n,r){if(Kr){var i=xo(e,t,n,r);if(i===null)jo(e,t,r,Xr,n),Ua(e,r);else if(td(i,e,t,n,r))r.stopPropagation();else if(Ua(e,r),t&4&&-1<ed.indexOf(e)){for(;i!==null;){var o=gr(i);if(o!==null&&ja(o),o=xo(e,t,n,r),o===null&&jo(e,t,r,Xr,n),o===i)break;i=o}i!==null&&r.stopPropagation()}else jo(e,t,r,null,n)}}var Xr=null;function xo(e,t,n,r){if(Xr=null,e=lo(r),e=nn(e),e!==null)if(t=tn(e),t===null)e=null;else if(n=t.tag,n===13){if(e=Ma(t),e!==null)return e;e=null}else if(n===3){if(t.stateNode.current.memoizedState.isDehydrated)return t.tag===3?t.stateNode.containerInfo:null;e=null}else t!==e&&(e=null);return Xr=e,null}function Va(e){switch(e){case"cancel":case"click":case"close":case"contextmenu":case"copy":case"cut":case"auxclick":case"dblclick":case"dragend":case"dragstart":case"drop":case"focusin":case"focusout":case"input":case"invalid":case"keydown":case"keypress":case"keyup":case"mousedown":case"mouseup":case"paste":case"pause":case"play":case"pointercancel":case"pointerdown":case"pointerup":case"ratechange":case"reset":case"resize":case"seeked":case"submit":case"touchcancel":case"touchend":case"touchstart":case"volumechange":case"change":case"selectionchange":case"textInput":case"compositionstart":case"compositionend":case"compositionupdate":case"beforeblur":case"afterblur":case"beforeinput":case"blur":case"fullscreenchange":case"focus":case"hashchange":case"popstate":case"select":case"selectstart":return 1;case"drag":case"dragenter":case"dragexit":case"dragleave":case"dragover":case"mousemove":case"mouseout":case"mouseover":case"pointermove":case"pointerout":case"pointerover":case"scroll":case"toggle":case"touchmove":case"wheel":case"mouseenter":case"mouseleave":case"pointerenter":case"pointerleave":return 4;case"message":switch(Vu()){case fo:return 1;case Na:return 4;case Ur:case Gu:return 16;case La:return 536870912;default:return 16}default:return 16}}var Bt=null,So=null,Yr=null;function Ga(){if(Yr)return Yr;var e,t=So,n=t.length,r,i="value"in Bt?Bt.value:Bt.textContent,o=i.length;for(e=0;e<n&&t[e]===i[e];e++);var a=n-e;for(r=1;r<=a&&t[n-r]===i[o-r];r++);return Yr=i.slice(e,1<r?1-r:void 0)}function Jr(e){var t=e.keyCode;return"charCode"in e?(e=e.charCode,e===0&&t===13&&(e=13)):e=t,e===10&&(e=13),32<=e||e===13?e:0}function Zr(){return!0}function qa(){return!1}function et(e){function t(n,r,i,o,a){this._reactName=n,this._targetInst=i,this.type=r,this.nativeEvent=o,this.target=a,this.currentTarget=null;for(var u in e)e.hasOwnProperty(u)&&(n=e[u],this[u]=n?n(o):o[u]);return this.isDefaultPrevented=(o.defaultPrevented!=null?o.defaultPrevented:o.returnValue===!1)?Zr:qa,this.isPropagationStopped=qa,this}return B(t.prototype,{preventDefault:function(){this.defaultPrevented=!0;var n=this.nativeEvent;n&&(n.preventDefault?n.preventDefault():typeof n.returnValue!="unknown"&&(n.returnValue=!1),this.isDefaultPrevented=Zr)},stopPropagation:function(){var n=this.nativeEvent;n&&(n.stopPropagation?n.stopPropagation():typeof n.cancelBubble!="unknown"&&(n.cancelBubble=!0),this.isPropagationStopped=Zr)},persist:function(){},isPersistent:Zr}),t}var kn={eventPhase:0,bubbles:0,cancelable:0,timeStamp:function(e){return e.timeStamp||Date.now()},defaultPrevented:0,isTrusted:0},bo=et(kn),or=B({},kn,{view:0,detail:0}),od=et(or),Ao,Io,sr,ei=B({},or,{screenX:0,screenY:0,clientX:0,clientY:0,pageX:0,pageY:0,ctrlKey:0,shiftKey:0,altKey:0,metaKey:0,getModifierState:Eo,button:0,buttons:0,relatedTarget:function(e){return e.relatedTarget===void 0?e.fromElement===e.srcElement?e.toElement:e.fromElement:e.relatedTarget},movementX:function(e){return"movementX"in e?e.movementX:(e!==sr&&(sr&&e.type==="mousemove"?(Ao=e.screenX-sr.screenX,Io=e.screenY-sr.screenY):Io=Ao=0,sr=e),Ao)},movementY:function(e){return"movementY"in e?e.movementY:Io}}),Qa=et(ei),sd=B({},ei,{dataTransfer:0}),ad=et(sd),ld=B({},or,{relatedTarget:0}),_o=et(ld),cd=B({},kn,{animationName:0,elapsedTime:0,pseudoElement:0}),ud=et(cd),dd=B({},kn,{clipboardData:function(e){return"clipboardData"in e?e.clipboardData:window.clipboardData}}),pd=et(dd),hd=B({},kn,{data:0}),Ka=et(hd),fd={Esc:"Escape",Spacebar:" ",Left:"ArrowLeft",Up:"ArrowUp",Right:"ArrowRight",Down:"ArrowDown",Del:"Delete",Win:"OS",Menu:"ContextMenu",Apps:"ContextMenu",Scroll:"ScrollLock",MozPrintableKey:"Unidentified"},md={8:"Backspace",9:"Tab",12:"Clear",13:"Enter",16:"Shift",17:"Control",18:"Alt",19:"Pause",20:"CapsLock",27:"Escape",32:" ",33:"PageUp",34:"PageDown",35:"End",36:"Home",37:"ArrowLeft",38:"ArrowUp",39:"ArrowRight",40:"ArrowDown",45:"Insert",46:"Delete",112:"F1",113:"F2",114:"F3",115:"F4",116:"F5",117:"F6",118:"F7",119:"F8",120:"F9",121:"F10",122:"F11",123:"F12",144:"NumLock",145:"ScrollLock",224:"Meta"},gd={Alt:"altKey",Control:"ctrlKey",Meta:"metaKey",Shift:"shiftKey"};function yd(e){var t=this.nativeEvent;return t.getModifierState?t.getModifierState(e):(e=gd[e])?!!t[e]:!1}function Eo(){return yd}var vd=B({},or,{key:function(e){if(e.key){var t=fd[e.key]||e.key;if(t!=="Unidentified")return t}return e.type==="keypress"?(e=Jr(e),e===13?"Enter":String.fromCharCode(e)):e.type==="keydown"||e.type==="keyup"?md[e.keyCode]||"Unidentified":""},code:0,location:0,ctrlKey:0,shiftKey:0,altKey:0,metaKey:0,repeat:0,locale:0,getModifierState:Eo,charCode:function(e){return e.type==="keypress"?Jr(e):0},keyCode:function(e){return e.type==="keydown"||e.type==="keyup"?e.keyCode:0},which:function(e){return e.type==="keypress"?Jr(e):e.type==="keydown"||e.type==="keyup"?e.keyCode:0}}),wd=et(vd),kd=B({},ei,{pointerId:0,width:0,height:0,pressure:0,tangentialPressure:0,tiltX:0,tiltY:0,twist:0,pointerType:0,isPrimary:0}),Xa=et(kd),xd=B({},or,{touches:0,targetTouches:0,changedTouches:0,altKey:0,metaKey:0,ctrlKey:0,shiftKey:0,getModifierState:Eo}),Sd=et(xd),bd=B({},kn,{propertyName:0,elapsedTime:0,pseudoElement:0}),Ad=et(bd),Id=B({},ei,{deltaX:function(e){return"deltaX"in e?e.deltaX:"wheelDeltaX"in e?-e.wheelDeltaX:0},deltaY:function(e){return"deltaY"in e?e.deltaY:"wheelDeltaY"in e?-e.wheelDeltaY:"wheelDelta"in e?-e.wheelDelta:0},deltaZ:0,deltaMode:0}),_d=et(Id),Ed=[9,13,27,32],Mo=A&&"CompositionEvent"in window,ar=null;A&&"documentMode"in document&&(ar=document.documentMode);var Md=A&&"TextEvent"in window&&!ar,Ya=A&&(!Mo||ar&&8<ar&&11>=ar),Ja=" ",Za=!1;function el(e,t){switch(e){case"keyup":return Ed.indexOf(t.keyCode)!==-1;case"keydown":return t.keyCode!==229;case"keypress":case"mousedown":case"focusout":return!0;default:return!1}}function tl(e){return e=e.detail,typeof e=="object"&&"data"in e?e.data:null}var xn=!1;function Cd(e,t){switch(e){case"compositionend":return tl(t);case"keypress":return t.which!==32?null:(Za=!0,Ja);case"textInput":return e=t.data,e===Ja&&Za?null:e;default:return null}}function Pd(e,t){if(xn)return e==="compositionend"||!Mo&&el(e,t)?(e=Ga(),Yr=So=Bt=null,xn=!1,e):null;switch(e){case"paste":return null;case"keypress":if(!(t.ctrlKey||t.altKey||t.metaKey)||t.ctrlKey&&t.altKey){if(t.char&&1<t.char.length)return t.char;if(t.which)return String.fromCharCode(t.which)}return null;case"compositionend":return Ya&&t.locale!=="ko"?null:t.data;default:return null}}var Td={color:!0,date:!0,datetime:!0,"datetime-local":!0,email:!0,month:!0,number:!0,password:!0,range:!0,search:!0,tel:!0,text:!0,time:!0,url:!0,week:!0};function nl(e){var t=e&&e.nodeName&&e.nodeName.toLowerCase();return t==="input"?!!Td[e.type]:t==="textarea"}function rl(e,t,n,r){ba(r),t=oi(t,"onChange"),0<t.length&&(n=new bo("onChange","change",null,n,r),e.push({event:n,listeners:t}))}var lr=null,cr=null;function Dd(e){xl(e,0)}function ti(e){var t=_n(e);if(da(t))return e}function Rd(e,t){if(e==="change")return t}var il=!1;if(A){var Co;if(A){var Po="oninput"in document;if(!Po){var ol=document.createElement("div");ol.setAttribute("oninput","return;"),Po=typeof ol.oninput=="function"}Co=Po}else Co=!1;il=Co&&(!document.documentMode||9<document.documentMode)}function sl(){lr&&(lr.detachEvent("onpropertychange",al),cr=lr=null)}function al(e){if(e.propertyName==="value"&&ti(cr)){var t=[];rl(t,cr,e,lo(e)),Ea(Dd,t)}}function Nd(e,t,n){e==="focusin"?(sl(),lr=t,cr=n,lr.attachEvent("onpropertychange",al)):e==="focusout"&&sl()}function Ld(e){if(e==="selectionchange"||e==="keyup"||e==="keydown")return ti(cr)}function Od(e,t){if(e==="click")return ti(t)}function Fd(e,t){if(e==="input"||e==="change")return ti(t)}function jd(e,t){return e===t&&(e!==0||1/e===1/t)||e!==e&&t!==t}var dt=typeof Object.is=="function"?Object.is:jd;function ur(e,t){if(dt(e,t))return!0;if(typeof e!="object"||e===null||typeof t!="object"||t===null)return!1;var n=Object.keys(e),r=Object.keys(t);if(n.length!==r.length)return!1;for(r=0;r<n.length;r++){var i=n[r];if(!k.call(t,i)||!dt(e[i],t[i]))return!1}return!0}function ll(e){for(;e&&e.firstChild;)e=e.firstChild;return e}function cl(e,t){var n=ll(e);e=0;for(var r;n;){if(n.nodeType===3){if(r=e+n.textContent.length,e<=t&&r>=t)return{node:n,offset:t-e};e=r}e:{for(;n;){if(n.nextSibling){n=n.nextSibling;break e}n=n.parentNode}n=void 0}n=ll(n)}}function ul(e,t){return e&&t?e===t?!0:e&&e.nodeType===3?!1:t&&t.nodeType===3?ul(e,t.parentNode):"contains"in e?e.contains(t):e.compareDocumentPosition?!!(e.compareDocumentPosition(t)&16):!1:!1}function dl(){for(var e=window,t=jr();t instanceof e.HTMLIFrameElement;){try{var n=typeof t.contentWindow.location.href=="string"}catch{n=!1}if(n)e=t.contentWindow;else break;t=jr(e.document)}return t}function To(e){var t=e&&e.nodeName&&e.nodeName.toLowerCase();return t&&(t==="input"&&(e.type==="text"||e.type==="search"||e.type==="tel"||e.type==="url"||e.type==="password")||t==="textarea"||e.contentEditable==="true")}function zd(e){var t=dl(),n=e.focusedElem,r=e.selectionRange;if(t!==n&&n&&n.ownerDocument&&ul(n.ownerDocument.documentElement,n)){if(r!==null&&To(n)){if(t=r.start,e=r.end,e===void 0&&(e=t),"selectionStart"in n)n.selectionStart=t,n.selectionEnd=Math.min(e,n.value.length);else if(e=(t=n.ownerDocument||document)&&t.defaultView||window,e.getSelection){e=e.getSelection();var i=n.textContent.length,o=Math.min(r.start,i);r=r.end===void 0?o:Math.min(r.end,i),!e.extend&&o>r&&(i=r,r=o,o=i),i=cl(n,o);var a=cl(n,r);i&&a&&(e.rangeCount!==1||e.anchorNode!==i.node||e.anchorOffset!==i.offset||e.focusNode!==a.node||e.focusOffset!==a.offset)&&(t=t.createRange(),t.setStart(i.node,i.offset),e.removeAllRanges(),o>r?(e.addRange(t),e.extend(a.node,a.offset)):(t.setEnd(a.node,a.offset),e.addRange(t)))}}for(t=[],e=n;e=e.parentNode;)e.nodeType===1&&t.push({element:e,left:e.scrollLeft,top:e.scrollTop});for(typeof n.focus=="function"&&n.focus(),n=0;n<t.length;n++)e=t[n],e.element.scrollLeft=e.left,e.element.scrollTop=e.top}}var Bd=A&&"documentMode"in document&&11>=document.documentMode,Sn=null,Do=null,dr=null,Ro=!1;function pl(e,t,n){var r=n.window===n?n.document:n.nodeType===9?n:n.ownerDocument;Ro||Sn==null||Sn!==jr(r)||(r=Sn,"selectionStart"in r&&To(r)?r={start:r.selectionStart,end:r.selectionEnd}:(r=(r.ownerDocument&&r.ownerDocument.defaultView||window).getSelection(),r={anchorNode:r.anchorNode,anchorOffset:r.anchorOffset,focusNode:r.focusNode,focusOffset:r.focusOffset}),dr&&ur(dr,r)||(dr=r,r=oi(Do,"onSelect"),0<r.length&&(t=new bo("onSelect","select",null,t,n),e.push({event:t,listeners:r}),t.target=Sn)))}function ni(e,t){var n={};return n[e.toLowerCase()]=t.toLowerCase(),n["Webkit"+e]="webkit"+t,n["Moz"+e]="moz"+t,n}var bn={animationend:ni("Animation","AnimationEnd"),animationiteration:ni("Animation","AnimationIteration"),animationstart:ni("Animation","AnimationStart"),transitionend:ni("Transition","TransitionEnd")},No={},hl={};A&&(hl=document.createElement("div").style,"AnimationEvent"in window||(delete bn.animationend.animation,delete bn.animationiteration.animation,delete bn.animationstart.animation),"TransitionEvent"in window||delete bn.transitionend.transition);function ri(e){if(No[e])return No[e];if(!bn[e])return e;var t=bn[e],n;for(n in t)if(t.hasOwnProperty(n)&&n in hl)return No[e]=t[n];return e}var fl=ri("animationend"),ml=ri("animationiteration"),gl=ri("animationstart"),yl=ri("transitionend"),vl=new Map,wl="abort auxClick cancel canPlay canPlayThrough click close contextMenu copy cut drag dragEnd dragEnter dragExit dragLeave dragOver dragStart drop durationChange emptied encrypted ended error gotPointerCapture input invalid keyDown keyPress keyUp load loadedData loadedMetadata loadStart lostPointerCapture mouseDown mouseMove mouseOut mouseOver mouseUp paste pause play playing pointerCancel pointerDown pointerMove pointerOut pointerOver pointerUp progress rateChange reset resize seeked seeking stalled submit suspend timeUpdate touchCancel touchEnd touchStart volumeChange scroll toggle touchMove waiting wheel".split(" ");function $t(e,t){vl.set(e,t),m(t,[e])}for(var Lo=0;Lo<wl.length;Lo++){var Oo=wl[Lo],$d=Oo.toLowerCase(),Ud=Oo[0].toUpperCase()+Oo.slice(1);$t($d,"on"+Ud)}$t(fl,"onAnimationEnd"),$t(ml,"onAnimationIteration"),$t(gl,"onAnimationStart"),$t("dblclick","onDoubleClick"),$t("focusin","onFocus"),$t("focusout","onBlur"),$t(yl,"onTransitionEnd"),v("onMouseEnter",["mouseout","mouseover"]),v("onMouseLeave",["mouseout","mouseover"]),v("onPointerEnter",["pointerout","pointerover"]),v("onPointerLeave",["pointerout","pointerover"]),m("onChange","change click focusin focusout input keydown keyup selectionchange".split(" ")),m("onSelect","focusout contextmenu dragend focusin keydown keyup mousedown mouseup selectionchange".split(" ")),m("onBeforeInput",["compositionend","keypress","textInput","paste"]),m("onCompositionEnd","compositionend focusout keydown keypress keyup mousedown".split(" ")),m("onCompositionStart","compositionstart focusout keydown keypress keyup mousedown".split(" ")),m("onCompositionUpdate","compositionupdate focusout keydown keypress keyup mousedown".split(" "));var pr="abort canplay canplaythrough durationchange emptied encrypted ended error loadeddata loadedmetadata loadstart pause play playing progress ratechange resize seeked seeking stalled suspend timeupdate volumechange waiting".split(" "),Wd=new Set("cancel close invalid load scroll toggle".split(" ").concat(pr));function kl(e,t,n){var r=e.type||"unknown-event";e.currentTarget=n,$u(r,t,void 0,e),e.currentTarget=null}function xl(e,t){t=(t&4)!==0;for(var n=0;n<e.length;n++){var r=e[n],i=r.event;r=r.listeners;e:{var o=void 0;if(t)for(var a=r.length-1;0<=a;a--){var u=r[a],h=u.instance,S=u.currentTarget;if(u=u.listener,h!==o&&i.isPropagationStopped())break e;kl(i,u,S),o=h}else for(a=0;a<r.length;a++){if(u=r[a],h=u.instance,S=u.currentTarget,u=u.listener,h!==o&&i.isPropagationStopped())break e;kl(i,u,S),o=h}}}if($r)throw e=ho,$r=!1,ho=null,e}function ke(e,t){var n=t[Ho];n===void 0&&(n=t[Ho]=new Set);var r=e+"__bubble";n.has(r)||(Sl(t,e,2,!1),n.add(r))}function Fo(e,t,n){var r=0;t&&(r|=4),Sl(n,e,r,t)}var ii="_reactListening"+Math.random().toString(36).slice(2);function hr(e){if(!e[ii]){e[ii]=!0,p.forEach(function(n){n!=="selectionchange"&&(Wd.has(n)||Fo(n,!1,e),Fo(n,!0,e))});var t=e.nodeType===9?e:e.ownerDocument;t===null||t[ii]||(t[ii]=!0,Fo("selectionchange",!1,t))}}function Sl(e,t,n,r){switch(Va(t)){case 1:var i=rd;break;case 4:i=id;break;default:i=ko}n=i.bind(null,t,n,e),i=void 0,!po||t!=="touchstart"&&t!=="touchmove"&&t!=="wheel"||(i=!0),r?i!==void 0?e.addEventListener(t,n,{capture:!0,passive:i}):e.addEventListener(t,n,!0):i!==void 0?e.addEventListener(t,n,{passive:i}):e.addEventListener(t,n,!1)}function jo(e,t,n,r,i){var o=r;if((t&1)===0&&(t&2)===0&&r!==null)e:for(;;){if(r===null)return;var a=r.tag;if(a===3||a===4){var u=r.stateNode.containerInfo;if(u===i||u.nodeType===8&&u.parentNode===i)break;if(a===4)for(a=r.return;a!==null;){var h=a.tag;if((h===3||h===4)&&(h=a.stateNode.containerInfo,h===i||h.nodeType===8&&h.parentNode===i))return;a=a.return}for(;u!==null;){if(a=nn(u),a===null)return;if(h=a.tag,h===5||h===6){r=o=a;continue e}u=u.parentNode}}r=r.return}Ea(function(){var S=o,C=lo(n),P=[];e:{var E=vl.get(e);if(E!==void 0){var F=bo,U=e;switch(e){case"keypress":if(Jr(n)===0)break e;case"keydown":case"keyup":F=wd;break;case"focusin":U="focus",F=_o;break;case"focusout":U="blur",F=_o;break;case"beforeblur":case"afterblur":F=_o;break;case"click":if(n.button===2)break e;case"auxclick":case"dblclick":case"mousedown":case"mousemove":case"mouseup":case"mouseout":case"mouseover":case"contextmenu":F=Qa;break;case"drag":case"dragend":case"dragenter":case"dragexit":case"dragleave":case"dragover":case"dragstart":case"drop":F=ad;break;case"touchcancel":case"touchend":case"touchmove":case"touchstart":F=Sd;break;case fl:case ml:case gl:F=ud;break;case yl:F=Ad;break;case"scroll":F=od;break;case"wheel":F=_d;break;case"copy":case"cut":case"paste":F=pd;break;case"gotpointercapture":case"lostpointercapture":case"pointercancel":case"pointerdown":case"pointermove":case"pointerout":case"pointerover":case"pointerup":F=Xa}var W=(t&4)!==0,De=!W&&e==="scroll",y=W?E!==null?E+"Capture":null:E;W=[];for(var f=S,w;f!==null;){w=f;var D=w.stateNode;if(w.tag===5&&D!==null&&(w=D,y!==null&&(D=Kn(f,y),D!=null&&W.push(fr(f,D,w)))),De)break;f=f.return}0<W.length&&(E=new F(E,U,null,n,C),P.push({event:E,listeners:W}))}}if((t&7)===0){e:{if(E=e==="mouseover"||e==="pointerover",F=e==="mouseout"||e==="pointerout",E&&n!==ao&&(U=n.relatedTarget||n.fromElement)&&(nn(U)||U[_t]))break e;if((F||E)&&(E=C.window===C?C:(E=C.ownerDocument)?E.defaultView||E.parentWindow:window,F?(U=n.relatedTarget||n.toElement,F=S,U=U?nn(U):null,U!==null&&(De=tn(U),U!==De||U.tag!==5&&U.tag!==6)&&(U=null)):(F=null,U=S),F!==U)){if(W=Qa,D="onMouseLeave",y="onMouseEnter",f="mouse",(e==="pointerout"||e==="pointerover")&&(W=Xa,D="onPointerLeave",y="onPointerEnter",f="pointer"),De=F==null?E:_n(F),w=U==null?E:_n(U),E=new W(D,f+"leave",F,n,C),E.target=De,E.relatedTarget=w,D=null,nn(C)===S&&(W=new W(y,f+"enter",U,n,C),W.target=w,W.relatedTarget=De,D=W),De=D,F&&U)t:{for(W=F,y=U,f=0,w=W;w;w=An(w))f++;for(w=0,D=y;D;D=An(D))w++;for(;0<f-w;)W=An(W),f--;for(;0<w-f;)y=An(y),w--;for(;f--;){if(W===y||y!==null&&W===y.alternate)break t;W=An(W),y=An(y)}W=null}else W=null;F!==null&&bl(P,E,F,W,!1),U!==null&&De!==null&&bl(P,De,U,W,!0)}}e:{if(E=S?_n(S):window,F=E.nodeName&&E.nodeName.toLowerCase(),F==="select"||F==="input"&&E.type==="file")var G=Rd;else if(nl(E))if(il)G=Fd;else{G=Ld;var X=Nd}else(F=E.nodeName)&&F.toLowerCase()==="input"&&(E.type==="checkbox"||E.type==="radio")&&(G=Od);if(G&&(G=G(e,S))){rl(P,G,n,C);break e}X&&X(e,E,S),e==="focusout"&&(X=E._wrapperState)&&X.controlled&&E.type==="number"&&no(E,"number",E.value)}switch(X=S?_n(S):window,e){case"focusin":(nl(X)||X.contentEditable==="true")&&(Sn=X,Do=S,dr=null);break;case"focusout":dr=Do=Sn=null;break;case"mousedown":Ro=!0;break;case"contextmenu":case"mouseup":case"dragend":Ro=!1,pl(P,n,C);break;case"selectionchange":if(Bd)break;case"keydown":case"keyup":pl(P,n,C)}var Y;if(Mo)e:{switch(e){case"compositionstart":var ee="onCompositionStart";break e;case"compositionend":ee="onCompositionEnd";break e;case"compositionupdate":ee="onCompositionUpdate";break e}ee=void 0}else xn?el(e,n)&&(ee="onCompositionEnd"):e==="keydown"&&n.keyCode===229&&(ee="onCompositionStart");ee&&(Ya&&n.locale!=="ko"&&(xn||ee!=="onCompositionStart"?ee==="onCompositionEnd"&&xn&&(Y=Ga()):(Bt=C,So="value"in Bt?Bt.value:Bt.textContent,xn=!0)),X=oi(S,ee),0<X.length&&(ee=new Ka(ee,e,null,n,C),P.push({event:ee,listeners:X}),Y?ee.data=Y:(Y=tl(n),Y!==null&&(ee.data=Y)))),(Y=Md?Cd(e,n):Pd(e,n))&&(S=oi(S,"onBeforeInput"),0<S.length&&(C=new Ka("onBeforeInput","beforeinput",null,n,C),P.push({event:C,listeners:S}),C.data=Y))}xl(P,t)})}function fr(e,t,n){return{instance:e,listener:t,currentTarget:n}}function oi(e,t){for(var n=t+"Capture",r=[];e!==null;){var i=e,o=i.stateNode;i.tag===5&&o!==null&&(i=o,o=Kn(e,n),o!=null&&r.unshift(fr(e,o,i)),o=Kn(e,t),o!=null&&r.push(fr(e,o,i))),e=e.return}return r}function An(e){if(e===null)return null;do e=e.return;while(e&&e.tag!==5);return e||null}function bl(e,t,n,r,i){for(var o=t._reactName,a=[];n!==null&&n!==r;){var u=n,h=u.alternate,S=u.stateNode;if(h!==null&&h===r)break;u.tag===5&&S!==null&&(u=S,i?(h=Kn(n,o),h!=null&&a.unshift(fr(n,h,u))):i||(h=Kn(n,o),h!=null&&a.push(fr(n,h,u)))),n=n.return}a.length!==0&&e.push({event:t,listeners:a})}var Hd=/\r\n?/g,Vd=/\u0000|\uFFFD/g;function Al(e){return(typeof e=="string"?e:""+e).replace(Hd,`
`).replace(Vd,"")}function si(e,t,n){if(t=Al(t),Al(e)!==t&&n)throw Error(l(425))}function ai(){}var zo=null,Bo=null;function $o(e,t){return e==="textarea"||e==="noscript"||typeof t.children=="string"||typeof t.children=="number"||typeof t.dangerouslySetInnerHTML=="object"&&t.dangerouslySetInnerHTML!==null&&t.dangerouslySetInnerHTML.__html!=null}var Uo=typeof setTimeout=="function"?setTimeout:void 0,Gd=typeof clearTimeout=="function"?clearTimeout:void 0,Il=typeof Promise=="function"?Promise:void 0,qd=typeof queueMicrotask=="function"?queueMicrotask:typeof Il<"u"?function(e){return Il.resolve(null).then(e).catch(Qd)}:Uo;function Qd(e){setTimeout(function(){throw e})}function Wo(e,t){var n=t,r=0;do{var i=n.nextSibling;if(e.removeChild(n),i&&i.nodeType===8)if(n=i.data,n==="/$"){if(r===0){e.removeChild(i),ir(t);return}r--}else n!=="$"&&n!=="$?"&&n!=="$!"||r++;n=i}while(n);ir(t)}function Ut(e){for(;e!=null;e=e.nextSibling){var t=e.nodeType;if(t===1||t===3)break;if(t===8){if(t=e.data,t==="$"||t==="$!"||t==="$?")break;if(t==="/$")return null}}return e}function _l(e){e=e.previousSibling;for(var t=0;e;){if(e.nodeType===8){var n=e.data;if(n==="$"||n==="$!"||n==="$?"){if(t===0)return e;t--}else n==="/$"&&t++}e=e.previousSibling}return null}var In=Math.random().toString(36).slice(2),xt="__reactFiber$"+In,mr="__reactProps$"+In,_t="__reactContainer$"+In,Ho="__reactEvents$"+In,Kd="__reactListeners$"+In,Xd="__reactHandles$"+In;function nn(e){var t=e[xt];if(t)return t;for(var n=e.parentNode;n;){if(t=n[_t]||n[xt]){if(n=t.alternate,t.child!==null||n!==null&&n.child!==null)for(e=_l(e);e!==null;){if(n=e[xt])return n;e=_l(e)}return t}e=n,n=e.parentNode}return null}function gr(e){return e=e[xt]||e[_t],!e||e.tag!==5&&e.tag!==6&&e.tag!==13&&e.tag!==3?null:e}function _n(e){if(e.tag===5||e.tag===6)return e.stateNode;throw Error(l(33))}function li(e){return e[mr]||null}var Vo=[],En=-1;function Wt(e){return{current:e}}function xe(e){0>En||(e.current=Vo[En],Vo[En]=null,En--)}function we(e,t){En++,Vo[En]=e.current,e.current=t}var Ht={},$e=Wt(Ht),qe=Wt(!1),rn=Ht;function Mn(e,t){var n=e.type.contextTypes;if(!n)return Ht;var r=e.stateNode;if(r&&r.__reactInternalMemoizedUnmaskedChildContext===t)return r.__reactInternalMemoizedMaskedChildContext;var i={},o;for(o in n)i[o]=t[o];return r&&(e=e.stateNode,e.__reactInternalMemoizedUnmaskedChildContext=t,e.__reactInternalMemoizedMaskedChildContext=i),i}function Qe(e){return e=e.childContextTypes,e!=null}function ci(){xe(qe),xe($e)}function El(e,t,n){if($e.current!==Ht)throw Error(l(168));we($e,t),we(qe,n)}function Ml(e,t,n){var r=e.stateNode;if(t=t.childContextTypes,typeof r.getChildContext!="function")return n;r=r.getChildContext();for(var i in r)if(!(i in t))throw Error(l(108,ve(e)||"Unknown",i));return B({},n,r)}function ui(e){return e=(e=e.stateNode)&&e.__reactInternalMemoizedMergedChildContext||Ht,rn=$e.current,we($e,e),we(qe,qe.current),!0}function Cl(e,t,n){var r=e.stateNode;if(!r)throw Error(l(169));n?(e=Ml(e,t,rn),r.__reactInternalMemoizedMergedChildContext=e,xe(qe),xe($e),we($e,e)):xe(qe),we(qe,n)}var Et=null,di=!1,Go=!1;function Pl(e){Et===null?Et=[e]:Et.push(e)}function Yd(e){di=!0,Pl(e)}function Vt(){if(!Go&&Et!==null){Go=!0;var e=0,t=me;try{var n=Et;for(me=1;e<n.length;e++){var r=n[e];do r=r(!0);while(r!==null)}Et=null,di=!1}catch(i){throw Et!==null&&(Et=Et.slice(e+1)),Da(fo,Vt),i}finally{me=t,Go=!1}}return null}var Cn=[],Pn=0,pi=null,hi=0,it=[],ot=0,on=null,Mt=1,Ct="";function sn(e,t){Cn[Pn++]=hi,Cn[Pn++]=pi,pi=e,hi=t}function Tl(e,t,n){it[ot++]=Mt,it[ot++]=Ct,it[ot++]=on,on=e;var r=Mt;e=Ct;var i=32-ut(r)-1;r&=~(1<<i),n+=1;var o=32-ut(t)+i;if(30<o){var a=i-i%5;o=(r&(1<<a)-1).toString(32),r>>=a,i-=a,Mt=1<<32-ut(t)+i|n<<i|r,Ct=o+e}else Mt=1<<o|n<<i|r,Ct=e}function qo(e){e.return!==null&&(sn(e,1),Tl(e,1,0))}function Qo(e){for(;e===pi;)pi=Cn[--Pn],Cn[Pn]=null,hi=Cn[--Pn],Cn[Pn]=null;for(;e===on;)on=it[--ot],it[ot]=null,Ct=it[--ot],it[ot]=null,Mt=it[--ot],it[ot]=null}var tt=null,nt=null,be=!1,pt=null;function Dl(e,t){var n=ct(5,null,null,0);n.elementType="DELETED",n.stateNode=t,n.return=e,t=e.deletions,t===null?(e.deletions=[n],e.flags|=16):t.push(n)}function Rl(e,t){switch(e.tag){case 5:var n=e.type;return t=t.nodeType!==1||n.toLowerCase()!==t.nodeName.toLowerCase()?null:t,t!==null?(e.stateNode=t,tt=e,nt=Ut(t.firstChild),!0):!1;case 6:return t=e.pendingProps===""||t.nodeType!==3?null:t,t!==null?(e.stateNode=t,tt=e,nt=null,!0):!1;case 13:return t=t.nodeType!==8?null:t,t!==null?(n=on!==null?{id:Mt,overflow:Ct}:null,e.memoizedState={dehydrated:t,treeContext:n,retryLane:1073741824},n=ct(18,null,null,0),n.stateNode=t,n.return=e,e.child=n,tt=e,nt=null,!0):!1;default:return!1}}function Ko(e){return(e.mode&1)!==0&&(e.flags&128)===0}function Xo(e){if(be){var t=nt;if(t){var n=t;if(!Rl(e,t)){if(Ko(e))throw Error(l(418));t=Ut(n.nextSibling);var r=tt;t&&Rl(e,t)?Dl(r,n):(e.flags=e.flags&-4097|2,be=!1,tt=e)}}else{if(Ko(e))throw Error(l(418));e.flags=e.flags&-4097|2,be=!1,tt=e}}}function Nl(e){for(e=e.return;e!==null&&e.tag!==5&&e.tag!==3&&e.tag!==13;)e=e.return;tt=e}function fi(e){if(e!==tt)return!1;if(!be)return Nl(e),be=!0,!1;var t;if((t=e.tag!==3)&&!(t=e.tag!==5)&&(t=e.type,t=t!=="head"&&t!=="body"&&!$o(e.type,e.memoizedProps)),t&&(t=nt)){if(Ko(e))throw Ll(),Error(l(418));for(;t;)Dl(e,t),t=Ut(t.nextSibling)}if(Nl(e),e.tag===13){if(e=e.memoizedState,e=e!==null?e.dehydrated:null,!e)throw Error(l(317));e:{for(e=e.nextSibling,t=0;e;){if(e.nodeType===8){var n=e.data;if(n==="/$"){if(t===0){nt=Ut(e.nextSibling);break e}t--}else n!=="$"&&n!=="$!"&&n!=="$?"||t++}e=e.nextSibling}nt=null}}else nt=tt?Ut(e.stateNode.nextSibling):null;return!0}function Ll(){for(var e=nt;e;)e=Ut(e.nextSibling)}function Tn(){nt=tt=null,be=!1}function Yo(e){pt===null?pt=[e]:pt.push(e)}var Jd=se.ReactCurrentBatchConfig;function yr(e,t,n){if(e=n.ref,e!==null&&typeof e!="function"&&typeof e!="object"){if(n._owner){if(n=n._owner,n){if(n.tag!==1)throw Error(l(309));var r=n.stateNode}if(!r)throw Error(l(147,e));var i=r,o=""+e;return t!==null&&t.ref!==null&&typeof t.ref=="function"&&t.ref._stringRef===o?t.ref:(t=function(a){var u=i.refs;a===null?delete u[o]:u[o]=a},t._stringRef=o,t)}if(typeof e!="string")throw Error(l(284));if(!n._owner)throw Error(l(290,e))}return e}function mi(e,t){throw e=Object.prototype.toString.call(t),Error(l(31,e==="[object Object]"?"object with keys {"+Object.keys(t).join(", ")+"}":e))}function Ol(e){var t=e._init;return t(e._payload)}function Fl(e){function t(y,f){if(e){var w=y.deletions;w===null?(y.deletions=[f],y.flags|=16):w.push(f)}}function n(y,f){if(!e)return null;for(;f!==null;)t(y,f),f=f.sibling;return null}function r(y,f){for(y=new Map;f!==null;)f.key!==null?y.set(f.key,f):y.set(f.index,f),f=f.sibling;return y}function i(y,f){return y=Zt(y,f),y.index=0,y.sibling=null,y}function o(y,f,w){return y.index=w,e?(w=y.alternate,w!==null?(w=w.index,w<f?(y.flags|=2,f):w):(y.flags|=2,f)):(y.flags|=1048576,f)}function a(y){return e&&y.alternate===null&&(y.flags|=2),y}function u(y,f,w,D){return f===null||f.tag!==6?(f=Us(w,y.mode,D),f.return=y,f):(f=i(f,w),f.return=y,f)}function h(y,f,w,D){var G=w.type;return G===Q?C(y,f,w.props.children,D,w.key):f!==null&&(f.elementType===G||typeof G=="object"&&G!==null&&G.$$typeof===Pe&&Ol(G)===f.type)?(D=i(f,w.props),D.ref=yr(y,f,w),D.return=y,D):(D=zi(w.type,w.key,w.props,null,y.mode,D),D.ref=yr(y,f,w),D.return=y,D)}function S(y,f,w,D){return f===null||f.tag!==4||f.stateNode.containerInfo!==w.containerInfo||f.stateNode.implementation!==w.implementation?(f=Ws(w,y.mode,D),f.return=y,f):(f=i(f,w.children||[]),f.return=y,f)}function C(y,f,w,D,G){return f===null||f.tag!==7?(f=fn(w,y.mode,D,G),f.return=y,f):(f=i(f,w),f.return=y,f)}function P(y,f,w){if(typeof f=="string"&&f!==""||typeof f=="number")return f=Us(""+f,y.mode,w),f.return=y,f;if(typeof f=="object"&&f!==null){switch(f.$$typeof){case O:return w=zi(f.type,f.key,f.props,null,y.mode,w),w.ref=yr(y,null,f),w.return=y,w;case $:return f=Ws(f,y.mode,w),f.return=y,f;case Pe:var D=f._init;return P(y,D(f._payload),w)}if(Gn(f)||K(f))return f=fn(f,y.mode,w,null),f.return=y,f;mi(y,f)}return null}function E(y,f,w,D){var G=f!==null?f.key:null;if(typeof w=="string"&&w!==""||typeof w=="number")return G!==null?null:u(y,f,""+w,D);if(typeof w=="object"&&w!==null){switch(w.$$typeof){case O:return w.key===G?h(y,f,w,D):null;case $:return w.key===G?S(y,f,w,D):null;case Pe:return G=w._init,E(y,f,G(w._payload),D)}if(Gn(w)||K(w))return G!==null?null:C(y,f,w,D,null);mi(y,w)}return null}function F(y,f,w,D,G){if(typeof D=="string"&&D!==""||typeof D=="number")return y=y.get(w)||null,u(f,y,""+D,G);if(typeof D=="object"&&D!==null){switch(D.$$typeof){case O:return y=y.get(D.key===null?w:D.key)||null,h(f,y,D,G);case $:return y=y.get(D.key===null?w:D.key)||null,S(f,y,D,G);case Pe:var X=D._init;return F(y,f,w,X(D._payload),G)}if(Gn(D)||K(D))return y=y.get(w)||null,C(f,y,D,G,null);mi(f,D)}return null}function U(y,f,w,D){for(var G=null,X=null,Y=f,ee=f=0,je=null;Y!==null&&ee<w.length;ee++){Y.index>ee?(je=Y,Y=null):je=Y.sibling;var pe=E(y,Y,w[ee],D);if(pe===null){Y===null&&(Y=je);break}e&&Y&&pe.alternate===null&&t(y,Y),f=o(pe,f,ee),X===null?G=pe:X.sibling=pe,X=pe,Y=je}if(ee===w.length)return n(y,Y),be&&sn(y,ee),G;if(Y===null){for(;ee<w.length;ee++)Y=P(y,w[ee],D),Y!==null&&(f=o(Y,f,ee),X===null?G=Y:X.sibling=Y,X=Y);return be&&sn(y,ee),G}for(Y=r(y,Y);ee<w.length;ee++)je=F(Y,y,ee,w[ee],D),je!==null&&(e&&je.alternate!==null&&Y.delete(je.key===null?ee:je.key),f=o(je,f,ee),X===null?G=je:X.sibling=je,X=je);return e&&Y.forEach(function(en){return t(y,en)}),be&&sn(y,ee),G}function W(y,f,w,D){var G=K(w);if(typeof G!="function")throw Error(l(150));if(w=G.call(w),w==null)throw Error(l(151));for(var X=G=null,Y=f,ee=f=0,je=null,pe=w.next();Y!==null&&!pe.done;ee++,pe=w.next()){Y.index>ee?(je=Y,Y=null):je=Y.sibling;var en=E(y,Y,pe.value,D);if(en===null){Y===null&&(Y=je);break}e&&Y&&en.alternate===null&&t(y,Y),f=o(en,f,ee),X===null?G=en:X.sibling=en,X=en,Y=je}if(pe.done)return n(y,Y),be&&sn(y,ee),G;if(Y===null){for(;!pe.done;ee++,pe=w.next())pe=P(y,pe.value,D),pe!==null&&(f=o(pe,f,ee),X===null?G=pe:X.sibling=pe,X=pe);return be&&sn(y,ee),G}for(Y=r(y,Y);!pe.done;ee++,pe=w.next())pe=F(Y,y,ee,pe.value,D),pe!==null&&(e&&pe.alternate!==null&&Y.delete(pe.key===null?ee:pe.key),f=o(pe,f,ee),X===null?G=pe:X.sibling=pe,X=pe);return e&&Y.forEach(function(Tp){return t(y,Tp)}),be&&sn(y,ee),G}function De(y,f,w,D){if(typeof w=="object"&&w!==null&&w.type===Q&&w.key===null&&(w=w.props.children),typeof w=="object"&&w!==null){switch(w.$$typeof){case O:e:{for(var G=w.key,X=f;X!==null;){if(X.key===G){if(G=w.type,G===Q){if(X.tag===7){n(y,X.sibling),f=i(X,w.props.children),f.return=y,y=f;break e}}else if(X.elementType===G||typeof G=="object"&&G!==null&&G.$$typeof===Pe&&Ol(G)===X.type){n(y,X.sibling),f=i(X,w.props),f.ref=yr(y,X,w),f.return=y,y=f;break e}n(y,X);break}else t(y,X);X=X.sibling}w.type===Q?(f=fn(w.props.children,y.mode,D,w.key),f.return=y,y=f):(D=zi(w.type,w.key,w.props,null,y.mode,D),D.ref=yr(y,f,w),D.return=y,y=D)}return a(y);case $:e:{for(X=w.key;f!==null;){if(f.key===X)if(f.tag===4&&f.stateNode.containerInfo===w.containerInfo&&f.stateNode.implementation===w.implementation){n(y,f.sibling),f=i(f,w.children||[]),f.return=y,y=f;break e}else{n(y,f);break}else t(y,f);f=f.sibling}f=Ws(w,y.mode,D),f.return=y,y=f}return a(y);case Pe:return X=w._init,De(y,f,X(w._payload),D)}if(Gn(w))return U(y,f,w,D);if(K(w))return W(y,f,w,D);mi(y,w)}return typeof w=="string"&&w!==""||typeof w=="number"?(w=""+w,f!==null&&f.tag===6?(n(y,f.sibling),f=i(f,w),f.return=y,y=f):(n(y,f),f=Us(w,y.mode,D),f.return=y,y=f),a(y)):n(y,f)}return De}var Dn=Fl(!0),jl=Fl(!1),gi=Wt(null),yi=null,Rn=null,Jo=null;function Zo(){Jo=Rn=yi=null}function es(e){var t=gi.current;xe(gi),e._currentValue=t}function ts(e,t,n){for(;e!==null;){var r=e.alternate;if((e.childLanes&t)!==t?(e.childLanes|=t,r!==null&&(r.childLanes|=t)):r!==null&&(r.childLanes&t)!==t&&(r.childLanes|=t),e===n)break;e=e.return}}function Nn(e,t){yi=e,Jo=Rn=null,e=e.dependencies,e!==null&&e.firstContext!==null&&((e.lanes&t)!==0&&(Ke=!0),e.firstContext=null)}function st(e){var t=e._currentValue;if(Jo!==e)if(e={context:e,memoizedValue:t,next:null},Rn===null){if(yi===null)throw Error(l(308));Rn=e,yi.dependencies={lanes:0,firstContext:e}}else Rn=Rn.next=e;return t}var an=null;function ns(e){an===null?an=[e]:an.push(e)}function zl(e,t,n,r){var i=t.interleaved;return i===null?(n.next=n,ns(t)):(n.next=i.next,i.next=n),t.interleaved=n,Pt(e,r)}function Pt(e,t){e.lanes|=t;var n=e.alternate;for(n!==null&&(n.lanes|=t),n=e,e=e.return;e!==null;)e.childLanes|=t,n=e.alternate,n!==null&&(n.childLanes|=t),n=e,e=e.return;return n.tag===3?n.stateNode:null}var Gt=!1;function rs(e){e.updateQueue={baseState:e.memoizedState,firstBaseUpdate:null,lastBaseUpdate:null,shared:{pending:null,interleaved:null,lanes:0},effects:null}}function Bl(e,t){e=e.updateQueue,t.updateQueue===e&&(t.updateQueue={baseState:e.baseState,firstBaseUpdate:e.firstBaseUpdate,lastBaseUpdate:e.lastBaseUpdate,shared:e.shared,effects:e.effects})}function Tt(e,t){return{eventTime:e,lane:t,tag:0,payload:null,callback:null,next:null}}function qt(e,t,n){var r=e.updateQueue;if(r===null)return null;if(r=r.shared,(ce&2)!==0){var i=r.pending;return i===null?t.next=t:(t.next=i.next,i.next=t),r.pending=t,Pt(e,n)}return i=r.interleaved,i===null?(t.next=t,ns(r)):(t.next=i.next,i.next=t),r.interleaved=t,Pt(e,n)}function vi(e,t,n){if(t=t.updateQueue,t!==null&&(t=t.shared,(n&4194240)!==0)){var r=t.lanes;r&=e.pendingLanes,n|=r,t.lanes=n,yo(e,n)}}function $l(e,t){var n=e.updateQueue,r=e.alternate;if(r!==null&&(r=r.updateQueue,n===r)){var i=null,o=null;if(n=n.firstBaseUpdate,n!==null){do{var a={eventTime:n.eventTime,lane:n.lane,tag:n.tag,payload:n.payload,callback:n.callback,next:null};o===null?i=o=a:o=o.next=a,n=n.next}while(n!==null);o===null?i=o=t:o=o.next=t}else i=o=t;n={baseState:r.baseState,firstBaseUpdate:i,lastBaseUpdate:o,shared:r.shared,effects:r.effects},e.updateQueue=n;return}e=n.lastBaseUpdate,e===null?n.firstBaseUpdate=t:e.next=t,n.lastBaseUpdate=t}function wi(e,t,n,r){var i=e.updateQueue;Gt=!1;var o=i.firstBaseUpdate,a=i.lastBaseUpdate,u=i.shared.pending;if(u!==null){i.shared.pending=null;var h=u,S=h.next;h.next=null,a===null?o=S:a.next=S,a=h;var C=e.alternate;C!==null&&(C=C.updateQueue,u=C.lastBaseUpdate,u!==a&&(u===null?C.firstBaseUpdate=S:u.next=S,C.lastBaseUpdate=h))}if(o!==null){var P=i.baseState;a=0,C=S=h=null,u=o;do{var E=u.lane,F=u.eventTime;if((r&E)===E){C!==null&&(C=C.next={eventTime:F,lane:0,tag:u.tag,payload:u.payload,callback:u.callback,next:null});e:{var U=e,W=u;switch(E=t,F=n,W.tag){case 1:if(U=W.payload,typeof U=="function"){P=U.call(F,P,E);break e}P=U;break e;case 3:U.flags=U.flags&-65537|128;case 0:if(U=W.payload,E=typeof U=="function"?U.call(F,P,E):U,E==null)break e;P=B({},P,E);break e;case 2:Gt=!0}}u.callback!==null&&u.lane!==0&&(e.flags|=64,E=i.effects,E===null?i.effects=[u]:E.push(u))}else F={eventTime:F,lane:E,tag:u.tag,payload:u.payload,callback:u.callback,next:null},C===null?(S=C=F,h=P):C=C.next=F,a|=E;if(u=u.next,u===null){if(u=i.shared.pending,u===null)break;E=u,u=E.next,E.next=null,i.lastBaseUpdate=E,i.shared.pending=null}}while(!0);if(C===null&&(h=P),i.baseState=h,i.firstBaseUpdate=S,i.lastBaseUpdate=C,t=i.shared.interleaved,t!==null){i=t;do a|=i.lane,i=i.next;while(i!==t)}else o===null&&(i.shared.lanes=0);un|=a,e.lanes=a,e.memoizedState=P}}function Ul(e,t,n){if(e=t.effects,t.effects=null,e!==null)for(t=0;t<e.length;t++){var r=e[t],i=r.callback;if(i!==null){if(r.callback=null,r=n,typeof i!="function")throw Error(l(191,i));i.call(r)}}}var vr={},St=Wt(vr),wr=Wt(vr),kr=Wt(vr);function ln(e){if(e===vr)throw Error(l(174));return e}function is(e,t){switch(we(kr,t),we(wr,e),we(St,vr),e=t.nodeType,e){case 9:case 11:t=(t=t.documentElement)?t.namespaceURI:io(null,"");break;default:e=e===8?t.parentNode:t,t=e.namespaceURI||null,e=e.tagName,t=io(t,e)}xe(St),we(St,t)}function Ln(){xe(St),xe(wr),xe(kr)}function Wl(e){ln(kr.current);var t=ln(St.current),n=io(t,e.type);t!==n&&(we(wr,e),we(St,n))}function os(e){wr.current===e&&(xe(St),xe(wr))}var _e=Wt(0);function ki(e){for(var t=e;t!==null;){if(t.tag===13){var n=t.memoizedState;if(n!==null&&(n=n.dehydrated,n===null||n.data==="$?"||n.data==="$!"))return t}else if(t.tag===19&&t.memoizedProps.revealOrder!==void 0){if((t.flags&128)!==0)return t}else if(t.child!==null){t.child.return=t,t=t.child;continue}if(t===e)break;for(;t.sibling===null;){if(t.return===null||t.return===e)return null;t=t.return}t.sibling.return=t.return,t=t.sibling}return null}var ss=[];function as(){for(var e=0;e<ss.length;e++)ss[e]._workInProgressVersionPrimary=null;ss.length=0}var xi=se.ReactCurrentDispatcher,ls=se.ReactCurrentBatchConfig,cn=0,Ee=null,Ne=null,Oe=null,Si=!1,xr=!1,Sr=0,Zd=0;function Ue(){throw Error(l(321))}function cs(e,t){if(t===null)return!1;for(var n=0;n<t.length&&n<e.length;n++)if(!dt(e[n],t[n]))return!1;return!0}function us(e,t,n,r,i,o){if(cn=o,Ee=t,t.memoizedState=null,t.updateQueue=null,t.lanes=0,xi.current=e===null||e.memoizedState===null?rp:ip,e=n(r,i),xr){o=0;do{if(xr=!1,Sr=0,25<=o)throw Error(l(301));o+=1,Oe=Ne=null,t.updateQueue=null,xi.current=op,e=n(r,i)}while(xr)}if(xi.current=Ii,t=Ne!==null&&Ne.next!==null,cn=0,Oe=Ne=Ee=null,Si=!1,t)throw Error(l(300));return e}function ds(){var e=Sr!==0;return Sr=0,e}function bt(){var e={memoizedState:null,baseState:null,baseQueue:null,queue:null,next:null};return Oe===null?Ee.memoizedState=Oe=e:Oe=Oe.next=e,Oe}function at(){if(Ne===null){var e=Ee.alternate;e=e!==null?e.memoizedState:null}else e=Ne.next;var t=Oe===null?Ee.memoizedState:Oe.next;if(t!==null)Oe=t,Ne=e;else{if(e===null)throw Error(l(310));Ne=e,e={memoizedState:Ne.memoizedState,baseState:Ne.baseState,baseQueue:Ne.baseQueue,queue:Ne.queue,next:null},Oe===null?Ee.memoizedState=Oe=e:Oe=Oe.next=e}return Oe}function br(e,t){return typeof t=="function"?t(e):t}function ps(e){var t=at(),n=t.queue;if(n===null)throw Error(l(311));n.lastRenderedReducer=e;var r=Ne,i=r.baseQueue,o=n.pending;if(o!==null){if(i!==null){var a=i.next;i.next=o.next,o.next=a}r.baseQueue=i=o,n.pending=null}if(i!==null){o=i.next,r=r.baseState;var u=a=null,h=null,S=o;do{var C=S.lane;if((cn&C)===C)h!==null&&(h=h.next={lane:0,action:S.action,hasEagerState:S.hasEagerState,eagerState:S.eagerState,next:null}),r=S.hasEagerState?S.eagerState:e(r,S.action);else{var P={lane:C,action:S.action,hasEagerState:S.hasEagerState,eagerState:S.eagerState,next:null};h===null?(u=h=P,a=r):h=h.next=P,Ee.lanes|=C,un|=C}S=S.next}while(S!==null&&S!==o);h===null?a=r:h.next=u,dt(r,t.memoizedState)||(Ke=!0),t.memoizedState=r,t.baseState=a,t.baseQueue=h,n.lastRenderedState=r}if(e=n.interleaved,e!==null){i=e;do o=i.lane,Ee.lanes|=o,un|=o,i=i.next;while(i!==e)}else i===null&&(n.lanes=0);return[t.memoizedState,n.dispatch]}function hs(e){var t=at(),n=t.queue;if(n===null)throw Error(l(311));n.lastRenderedReducer=e;var r=n.dispatch,i=n.pending,o=t.memoizedState;if(i!==null){n.pending=null;var a=i=i.next;do o=e(o,a.action),a=a.next;while(a!==i);dt(o,t.memoizedState)||(Ke=!0),t.memoizedState=o,t.baseQueue===null&&(t.baseState=o),n.lastRenderedState=o}return[o,r]}function Hl(){}function Vl(e,t){var n=Ee,r=at(),i=t(),o=!dt(r.memoizedState,i);if(o&&(r.memoizedState=i,Ke=!0),r=r.queue,fs(Ql.bind(null,n,r,e),[e]),r.getSnapshot!==t||o||Oe!==null&&Oe.memoizedState.tag&1){if(n.flags|=2048,Ar(9,ql.bind(null,n,r,i,t),void 0,null),Fe===null)throw Error(l(349));(cn&30)!==0||Gl(n,t,i)}return i}function Gl(e,t,n){e.flags|=16384,e={getSnapshot:t,value:n},t=Ee.updateQueue,t===null?(t={lastEffect:null,stores:null},Ee.updateQueue=t,t.stores=[e]):(n=t.stores,n===null?t.stores=[e]:n.push(e))}function ql(e,t,n,r){t.value=n,t.getSnapshot=r,Kl(t)&&Xl(e)}function Ql(e,t,n){return n(function(){Kl(t)&&Xl(e)})}function Kl(e){var t=e.getSnapshot;e=e.value;try{var n=t();return!dt(e,n)}catch{return!0}}function Xl(e){var t=Pt(e,1);t!==null&&gt(t,e,1,-1)}function Yl(e){var t=bt();return typeof e=="function"&&(e=e()),t.memoizedState=t.baseState=e,e={pending:null,interleaved:null,lanes:0,dispatch:null,lastRenderedReducer:br,lastRenderedState:e},t.queue=e,e=e.dispatch=np.bind(null,Ee,e),[t.memoizedState,e]}function Ar(e,t,n,r){return e={tag:e,create:t,destroy:n,deps:r,next:null},t=Ee.updateQueue,t===null?(t={lastEffect:null,stores:null},Ee.updateQueue=t,t.lastEffect=e.next=e):(n=t.lastEffect,n===null?t.lastEffect=e.next=e:(r=n.next,n.next=e,e.next=r,t.lastEffect=e)),e}function Jl(){return at().memoizedState}function bi(e,t,n,r){var i=bt();Ee.flags|=e,i.memoizedState=Ar(1|t,n,void 0,r===void 0?null:r)}function Ai(e,t,n,r){var i=at();r=r===void 0?null:r;var o=void 0;if(Ne!==null){var a=Ne.memoizedState;if(o=a.destroy,r!==null&&cs(r,a.deps)){i.memoizedState=Ar(t,n,o,r);return}}Ee.flags|=e,i.memoizedState=Ar(1|t,n,o,r)}function Zl(e,t){return bi(8390656,8,e,t)}function fs(e,t){return Ai(2048,8,e,t)}function ec(e,t){return Ai(4,2,e,t)}function tc(e,t){return Ai(4,4,e,t)}function nc(e,t){if(typeof t=="function")return e=e(),t(e),function(){t(null)};if(t!=null)return e=e(),t.current=e,function(){t.current=null}}function rc(e,t,n){return n=n!=null?n.concat([e]):null,Ai(4,4,nc.bind(null,t,e),n)}function ms(){}function ic(e,t){var n=at();t=t===void 0?null:t;var r=n.memoizedState;return r!==null&&t!==null&&cs(t,r[1])?r[0]:(n.memoizedState=[e,t],e)}function oc(e,t){var n=at();t=t===void 0?null:t;var r=n.memoizedState;return r!==null&&t!==null&&cs(t,r[1])?r[0]:(e=e(),n.memoizedState=[e,t],e)}function sc(e,t,n){return(cn&21)===0?(e.baseState&&(e.baseState=!1,Ke=!0),e.memoizedState=n):(dt(n,t)||(n=Oa(),Ee.lanes|=n,un|=n,e.baseState=!0),t)}function ep(e,t){var n=me;me=n!==0&&4>n?n:4,e(!0);var r=ls.transition;ls.transition={};try{e(!1),t()}finally{me=n,ls.transition=r}}function ac(){return at().memoizedState}function tp(e,t,n){var r=Yt(e);if(n={lane:r,action:n,hasEagerState:!1,eagerState:null,next:null},lc(e))cc(t,n);else if(n=zl(e,t,n,r),n!==null){var i=Ge();gt(n,e,r,i),uc(n,t,r)}}function np(e,t,n){var r=Yt(e),i={lane:r,action:n,hasEagerState:!1,eagerState:null,next:null};if(lc(e))cc(t,i);else{var o=e.alternate;if(e.lanes===0&&(o===null||o.lanes===0)&&(o=t.lastRenderedReducer,o!==null))try{var a=t.lastRenderedState,u=o(a,n);if(i.hasEagerState=!0,i.eagerState=u,dt(u,a)){var h=t.interleaved;h===null?(i.next=i,ns(t)):(i.next=h.next,h.next=i),t.interleaved=i;return}}catch{}finally{}n=zl(e,t,i,r),n!==null&&(i=Ge(),gt(n,e,r,i),uc(n,t,r))}}function lc(e){var t=e.alternate;return e===Ee||t!==null&&t===Ee}function cc(e,t){xr=Si=!0;var n=e.pending;n===null?t.next=t:(t.next=n.next,n.next=t),e.pending=t}function uc(e,t,n){if((n&4194240)!==0){var r=t.lanes;r&=e.pendingLanes,n|=r,t.lanes=n,yo(e,n)}}var Ii={readContext:st,useCallback:Ue,useContext:Ue,useEffect:Ue,useImperativeHandle:Ue,useInsertionEffect:Ue,useLayoutEffect:Ue,useMemo:Ue,useReducer:Ue,useRef:Ue,useState:Ue,useDebugValue:Ue,useDeferredValue:Ue,useTransition:Ue,useMutableSource:Ue,useSyncExternalStore:Ue,useId:Ue,unstable_isNewReconciler:!1},rp={readContext:st,useCallback:function(e,t){return bt().memoizedState=[e,t===void 0?null:t],e},useContext:st,useEffect:Zl,useImperativeHandle:function(e,t,n){return n=n!=null?n.concat([e]):null,bi(4194308,4,nc.bind(null,t,e),n)},useLayoutEffect:function(e,t){return bi(4194308,4,e,t)},useInsertionEffect:function(e,t){return bi(4,2,e,t)},useMemo:function(e,t){var n=bt();return t=t===void 0?null:t,e=e(),n.memoizedState=[e,t],e},useReducer:function(e,t,n){var r=bt();return t=n!==void 0?n(t):t,r.memoizedState=r.baseState=t,e={pending:null,interleaved:null,lanes:0,dispatch:null,lastRenderedReducer:e,lastRenderedState:t},r.queue=e,e=e.dispatch=tp.bind(null,Ee,e),[r.memoizedState,e]},useRef:function(e){var t=bt();return e={current:e},t.memoizedState=e},useState:Yl,useDebugValue:ms,useDeferredValue:function(e){return bt().memoizedState=e},useTransition:function(){var e=Yl(!1),t=e[0];return e=ep.bind(null,e[1]),bt().memoizedState=e,[t,e]},useMutableSource:function(){},useSyncExternalStore:function(e,t,n){var r=Ee,i=bt();if(be){if(n===void 0)throw Error(l(407));n=n()}else{if(n=t(),Fe===null)throw Error(l(349));(cn&30)!==0||Gl(r,t,n)}i.memoizedState=n;var o={value:n,getSnapshot:t};return i.queue=o,Zl(Ql.bind(null,r,o,e),[e]),r.flags|=2048,Ar(9,ql.bind(null,r,o,n,t),void 0,null),n},useId:function(){var e=bt(),t=Fe.identifierPrefix;if(be){var n=Ct,r=Mt;n=(r&~(1<<32-ut(r)-1)).toString(32)+n,t=":"+t+"R"+n,n=Sr++,0<n&&(t+="H"+n.toString(32)),t+=":"}else n=Zd++,t=":"+t+"r"+n.toString(32)+":";return e.memoizedState=t},unstable_isNewReconciler:!1},ip={readContext:st,useCallback:ic,useContext:st,useEffect:fs,useImperativeHandle:rc,useInsertionEffect:ec,useLayoutEffect:tc,useMemo:oc,useReducer:ps,useRef:Jl,useState:function(){return ps(br)},useDebugValue:ms,useDeferredValue:function(e){var t=at();return sc(t,Ne.memoizedState,e)},useTransition:function(){var e=ps(br)[0],t=at().memoizedState;return[e,t]},useMutableSource:Hl,useSyncExternalStore:Vl,useId:ac,unstable_isNewReconciler:!1},op={readContext:st,useCallback:ic,useContext:st,useEffect:fs,useImperativeHandle:rc,useInsertionEffect:ec,useLayoutEffect:tc,useMemo:oc,useReducer:hs,useRef:Jl,useState:function(){return hs(br)},useDebugValue:ms,useDeferredValue:function(e){var t=at();return Ne===null?t.memoizedState=e:sc(t,Ne.memoizedState,e)},useTransition:function(){var e=hs(br)[0],t=at().memoizedState;return[e,t]},useMutableSource:Hl,useSyncExternalStore:Vl,useId:ac,unstable_isNewReconciler:!1};function ht(e,t){if(e&&e.defaultProps){t=B({},t),e=e.defaultProps;for(var n in e)t[n]===void 0&&(t[n]=e[n]);return t}return t}function gs(e,t,n,r){t=e.memoizedState,n=n(r,t),n=n==null?t:B({},t,n),e.memoizedState=n,e.lanes===0&&(e.updateQueue.baseState=n)}var _i={isMounted:function(e){return(e=e._reactInternals)?tn(e)===e:!1},enqueueSetState:function(e,t,n){e=e._reactInternals;var r=Ge(),i=Yt(e),o=Tt(r,i);o.payload=t,n!=null&&(o.callback=n),t=qt(e,o,i),t!==null&&(gt(t,e,i,r),vi(t,e,i))},enqueueReplaceState:function(e,t,n){e=e._reactInternals;var r=Ge(),i=Yt(e),o=Tt(r,i);o.tag=1,o.payload=t,n!=null&&(o.callback=n),t=qt(e,o,i),t!==null&&(gt(t,e,i,r),vi(t,e,i))},enqueueForceUpdate:function(e,t){e=e._reactInternals;var n=Ge(),r=Yt(e),i=Tt(n,r);i.tag=2,t!=null&&(i.callback=t),t=qt(e,i,r),t!==null&&(gt(t,e,r,n),vi(t,e,r))}};function dc(e,t,n,r,i,o,a){return e=e.stateNode,typeof e.shouldComponentUpdate=="function"?e.shouldComponentUpdate(r,o,a):t.prototype&&t.prototype.isPureReactComponent?!ur(n,r)||!ur(i,o):!0}function pc(e,t,n){var r=!1,i=Ht,o=t.contextType;return typeof o=="object"&&o!==null?o=st(o):(i=Qe(t)?rn:$e.current,r=t.contextTypes,o=(r=r!=null)?Mn(e,i):Ht),t=new t(n,o),e.memoizedState=t.state!==null&&t.state!==void 0?t.state:null,t.updater=_i,e.stateNode=t,t._reactInternals=e,r&&(e=e.stateNode,e.__reactInternalMemoizedUnmaskedChildContext=i,e.__reactInternalMemoizedMaskedChildContext=o),t}function hc(e,t,n,r){e=t.state,typeof t.componentWillReceiveProps=="function"&&t.componentWillReceiveProps(n,r),typeof t.UNSAFE_componentWillReceiveProps=="function"&&t.UNSAFE_componentWillReceiveProps(n,r),t.state!==e&&_i.enqueueReplaceState(t,t.state,null)}function ys(e,t,n,r){var i=e.stateNode;i.props=n,i.state=e.memoizedState,i.refs={},rs(e);var o=t.contextType;typeof o=="object"&&o!==null?i.context=st(o):(o=Qe(t)?rn:$e.current,i.context=Mn(e,o)),i.state=e.memoizedState,o=t.getDerivedStateFromProps,typeof o=="function"&&(gs(e,t,o,n),i.state=e.memoizedState),typeof t.getDerivedStateFromProps=="function"||typeof i.getSnapshotBeforeUpdate=="function"||typeof i.UNSAFE_componentWillMount!="function"&&typeof i.componentWillMount!="function"||(t=i.state,typeof i.componentWillMount=="function"&&i.componentWillMount(),typeof i.UNSAFE_componentWillMount=="function"&&i.UNSAFE_componentWillMount(),t!==i.state&&_i.enqueueReplaceState(i,i.state,null),wi(e,n,i,r),i.state=e.memoizedState),typeof i.componentDidMount=="function"&&(e.flags|=4194308)}function On(e,t){try{var n="",r=t;do n+=ue(r),r=r.return;while(r);var i=n}catch(o){i=`
Error generating stack: `+o.message+`
`+o.stack}return{value:e,source:t,stack:i,digest:null}}function vs(e,t,n){return{value:e,source:null,stack:n??null,digest:t??null}}function ws(e,t){try{console.error(t.value)}catch(n){setTimeout(function(){throw n})}}var sp=typeof WeakMap=="function"?WeakMap:Map;function fc(e,t,n){n=Tt(-1,n),n.tag=3,n.payload={element:null};var r=t.value;return n.callback=function(){Ri||(Ri=!0,Ns=r),ws(e,t)},n}function mc(e,t,n){n=Tt(-1,n),n.tag=3;var r=e.type.getDerivedStateFromError;if(typeof r=="function"){var i=t.value;n.payload=function(){return r(i)},n.callback=function(){ws(e,t)}}var o=e.stateNode;return o!==null&&typeof o.componentDidCatch=="function"&&(n.callback=function(){ws(e,t),typeof r!="function"&&(Kt===null?Kt=new Set([this]):Kt.add(this));var a=t.stack;this.componentDidCatch(t.value,{componentStack:a!==null?a:""})}),n}function gc(e,t,n){var r=e.pingCache;if(r===null){r=e.pingCache=new sp;var i=new Set;r.set(t,i)}else i=r.get(t),i===void 0&&(i=new Set,r.set(t,i));i.has(n)||(i.add(n),e=kp.bind(null,e,t,n),t.then(e,e))}function yc(e){do{var t;if((t=e.tag===13)&&(t=e.memoizedState,t=t!==null?t.dehydrated!==null:!0),t)return e;e=e.return}while(e!==null);return null}function vc(e,t,n,r,i){return(e.mode&1)===0?(e===t?e.flags|=65536:(e.flags|=128,n.flags|=131072,n.flags&=-52805,n.tag===1&&(n.alternate===null?n.tag=17:(t=Tt(-1,1),t.tag=2,qt(n,t,1))),n.lanes|=1),e):(e.flags|=65536,e.lanes=i,e)}var ap=se.ReactCurrentOwner,Ke=!1;function Ve(e,t,n,r){t.child=e===null?jl(t,null,n,r):Dn(t,e.child,n,r)}function wc(e,t,n,r,i){n=n.render;var o=t.ref;return Nn(t,i),r=us(e,t,n,r,o,i),n=ds(),e!==null&&!Ke?(t.updateQueue=e.updateQueue,t.flags&=-2053,e.lanes&=~i,Dt(e,t,i)):(be&&n&&qo(t),t.flags|=1,Ve(e,t,r,i),t.child)}function kc(e,t,n,r,i){if(e===null){var o=n.type;return typeof o=="function"&&!$s(o)&&o.defaultProps===void 0&&n.compare===null&&n.defaultProps===void 0?(t.tag=15,t.type=o,xc(e,t,o,r,i)):(e=zi(n.type,null,r,t,t.mode,i),e.ref=t.ref,e.return=t,t.child=e)}if(o=e.child,(e.lanes&i)===0){var a=o.memoizedProps;if(n=n.compare,n=n!==null?n:ur,n(a,r)&&e.ref===t.ref)return Dt(e,t,i)}return t.flags|=1,e=Zt(o,r),e.ref=t.ref,e.return=t,t.child=e}function xc(e,t,n,r,i){if(e!==null){var o=e.memoizedProps;if(ur(o,r)&&e.ref===t.ref)if(Ke=!1,t.pendingProps=r=o,(e.lanes&i)!==0)(e.flags&131072)!==0&&(Ke=!0);else return t.lanes=e.lanes,Dt(e,t,i)}return ks(e,t,n,r,i)}function Sc(e,t,n){var r=t.pendingProps,i=r.children,o=e!==null?e.memoizedState:null;if(r.mode==="hidden")if((t.mode&1)===0)t.memoizedState={baseLanes:0,cachePool:null,transitions:null},we(jn,rt),rt|=n;else{if((n&1073741824)===0)return e=o!==null?o.baseLanes|n:n,t.lanes=t.childLanes=1073741824,t.memoizedState={baseLanes:e,cachePool:null,transitions:null},t.updateQueue=null,we(jn,rt),rt|=e,null;t.memoizedState={baseLanes:0,cachePool:null,transitions:null},r=o!==null?o.baseLanes:n,we(jn,rt),rt|=r}else o!==null?(r=o.baseLanes|n,t.memoizedState=null):r=n,we(jn,rt),rt|=r;return Ve(e,t,i,n),t.child}function bc(e,t){var n=t.ref;(e===null&&n!==null||e!==null&&e.ref!==n)&&(t.flags|=512,t.flags|=2097152)}function ks(e,t,n,r,i){var o=Qe(n)?rn:$e.current;return o=Mn(t,o),Nn(t,i),n=us(e,t,n,r,o,i),r=ds(),e!==null&&!Ke?(t.updateQueue=e.updateQueue,t.flags&=-2053,e.lanes&=~i,Dt(e,t,i)):(be&&r&&qo(t),t.flags|=1,Ve(e,t,n,i),t.child)}function Ac(e,t,n,r,i){if(Qe(n)){var o=!0;ui(t)}else o=!1;if(Nn(t,i),t.stateNode===null)Mi(e,t),pc(t,n,r),ys(t,n,r,i),r=!0;else if(e===null){var a=t.stateNode,u=t.memoizedProps;a.props=u;var h=a.context,S=n.contextType;typeof S=="object"&&S!==null?S=st(S):(S=Qe(n)?rn:$e.current,S=Mn(t,S));var C=n.getDerivedStateFromProps,P=typeof C=="function"||typeof a.getSnapshotBeforeUpdate=="function";P||typeof a.UNSAFE_componentWillReceiveProps!="function"&&typeof a.componentWillReceiveProps!="function"||(u!==r||h!==S)&&hc(t,a,r,S),Gt=!1;var E=t.memoizedState;a.state=E,wi(t,r,a,i),h=t.memoizedState,u!==r||E!==h||qe.current||Gt?(typeof C=="function"&&(gs(t,n,C,r),h=t.memoizedState),(u=Gt||dc(t,n,u,r,E,h,S))?(P||typeof a.UNSAFE_componentWillMount!="function"&&typeof a.componentWillMount!="function"||(typeof a.componentWillMount=="function"&&a.componentWillMount(),typeof a.UNSAFE_componentWillMount=="function"&&a.UNSAFE_componentWillMount()),typeof a.componentDidMount=="function"&&(t.flags|=4194308)):(typeof a.componentDidMount=="function"&&(t.flags|=4194308),t.memoizedProps=r,t.memoizedState=h),a.props=r,a.state=h,a.context=S,r=u):(typeof a.componentDidMount=="function"&&(t.flags|=4194308),r=!1)}else{a=t.stateNode,Bl(e,t),u=t.memoizedProps,S=t.type===t.elementType?u:ht(t.type,u),a.props=S,P=t.pendingProps,E=a.context,h=n.contextType,typeof h=="object"&&h!==null?h=st(h):(h=Qe(n)?rn:$e.current,h=Mn(t,h));var F=n.getDerivedStateFromProps;(C=typeof F=="function"||typeof a.getSnapshotBeforeUpdate=="function")||typeof a.UNSAFE_componentWillReceiveProps!="function"&&typeof a.componentWillReceiveProps!="function"||(u!==P||E!==h)&&hc(t,a,r,h),Gt=!1,E=t.memoizedState,a.state=E,wi(t,r,a,i);var U=t.memoizedState;u!==P||E!==U||qe.current||Gt?(typeof F=="function"&&(gs(t,n,F,r),U=t.memoizedState),(S=Gt||dc(t,n,S,r,E,U,h)||!1)?(C||typeof a.UNSAFE_componentWillUpdate!="function"&&typeof a.componentWillUpdate!="function"||(typeof a.componentWillUpdate=="function"&&a.componentWillUpdate(r,U,h),typeof a.UNSAFE_componentWillUpdate=="function"&&a.UNSAFE_componentWillUpdate(r,U,h)),typeof a.componentDidUpdate=="function"&&(t.flags|=4),typeof a.getSnapshotBeforeUpdate=="function"&&(t.flags|=1024)):(typeof a.componentDidUpdate!="function"||u===e.memoizedProps&&E===e.memoizedState||(t.flags|=4),typeof a.getSnapshotBeforeUpdate!="function"||u===e.memoizedProps&&E===e.memoizedState||(t.flags|=1024),t.memoizedProps=r,t.memoizedState=U),a.props=r,a.state=U,a.context=h,r=S):(typeof a.componentDidUpdate!="function"||u===e.memoizedProps&&E===e.memoizedState||(t.flags|=4),typeof a.getSnapshotBeforeUpdate!="function"||u===e.memoizedProps&&E===e.memoizedState||(t.flags|=1024),r=!1)}return xs(e,t,n,r,o,i)}function xs(e,t,n,r,i,o){bc(e,t);var a=(t.flags&128)!==0;if(!r&&!a)return i&&Cl(t,n,!1),Dt(e,t,o);r=t.stateNode,ap.current=t;var u=a&&typeof n.getDerivedStateFromError!="function"?null:r.render();return t.flags|=1,e!==null&&a?(t.child=Dn(t,e.child,null,o),t.child=Dn(t,null,u,o)):Ve(e,t,u,o),t.memoizedState=r.state,i&&Cl(t,n,!0),t.child}function Ic(e){var t=e.stateNode;t.pendingContext?El(e,t.pendingContext,t.pendingContext!==t.context):t.context&&El(e,t.context,!1),is(e,t.containerInfo)}function _c(e,t,n,r,i){return Tn(),Yo(i),t.flags|=256,Ve(e,t,n,r),t.child}var Ss={dehydrated:null,treeContext:null,retryLane:0};function bs(e){return{baseLanes:e,cachePool:null,transitions:null}}function Ec(e,t,n){var r=t.pendingProps,i=_e.current,o=!1,a=(t.flags&128)!==0,u;if((u=a)||(u=e!==null&&e.memoizedState===null?!1:(i&2)!==0),u?(o=!0,t.flags&=-129):(e===null||e.memoizedState!==null)&&(i|=1),we(_e,i&1),e===null)return Xo(t),e=t.memoizedState,e!==null&&(e=e.dehydrated,e!==null)?((t.mode&1)===0?t.lanes=1:e.data==="$!"?t.lanes=8:t.lanes=1073741824,null):(a=r.children,e=r.fallback,o?(r=t.mode,o=t.child,a={mode:"hidden",children:a},(r&1)===0&&o!==null?(o.childLanes=0,o.pendingProps=a):o=Bi(a,r,0,null),e=fn(e,r,n,null),o.return=t,e.return=t,o.sibling=e,t.child=o,t.child.memoizedState=bs(n),t.memoizedState=Ss,e):As(t,a));if(i=e.memoizedState,i!==null&&(u=i.dehydrated,u!==null))return lp(e,t,a,r,u,i,n);if(o){o=r.fallback,a=t.mode,i=e.child,u=i.sibling;var h={mode:"hidden",children:r.children};return(a&1)===0&&t.child!==i?(r=t.child,r.childLanes=0,r.pendingProps=h,t.deletions=null):(r=Zt(i,h),r.subtreeFlags=i.subtreeFlags&14680064),u!==null?o=Zt(u,o):(o=fn(o,a,n,null),o.flags|=2),o.return=t,r.return=t,r.sibling=o,t.child=r,r=o,o=t.child,a=e.child.memoizedState,a=a===null?bs(n):{baseLanes:a.baseLanes|n,cachePool:null,transitions:a.transitions},o.memoizedState=a,o.childLanes=e.childLanes&~n,t.memoizedState=Ss,r}return o=e.child,e=o.sibling,r=Zt(o,{mode:"visible",children:r.children}),(t.mode&1)===0&&(r.lanes=n),r.return=t,r.sibling=null,e!==null&&(n=t.deletions,n===null?(t.deletions=[e],t.flags|=16):n.push(e)),t.child=r,t.memoizedState=null,r}function As(e,t){return t=Bi({mode:"visible",children:t},e.mode,0,null),t.return=e,e.child=t}function Ei(e,t,n,r){return r!==null&&Yo(r),Dn(t,e.child,null,n),e=As(t,t.pendingProps.children),e.flags|=2,t.memoizedState=null,e}function lp(e,t,n,r,i,o,a){if(n)return t.flags&256?(t.flags&=-257,r=vs(Error(l(422))),Ei(e,t,a,r)):t.memoizedState!==null?(t.child=e.child,t.flags|=128,null):(o=r.fallback,i=t.mode,r=Bi({mode:"visible",children:r.children},i,0,null),o=fn(o,i,a,null),o.flags|=2,r.return=t,o.return=t,r.sibling=o,t.child=r,(t.mode&1)!==0&&Dn(t,e.child,null,a),t.child.memoizedState=bs(a),t.memoizedState=Ss,o);if((t.mode&1)===0)return Ei(e,t,a,null);if(i.data==="$!"){if(r=i.nextSibling&&i.nextSibling.dataset,r)var u=r.dgst;return r=u,o=Error(l(419)),r=vs(o,r,void 0),Ei(e,t,a,r)}if(u=(a&e.childLanes)!==0,Ke||u){if(r=Fe,r!==null){switch(a&-a){case 4:i=2;break;case 16:i=8;break;case 64:case 128:case 256:case 512:case 1024:case 2048:case 4096:case 8192:case 16384:case 32768:case 65536:case 131072:case 262144:case 524288:case 1048576:case 2097152:case 4194304:case 8388608:case 16777216:case 33554432:case 67108864:i=32;break;case 536870912:i=268435456;break;default:i=0}i=(i&(r.suspendedLanes|a))!==0?0:i,i!==0&&i!==o.retryLane&&(o.retryLane=i,Pt(e,i),gt(r,e,i,-1))}return Bs(),r=vs(Error(l(421))),Ei(e,t,a,r)}return i.data==="$?"?(t.flags|=128,t.child=e.child,t=xp.bind(null,e),i._reactRetry=t,null):(e=o.treeContext,nt=Ut(i.nextSibling),tt=t,be=!0,pt=null,e!==null&&(it[ot++]=Mt,it[ot++]=Ct,it[ot++]=on,Mt=e.id,Ct=e.overflow,on=t),t=As(t,r.children),t.flags|=4096,t)}function Mc(e,t,n){e.lanes|=t;var r=e.alternate;r!==null&&(r.lanes|=t),ts(e.return,t,n)}function Is(e,t,n,r,i){var o=e.memoizedState;o===null?e.memoizedState={isBackwards:t,rendering:null,renderingStartTime:0,last:r,tail:n,tailMode:i}:(o.isBackwards=t,o.rendering=null,o.renderingStartTime=0,o.last=r,o.tail=n,o.tailMode=i)}function Cc(e,t,n){var r=t.pendingProps,i=r.revealOrder,o=r.tail;if(Ve(e,t,r.children,n),r=_e.current,(r&2)!==0)r=r&1|2,t.flags|=128;else{if(e!==null&&(e.flags&128)!==0)e:for(e=t.child;e!==null;){if(e.tag===13)e.memoizedState!==null&&Mc(e,n,t);else if(e.tag===19)Mc(e,n,t);else if(e.child!==null){e.child.return=e,e=e.child;continue}if(e===t)break e;for(;e.sibling===null;){if(e.return===null||e.return===t)break e;e=e.return}e.sibling.return=e.return,e=e.sibling}r&=1}if(we(_e,r),(t.mode&1)===0)t.memoizedState=null;else switch(i){case"forwards":for(n=t.child,i=null;n!==null;)e=n.alternate,e!==null&&ki(e)===null&&(i=n),n=n.sibling;n=i,n===null?(i=t.child,t.child=null):(i=n.sibling,n.sibling=null),Is(t,!1,i,n,o);break;case"backwards":for(n=null,i=t.child,t.child=null;i!==null;){if(e=i.alternate,e!==null&&ki(e)===null){t.child=i;break}e=i.sibling,i.sibling=n,n=i,i=e}Is(t,!0,n,null,o);break;case"together":Is(t,!1,null,null,void 0);break;default:t.memoizedState=null}return t.child}function Mi(e,t){(t.mode&1)===0&&e!==null&&(e.alternate=null,t.alternate=null,t.flags|=2)}function Dt(e,t,n){if(e!==null&&(t.dependencies=e.dependencies),un|=t.lanes,(n&t.childLanes)===0)return null;if(e!==null&&t.child!==e.child)throw Error(l(153));if(t.child!==null){for(e=t.child,n=Zt(e,e.pendingProps),t.child=n,n.return=t;e.sibling!==null;)e=e.sibling,n=n.sibling=Zt(e,e.pendingProps),n.return=t;n.sibling=null}return t.child}function cp(e,t,n){switch(t.tag){case 3:Ic(t),Tn();break;case 5:Wl(t);break;case 1:Qe(t.type)&&ui(t);break;case 4:is(t,t.stateNode.containerInfo);break;case 10:var r=t.type._context,i=t.memoizedProps.value;we(gi,r._currentValue),r._currentValue=i;break;case 13:if(r=t.memoizedState,r!==null)return r.dehydrated!==null?(we(_e,_e.current&1),t.flags|=128,null):(n&t.child.childLanes)!==0?Ec(e,t,n):(we(_e,_e.current&1),e=Dt(e,t,n),e!==null?e.sibling:null);we(_e,_e.current&1);break;case 19:if(r=(n&t.childLanes)!==0,(e.flags&128)!==0){if(r)return Cc(e,t,n);t.flags|=128}if(i=t.memoizedState,i!==null&&(i.rendering=null,i.tail=null,i.lastEffect=null),we(_e,_e.current),r)break;return null;case 22:case 23:return t.lanes=0,Sc(e,t,n)}return Dt(e,t,n)}var Pc,_s,Tc,Dc;Pc=function(e,t){for(var n=t.child;n!==null;){if(n.tag===5||n.tag===6)e.appendChild(n.stateNode);else if(n.tag!==4&&n.child!==null){n.child.return=n,n=n.child;continue}if(n===t)break;for(;n.sibling===null;){if(n.return===null||n.return===t)return;n=n.return}n.sibling.return=n.return,n=n.sibling}},_s=function(){},Tc=function(e,t,n,r){var i=e.memoizedProps;if(i!==r){e=t.stateNode,ln(St.current);var o=null;switch(n){case"input":i=eo(e,i),r=eo(e,r),o=[];break;case"select":i=B({},i,{value:void 0}),r=B({},r,{value:void 0}),o=[];break;case"textarea":i=ro(e,i),r=ro(e,r),o=[];break;default:typeof i.onClick!="function"&&typeof r.onClick=="function"&&(e.onclick=ai)}oo(n,r);var a;n=null;for(S in i)if(!r.hasOwnProperty(S)&&i.hasOwnProperty(S)&&i[S]!=null)if(S==="style"){var u=i[S];for(a in u)u.hasOwnProperty(a)&&(n||(n={}),n[a]="")}else S!=="dangerouslySetInnerHTML"&&S!=="children"&&S!=="suppressContentEditableWarning"&&S!=="suppressHydrationWarning"&&S!=="autoFocus"&&(d.hasOwnProperty(S)?o||(o=[]):(o=o||[]).push(S,null));for(S in r){var h=r[S];if(u=i!=null?i[S]:void 0,r.hasOwnProperty(S)&&h!==u&&(h!=null||u!=null))if(S==="style")if(u){for(a in u)!u.hasOwnProperty(a)||h&&h.hasOwnProperty(a)||(n||(n={}),n[a]="");for(a in h)h.hasOwnProperty(a)&&u[a]!==h[a]&&(n||(n={}),n[a]=h[a])}else n||(o||(o=[]),o.push(S,n)),n=h;else S==="dangerouslySetInnerHTML"?(h=h?h.__html:void 0,u=u?u.__html:void 0,h!=null&&u!==h&&(o=o||[]).push(S,h)):S==="children"?typeof h!="string"&&typeof h!="number"||(o=o||[]).push(S,""+h):S!=="suppressContentEditableWarning"&&S!=="suppressHydrationWarning"&&(d.hasOwnProperty(S)?(h!=null&&S==="onScroll"&&ke("scroll",e),o||u===h||(o=[])):(o=o||[]).push(S,h))}n&&(o=o||[]).push("style",n);var S=o;(t.updateQueue=S)&&(t.flags|=4)}},Dc=function(e,t,n,r){n!==r&&(t.flags|=4)};function Ir(e,t){if(!be)switch(e.tailMode){case"hidden":t=e.tail;for(var n=null;t!==null;)t.alternate!==null&&(n=t),t=t.sibling;n===null?e.tail=null:n.sibling=null;break;case"collapsed":n=e.tail;for(var r=null;n!==null;)n.alternate!==null&&(r=n),n=n.sibling;r===null?t||e.tail===null?e.tail=null:e.tail.sibling=null:r.sibling=null}}function We(e){var t=e.alternate!==null&&e.alternate.child===e.child,n=0,r=0;if(t)for(var i=e.child;i!==null;)n|=i.lanes|i.childLanes,r|=i.subtreeFlags&14680064,r|=i.flags&14680064,i.return=e,i=i.sibling;else for(i=e.child;i!==null;)n|=i.lanes|i.childLanes,r|=i.subtreeFlags,r|=i.flags,i.return=e,i=i.sibling;return e.subtreeFlags|=r,e.childLanes=n,t}function up(e,t,n){var r=t.pendingProps;switch(Qo(t),t.tag){case 2:case 16:case 15:case 0:case 11:case 7:case 8:case 12:case 9:case 14:return We(t),null;case 1:return Qe(t.type)&&ci(),We(t),null;case 3:return r=t.stateNode,Ln(),xe(qe),xe($e),as(),r.pendingContext&&(r.context=r.pendingContext,r.pendingContext=null),(e===null||e.child===null)&&(fi(t)?t.flags|=4:e===null||e.memoizedState.isDehydrated&&(t.flags&256)===0||(t.flags|=1024,pt!==null&&(Fs(pt),pt=null))),_s(e,t),We(t),null;case 5:os(t);var i=ln(kr.current);if(n=t.type,e!==null&&t.stateNode!=null)Tc(e,t,n,r,i),e.ref!==t.ref&&(t.flags|=512,t.flags|=2097152);else{if(!r){if(t.stateNode===null)throw Error(l(166));return We(t),null}if(e=ln(St.current),fi(t)){r=t.stateNode,n=t.type;var o=t.memoizedProps;switch(r[xt]=t,r[mr]=o,e=(t.mode&1)!==0,n){case"dialog":ke("cancel",r),ke("close",r);break;case"iframe":case"object":case"embed":ke("load",r);break;case"video":case"audio":for(i=0;i<pr.length;i++)ke(pr[i],r);break;case"source":ke("error",r);break;case"img":case"image":case"link":ke("error",r),ke("load",r);break;case"details":ke("toggle",r);break;case"input":pa(r,o),ke("invalid",r);break;case"select":r._wrapperState={wasMultiple:!!o.multiple},ke("invalid",r);break;case"textarea":ma(r,o),ke("invalid",r)}oo(n,o),i=null;for(var a in o)if(o.hasOwnProperty(a)){var u=o[a];a==="children"?typeof u=="string"?r.textContent!==u&&(o.suppressHydrationWarning!==!0&&si(r.textContent,u,e),i=["children",u]):typeof u=="number"&&r.textContent!==""+u&&(o.suppressHydrationWarning!==!0&&si(r.textContent,u,e),i=["children",""+u]):d.hasOwnProperty(a)&&u!=null&&a==="onScroll"&&ke("scroll",r)}switch(n){case"input":Fr(r),fa(r,o,!0);break;case"textarea":Fr(r),ya(r);break;case"select":case"option":break;default:typeof o.onClick=="function"&&(r.onclick=ai)}r=i,t.updateQueue=r,r!==null&&(t.flags|=4)}else{a=i.nodeType===9?i:i.ownerDocument,e==="http://www.w3.org/1999/xhtml"&&(e=va(n)),e==="http://www.w3.org/1999/xhtml"?n==="script"?(e=a.createElement("div"),e.innerHTML="<script><\/script>",e=e.removeChild(e.firstChild)):typeof r.is=="string"?e=a.createElement(n,{is:r.is}):(e=a.createElement(n),n==="select"&&(a=e,r.multiple?a.multiple=!0:r.size&&(a.size=r.size))):e=a.createElementNS(e,n),e[xt]=t,e[mr]=r,Pc(e,t,!1,!1),t.stateNode=e;e:{switch(a=so(n,r),n){case"dialog":ke("cancel",e),ke("close",e),i=r;break;case"iframe":case"object":case"embed":ke("load",e),i=r;break;case"video":case"audio":for(i=0;i<pr.length;i++)ke(pr[i],e);i=r;break;case"source":ke("error",e),i=r;break;case"img":case"image":case"link":ke("error",e),ke("load",e),i=r;break;case"details":ke("toggle",e),i=r;break;case"input":pa(e,r),i=eo(e,r),ke("invalid",e);break;case"option":i=r;break;case"select":e._wrapperState={wasMultiple:!!r.multiple},i=B({},r,{value:void 0}),ke("invalid",e);break;case"textarea":ma(e,r),i=ro(e,r),ke("invalid",e);break;default:i=r}oo(n,i),u=i;for(o in u)if(u.hasOwnProperty(o)){var h=u[o];o==="style"?xa(e,h):o==="dangerouslySetInnerHTML"?(h=h?h.__html:void 0,h!=null&&wa(e,h)):o==="children"?typeof h=="string"?(n!=="textarea"||h!=="")&&qn(e,h):typeof h=="number"&&qn(e,""+h):o!=="suppressContentEditableWarning"&&o!=="suppressHydrationWarning"&&o!=="autoFocus"&&(d.hasOwnProperty(o)?h!=null&&o==="onScroll"&&ke("scroll",e):h!=null&&V(e,o,h,a))}switch(n){case"input":Fr(e),fa(e,r,!1);break;case"textarea":Fr(e),ya(e);break;case"option":r.value!=null&&e.setAttribute("value",""+fe(r.value));break;case"select":e.multiple=!!r.multiple,o=r.value,o!=null?gn(e,!!r.multiple,o,!1):r.defaultValue!=null&&gn(e,!!r.multiple,r.defaultValue,!0);break;default:typeof i.onClick=="function"&&(e.onclick=ai)}switch(n){case"button":case"input":case"select":case"textarea":r=!!r.autoFocus;break e;case"img":r=!0;break e;default:r=!1}}r&&(t.flags|=4)}t.ref!==null&&(t.flags|=512,t.flags|=2097152)}return We(t),null;case 6:if(e&&t.stateNode!=null)Dc(e,t,e.memoizedProps,r);else{if(typeof r!="string"&&t.stateNode===null)throw Error(l(166));if(n=ln(kr.current),ln(St.current),fi(t)){if(r=t.stateNode,n=t.memoizedProps,r[xt]=t,(o=r.nodeValue!==n)&&(e=tt,e!==null))switch(e.tag){case 3:si(r.nodeValue,n,(e.mode&1)!==0);break;case 5:e.memoizedProps.suppressHydrationWarning!==!0&&si(r.nodeValue,n,(e.mode&1)!==0)}o&&(t.flags|=4)}else r=(n.nodeType===9?n:n.ownerDocument).createTextNode(r),r[xt]=t,t.stateNode=r}return We(t),null;case 13:if(xe(_e),r=t.memoizedState,e===null||e.memoizedState!==null&&e.memoizedState.dehydrated!==null){if(be&&nt!==null&&(t.mode&1)!==0&&(t.flags&128)===0)Ll(),Tn(),t.flags|=98560,o=!1;else if(o=fi(t),r!==null&&r.dehydrated!==null){if(e===null){if(!o)throw Error(l(318));if(o=t.memoizedState,o=o!==null?o.dehydrated:null,!o)throw Error(l(317));o[xt]=t}else Tn(),(t.flags&128)===0&&(t.memoizedState=null),t.flags|=4;We(t),o=!1}else pt!==null&&(Fs(pt),pt=null),o=!0;if(!o)return t.flags&65536?t:null}return(t.flags&128)!==0?(t.lanes=n,t):(r=r!==null,r!==(e!==null&&e.memoizedState!==null)&&r&&(t.child.flags|=8192,(t.mode&1)!==0&&(e===null||(_e.current&1)!==0?Le===0&&(Le=3):Bs())),t.updateQueue!==null&&(t.flags|=4),We(t),null);case 4:return Ln(),_s(e,t),e===null&&hr(t.stateNode.containerInfo),We(t),null;case 10:return es(t.type._context),We(t),null;case 17:return Qe(t.type)&&ci(),We(t),null;case 19:if(xe(_e),o=t.memoizedState,o===null)return We(t),null;if(r=(t.flags&128)!==0,a=o.rendering,a===null)if(r)Ir(o,!1);else{if(Le!==0||e!==null&&(e.flags&128)!==0)for(e=t.child;e!==null;){if(a=ki(e),a!==null){for(t.flags|=128,Ir(o,!1),r=a.updateQueue,r!==null&&(t.updateQueue=r,t.flags|=4),t.subtreeFlags=0,r=n,n=t.child;n!==null;)o=n,e=r,o.flags&=14680066,a=o.alternate,a===null?(o.childLanes=0,o.lanes=e,o.child=null,o.subtreeFlags=0,o.memoizedProps=null,o.memoizedState=null,o.updateQueue=null,o.dependencies=null,o.stateNode=null):(o.childLanes=a.childLanes,o.lanes=a.lanes,o.child=a.child,o.subtreeFlags=0,o.deletions=null,o.memoizedProps=a.memoizedProps,o.memoizedState=a.memoizedState,o.updateQueue=a.updateQueue,o.type=a.type,e=a.dependencies,o.dependencies=e===null?null:{lanes:e.lanes,firstContext:e.firstContext}),n=n.sibling;return we(_e,_e.current&1|2),t.child}e=e.sibling}o.tail!==null&&Te()>zn&&(t.flags|=128,r=!0,Ir(o,!1),t.lanes=4194304)}else{if(!r)if(e=ki(a),e!==null){if(t.flags|=128,r=!0,n=e.updateQueue,n!==null&&(t.updateQueue=n,t.flags|=4),Ir(o,!0),o.tail===null&&o.tailMode==="hidden"&&!a.alternate&&!be)return We(t),null}else 2*Te()-o.renderingStartTime>zn&&n!==1073741824&&(t.flags|=128,r=!0,Ir(o,!1),t.lanes=4194304);o.isBackwards?(a.sibling=t.child,t.child=a):(n=o.last,n!==null?n.sibling=a:t.child=a,o.last=a)}return o.tail!==null?(t=o.tail,o.rendering=t,o.tail=t.sibling,o.renderingStartTime=Te(),t.sibling=null,n=_e.current,we(_e,r?n&1|2:n&1),t):(We(t),null);case 22:case 23:return zs(),r=t.memoizedState!==null,e!==null&&e.memoizedState!==null!==r&&(t.flags|=8192),r&&(t.mode&1)!==0?(rt&1073741824)!==0&&(We(t),t.subtreeFlags&6&&(t.flags|=8192)):We(t),null;case 24:return null;case 25:return null}throw Error(l(156,t.tag))}function dp(e,t){switch(Qo(t),t.tag){case 1:return Qe(t.type)&&ci(),e=t.flags,e&65536?(t.flags=e&-65537|128,t):null;case 3:return Ln(),xe(qe),xe($e),as(),e=t.flags,(e&65536)!==0&&(e&128)===0?(t.flags=e&-65537|128,t):null;case 5:return os(t),null;case 13:if(xe(_e),e=t.memoizedState,e!==null&&e.dehydrated!==null){if(t.alternate===null)throw Error(l(340));Tn()}return e=t.flags,e&65536?(t.flags=e&-65537|128,t):null;case 19:return xe(_e),null;case 4:return Ln(),null;case 10:return es(t.type._context),null;case 22:case 23:return zs(),null;case 24:return null;default:return null}}var Ci=!1,He=!1,pp=typeof WeakSet=="function"?WeakSet:Set,z=null;function Fn(e,t){var n=e.ref;if(n!==null)if(typeof n=="function")try{n(null)}catch(r){Ce(e,t,r)}else n.current=null}function Es(e,t,n){try{n()}catch(r){Ce(e,t,r)}}var Rc=!1;function hp(e,t){if(zo=Kr,e=dl(),To(e)){if("selectionStart"in e)var n={start:e.selectionStart,end:e.selectionEnd};else e:{n=(n=e.ownerDocument)&&n.defaultView||window;var r=n.getSelection&&n.getSelection();if(r&&r.rangeCount!==0){n=r.anchorNode;var i=r.anchorOffset,o=r.focusNode;r=r.focusOffset;try{n.nodeType,o.nodeType}catch{n=null;break e}var a=0,u=-1,h=-1,S=0,C=0,P=e,E=null;t:for(;;){for(var F;P!==n||i!==0&&P.nodeType!==3||(u=a+i),P!==o||r!==0&&P.nodeType!==3||(h=a+r),P.nodeType===3&&(a+=P.nodeValue.length),(F=P.firstChild)!==null;)E=P,P=F;for(;;){if(P===e)break t;if(E===n&&++S===i&&(u=a),E===o&&++C===r&&(h=a),(F=P.nextSibling)!==null)break;P=E,E=P.parentNode}P=F}n=u===-1||h===-1?null:{start:u,end:h}}else n=null}n=n||{start:0,end:0}}else n=null;for(Bo={focusedElem:e,selectionRange:n},Kr=!1,z=t;z!==null;)if(t=z,e=t.child,(t.subtreeFlags&1028)!==0&&e!==null)e.return=t,z=e;else for(;z!==null;){t=z;try{var U=t.alternate;if((t.flags&1024)!==0)switch(t.tag){case 0:case 11:case 15:break;case 1:if(U!==null){var W=U.memoizedProps,De=U.memoizedState,y=t.stateNode,f=y.getSnapshotBeforeUpdate(t.elementType===t.type?W:ht(t.type,W),De);y.__reactInternalSnapshotBeforeUpdate=f}break;case 3:var w=t.stateNode.containerInfo;w.nodeType===1?w.textContent="":w.nodeType===9&&w.documentElement&&w.removeChild(w.documentElement);break;case 5:case 6:case 4:case 17:break;default:throw Error(l(163))}}catch(D){Ce(t,t.return,D)}if(e=t.sibling,e!==null){e.return=t.return,z=e;break}z=t.return}return U=Rc,Rc=!1,U}function _r(e,t,n){var r=t.updateQueue;if(r=r!==null?r.lastEffect:null,r!==null){var i=r=r.next;do{if((i.tag&e)===e){var o=i.destroy;i.destroy=void 0,o!==void 0&&Es(t,n,o)}i=i.next}while(i!==r)}}function Pi(e,t){if(t=t.updateQueue,t=t!==null?t.lastEffect:null,t!==null){var n=t=t.next;do{if((n.tag&e)===e){var r=n.create;n.destroy=r()}n=n.next}while(n!==t)}}function Ms(e){var t=e.ref;if(t!==null){var n=e.stateNode;switch(e.tag){case 5:e=n;break;default:e=n}typeof t=="function"?t(e):t.current=e}}function Nc(e){var t=e.alternate;t!==null&&(e.alternate=null,Nc(t)),e.child=null,e.deletions=null,e.sibling=null,e.tag===5&&(t=e.stateNode,t!==null&&(delete t[xt],delete t[mr],delete t[Ho],delete t[Kd],delete t[Xd])),e.stateNode=null,e.return=null,e.dependencies=null,e.memoizedProps=null,e.memoizedState=null,e.pendingProps=null,e.stateNode=null,e.updateQueue=null}function Lc(e){return e.tag===5||e.tag===3||e.tag===4}function Oc(e){e:for(;;){for(;e.sibling===null;){if(e.return===null||Lc(e.return))return null;e=e.return}for(e.sibling.return=e.return,e=e.sibling;e.tag!==5&&e.tag!==6&&e.tag!==18;){if(e.flags&2||e.child===null||e.tag===4)continue e;e.child.return=e,e=e.child}if(!(e.flags&2))return e.stateNode}}function Cs(e,t,n){var r=e.tag;if(r===5||r===6)e=e.stateNode,t?n.nodeType===8?n.parentNode.insertBefore(e,t):n.insertBefore(e,t):(n.nodeType===8?(t=n.parentNode,t.insertBefore(e,n)):(t=n,t.appendChild(e)),n=n._reactRootContainer,n!=null||t.onclick!==null||(t.onclick=ai));else if(r!==4&&(e=e.child,e!==null))for(Cs(e,t,n),e=e.sibling;e!==null;)Cs(e,t,n),e=e.sibling}function Ps(e,t,n){var r=e.tag;if(r===5||r===6)e=e.stateNode,t?n.insertBefore(e,t):n.appendChild(e);else if(r!==4&&(e=e.child,e!==null))for(Ps(e,t,n),e=e.sibling;e!==null;)Ps(e,t,n),e=e.sibling}var ze=null,ft=!1;function Qt(e,t,n){for(n=n.child;n!==null;)Fc(e,t,n),n=n.sibling}function Fc(e,t,n){if(kt&&typeof kt.onCommitFiberUnmount=="function")try{kt.onCommitFiberUnmount(Wr,n)}catch{}switch(n.tag){case 5:He||Fn(n,t);case 6:var r=ze,i=ft;ze=null,Qt(e,t,n),ze=r,ft=i,ze!==null&&(ft?(e=ze,n=n.stateNode,e.nodeType===8?e.parentNode.removeChild(n):e.removeChild(n)):ze.removeChild(n.stateNode));break;case 18:ze!==null&&(ft?(e=ze,n=n.stateNode,e.nodeType===8?Wo(e.parentNode,n):e.nodeType===1&&Wo(e,n),ir(e)):Wo(ze,n.stateNode));break;case 4:r=ze,i=ft,ze=n.stateNode.containerInfo,ft=!0,Qt(e,t,n),ze=r,ft=i;break;case 0:case 11:case 14:case 15:if(!He&&(r=n.updateQueue,r!==null&&(r=r.lastEffect,r!==null))){i=r=r.next;do{var o=i,a=o.destroy;o=o.tag,a!==void 0&&((o&2)!==0||(o&4)!==0)&&Es(n,t,a),i=i.next}while(i!==r)}Qt(e,t,n);break;case 1:if(!He&&(Fn(n,t),r=n.stateNode,typeof r.componentWillUnmount=="function"))try{r.props=n.memoizedProps,r.state=n.memoizedState,r.componentWillUnmount()}catch(u){Ce(n,t,u)}Qt(e,t,n);break;case 21:Qt(e,t,n);break;case 22:n.mode&1?(He=(r=He)||n.memoizedState!==null,Qt(e,t,n),He=r):Qt(e,t,n);break;default:Qt(e,t,n)}}function jc(e){var t=e.updateQueue;if(t!==null){e.updateQueue=null;var n=e.stateNode;n===null&&(n=e.stateNode=new pp),t.forEach(function(r){var i=Sp.bind(null,e,r);n.has(r)||(n.add(r),r.then(i,i))})}}function mt(e,t){var n=t.deletions;if(n!==null)for(var r=0;r<n.length;r++){var i=n[r];try{var o=e,a=t,u=a;e:for(;u!==null;){switch(u.tag){case 5:ze=u.stateNode,ft=!1;break e;case 3:ze=u.stateNode.containerInfo,ft=!0;break e;case 4:ze=u.stateNode.containerInfo,ft=!0;break e}u=u.return}if(ze===null)throw Error(l(160));Fc(o,a,i),ze=null,ft=!1;var h=i.alternate;h!==null&&(h.return=null),i.return=null}catch(S){Ce(i,t,S)}}if(t.subtreeFlags&12854)for(t=t.child;t!==null;)zc(t,e),t=t.sibling}function zc(e,t){var n=e.alternate,r=e.flags;switch(e.tag){case 0:case 11:case 14:case 15:if(mt(t,e),At(e),r&4){try{_r(3,e,e.return),Pi(3,e)}catch(W){Ce(e,e.return,W)}try{_r(5,e,e.return)}catch(W){Ce(e,e.return,W)}}break;case 1:mt(t,e),At(e),r&512&&n!==null&&Fn(n,n.return);break;case 5:if(mt(t,e),At(e),r&512&&n!==null&&Fn(n,n.return),e.flags&32){var i=e.stateNode;try{qn(i,"")}catch(W){Ce(e,e.return,W)}}if(r&4&&(i=e.stateNode,i!=null)){var o=e.memoizedProps,a=n!==null?n.memoizedProps:o,u=e.type,h=e.updateQueue;if(e.updateQueue=null,h!==null)try{u==="input"&&o.type==="radio"&&o.name!=null&&ha(i,o),so(u,a);var S=so(u,o);for(a=0;a<h.length;a+=2){var C=h[a],P=h[a+1];C==="style"?xa(i,P):C==="dangerouslySetInnerHTML"?wa(i,P):C==="children"?qn(i,P):V(i,C,P,S)}switch(u){case"input":to(i,o);break;case"textarea":ga(i,o);break;case"select":var E=i._wrapperState.wasMultiple;i._wrapperState.wasMultiple=!!o.multiple;var F=o.value;F!=null?gn(i,!!o.multiple,F,!1):E!==!!o.multiple&&(o.defaultValue!=null?gn(i,!!o.multiple,o.defaultValue,!0):gn(i,!!o.multiple,o.multiple?[]:"",!1))}i[mr]=o}catch(W){Ce(e,e.return,W)}}break;case 6:if(mt(t,e),At(e),r&4){if(e.stateNode===null)throw Error(l(162));i=e.stateNode,o=e.memoizedProps;try{i.nodeValue=o}catch(W){Ce(e,e.return,W)}}break;case 3:if(mt(t,e),At(e),r&4&&n!==null&&n.memoizedState.isDehydrated)try{ir(t.containerInfo)}catch(W){Ce(e,e.return,W)}break;case 4:mt(t,e),At(e);break;case 13:mt(t,e),At(e),i=e.child,i.flags&8192&&(o=i.memoizedState!==null,i.stateNode.isHidden=o,!o||i.alternate!==null&&i.alternate.memoizedState!==null||(Rs=Te())),r&4&&jc(e);break;case 22:if(C=n!==null&&n.memoizedState!==null,e.mode&1?(He=(S=He)||C,mt(t,e),He=S):mt(t,e),At(e),r&8192){if(S=e.memoizedState!==null,(e.stateNode.isHidden=S)&&!C&&(e.mode&1)!==0)for(z=e,C=e.child;C!==null;){for(P=z=C;z!==null;){switch(E=z,F=E.child,E.tag){case 0:case 11:case 14:case 15:_r(4,E,E.return);break;case 1:Fn(E,E.return);var U=E.stateNode;if(typeof U.componentWillUnmount=="function"){r=E,n=E.return;try{t=r,U.props=t.memoizedProps,U.state=t.memoizedState,U.componentWillUnmount()}catch(W){Ce(r,n,W)}}break;case 5:Fn(E,E.return);break;case 22:if(E.memoizedState!==null){Uc(P);continue}}F!==null?(F.return=E,z=F):Uc(P)}C=C.sibling}e:for(C=null,P=e;;){if(P.tag===5){if(C===null){C=P;try{i=P.stateNode,S?(o=i.style,typeof o.setProperty=="function"?o.setProperty("display","none","important"):o.display="none"):(u=P.stateNode,h=P.memoizedProps.style,a=h!=null&&h.hasOwnProperty("display")?h.display:null,u.style.display=ka("display",a))}catch(W){Ce(e,e.return,W)}}}else if(P.tag===6){if(C===null)try{P.stateNode.nodeValue=S?"":P.memoizedProps}catch(W){Ce(e,e.return,W)}}else if((P.tag!==22&&P.tag!==23||P.memoizedState===null||P===e)&&P.child!==null){P.child.return=P,P=P.child;continue}if(P===e)break e;for(;P.sibling===null;){if(P.return===null||P.return===e)break e;C===P&&(C=null),P=P.return}C===P&&(C=null),P.sibling.return=P.return,P=P.sibling}}break;case 19:mt(t,e),At(e),r&4&&jc(e);break;case 21:break;default:mt(t,e),At(e)}}function At(e){var t=e.flags;if(t&2){try{e:{for(var n=e.return;n!==null;){if(Lc(n)){var r=n;break e}n=n.return}throw Error(l(160))}switch(r.tag){case 5:var i=r.stateNode;r.flags&32&&(qn(i,""),r.flags&=-33);var o=Oc(e);Ps(e,o,i);break;case 3:case 4:var a=r.stateNode.containerInfo,u=Oc(e);Cs(e,u,a);break;default:throw Error(l(161))}}catch(h){Ce(e,e.return,h)}e.flags&=-3}t&4096&&(e.flags&=-4097)}function fp(e,t,n){z=e,Bc(e)}function Bc(e,t,n){for(var r=(e.mode&1)!==0;z!==null;){var i=z,o=i.child;if(i.tag===22&&r){var a=i.memoizedState!==null||Ci;if(!a){var u=i.alternate,h=u!==null&&u.memoizedState!==null||He;u=Ci;var S=He;if(Ci=a,(He=h)&&!S)for(z=i;z!==null;)a=z,h=a.child,a.tag===22&&a.memoizedState!==null?Wc(i):h!==null?(h.return=a,z=h):Wc(i);for(;o!==null;)z=o,Bc(o),o=o.sibling;z=i,Ci=u,He=S}$c(e)}else(i.subtreeFlags&8772)!==0&&o!==null?(o.return=i,z=o):$c(e)}}function $c(e){for(;z!==null;){var t=z;if((t.flags&8772)!==0){var n=t.alternate;try{if((t.flags&8772)!==0)switch(t.tag){case 0:case 11:case 15:He||Pi(5,t);break;case 1:var r=t.stateNode;if(t.flags&4&&!He)if(n===null)r.componentDidMount();else{var i=t.elementType===t.type?n.memoizedProps:ht(t.type,n.memoizedProps);r.componentDidUpdate(i,n.memoizedState,r.__reactInternalSnapshotBeforeUpdate)}var o=t.updateQueue;o!==null&&Ul(t,o,r);break;case 3:var a=t.updateQueue;if(a!==null){if(n=null,t.child!==null)switch(t.child.tag){case 5:n=t.child.stateNode;break;case 1:n=t.child.stateNode}Ul(t,a,n)}break;case 5:var u=t.stateNode;if(n===null&&t.flags&4){n=u;var h=t.memoizedProps;switch(t.type){case"button":case"input":case"select":case"textarea":h.autoFocus&&n.focus();break;case"img":h.src&&(n.src=h.src)}}break;case 6:break;case 4:break;case 12:break;case 13:if(t.memoizedState===null){var S=t.alternate;if(S!==null){var C=S.memoizedState;if(C!==null){var P=C.dehydrated;P!==null&&ir(P)}}}break;case 19:case 17:case 21:case 22:case 23:case 25:break;default:throw Error(l(163))}He||t.flags&512&&Ms(t)}catch(E){Ce(t,t.return,E)}}if(t===e){z=null;break}if(n=t.sibling,n!==null){n.return=t.return,z=n;break}z=t.return}}function Uc(e){for(;z!==null;){var t=z;if(t===e){z=null;break}var n=t.sibling;if(n!==null){n.return=t.return,z=n;break}z=t.return}}function Wc(e){for(;z!==null;){var t=z;try{switch(t.tag){case 0:case 11:case 15:var n=t.return;try{Pi(4,t)}catch(h){Ce(t,n,h)}break;case 1:var r=t.stateNode;if(typeof r.componentDidMount=="function"){var i=t.return;try{r.componentDidMount()}catch(h){Ce(t,i,h)}}var o=t.return;try{Ms(t)}catch(h){Ce(t,o,h)}break;case 5:var a=t.return;try{Ms(t)}catch(h){Ce(t,a,h)}}}catch(h){Ce(t,t.return,h)}if(t===e){z=null;break}var u=t.sibling;if(u!==null){u.return=t.return,z=u;break}z=t.return}}var mp=Math.ceil,Ti=se.ReactCurrentDispatcher,Ts=se.ReactCurrentOwner,lt=se.ReactCurrentBatchConfig,ce=0,Fe=null,Re=null,Be=0,rt=0,jn=Wt(0),Le=0,Er=null,un=0,Di=0,Ds=0,Mr=null,Xe=null,Rs=0,zn=1/0,Rt=null,Ri=!1,Ns=null,Kt=null,Ni=!1,Xt=null,Li=0,Cr=0,Ls=null,Oi=-1,Fi=0;function Ge(){return(ce&6)!==0?Te():Oi!==-1?Oi:Oi=Te()}function Yt(e){return(e.mode&1)===0?1:(ce&2)!==0&&Be!==0?Be&-Be:Jd.transition!==null?(Fi===0&&(Fi=Oa()),Fi):(e=me,e!==0||(e=window.event,e=e===void 0?16:Va(e.type)),e)}function gt(e,t,n,r){if(50<Cr)throw Cr=0,Ls=null,Error(l(185));Zn(e,n,r),((ce&2)===0||e!==Fe)&&(e===Fe&&((ce&2)===0&&(Di|=n),Le===4&&Jt(e,Be)),Ye(e,r),n===1&&ce===0&&(t.mode&1)===0&&(zn=Te()+500,di&&Vt()))}function Ye(e,t){var n=e.callbackNode;Ju(e,t);var r=Gr(e,e===Fe?Be:0);if(r===0)n!==null&&Ra(n),e.callbackNode=null,e.callbackPriority=0;else if(t=r&-r,e.callbackPriority!==t){if(n!=null&&Ra(n),t===1)e.tag===0?Yd(Vc.bind(null,e)):Pl(Vc.bind(null,e)),qd(function(){(ce&6)===0&&Vt()}),n=null;else{switch(Fa(r)){case 1:n=fo;break;case 4:n=Na;break;case 16:n=Ur;break;case 536870912:n=La;break;default:n=Ur}n=Zc(n,Hc.bind(null,e))}e.callbackPriority=t,e.callbackNode=n}}function Hc(e,t){if(Oi=-1,Fi=0,(ce&6)!==0)throw Error(l(327));var n=e.callbackNode;if(Bn()&&e.callbackNode!==n)return null;var r=Gr(e,e===Fe?Be:0);if(r===0)return null;if((r&30)!==0||(r&e.expiredLanes)!==0||t)t=ji(e,r);else{t=r;var i=ce;ce|=2;var o=qc();(Fe!==e||Be!==t)&&(Rt=null,zn=Te()+500,pn(e,t));do try{vp();break}catch(u){Gc(e,u)}while(!0);Zo(),Ti.current=o,ce=i,Re!==null?t=0:(Fe=null,Be=0,t=Le)}if(t!==0){if(t===2&&(i=mo(e),i!==0&&(r=i,t=Os(e,i))),t===1)throw n=Er,pn(e,0),Jt(e,r),Ye(e,Te()),n;if(t===6)Jt(e,r);else{if(i=e.current.alternate,(r&30)===0&&!gp(i)&&(t=ji(e,r),t===2&&(o=mo(e),o!==0&&(r=o,t=Os(e,o))),t===1))throw n=Er,pn(e,0),Jt(e,r),Ye(e,Te()),n;switch(e.finishedWork=i,e.finishedLanes=r,t){case 0:case 1:throw Error(l(345));case 2:hn(e,Xe,Rt);break;case 3:if(Jt(e,r),(r&130023424)===r&&(t=Rs+500-Te(),10<t)){if(Gr(e,0)!==0)break;if(i=e.suspendedLanes,(i&r)!==r){Ge(),e.pingedLanes|=e.suspendedLanes&i;break}e.timeoutHandle=Uo(hn.bind(null,e,Xe,Rt),t);break}hn(e,Xe,Rt);break;case 4:if(Jt(e,r),(r&4194240)===r)break;for(t=e.eventTimes,i=-1;0<r;){var a=31-ut(r);o=1<<a,a=t[a],a>i&&(i=a),r&=~o}if(r=i,r=Te()-r,r=(120>r?120:480>r?480:1080>r?1080:1920>r?1920:3e3>r?3e3:4320>r?4320:1960*mp(r/1960))-r,10<r){e.timeoutHandle=Uo(hn.bind(null,e,Xe,Rt),r);break}hn(e,Xe,Rt);break;case 5:hn(e,Xe,Rt);break;default:throw Error(l(329))}}}return Ye(e,Te()),e.callbackNode===n?Hc.bind(null,e):null}function Os(e,t){var n=Mr;return e.current.memoizedState.isDehydrated&&(pn(e,t).flags|=256),e=ji(e,t),e!==2&&(t=Xe,Xe=n,t!==null&&Fs(t)),e}function Fs(e){Xe===null?Xe=e:Xe.push.apply(Xe,e)}function gp(e){for(var t=e;;){if(t.flags&16384){var n=t.updateQueue;if(n!==null&&(n=n.stores,n!==null))for(var r=0;r<n.length;r++){var i=n[r],o=i.getSnapshot;i=i.value;try{if(!dt(o(),i))return!1}catch{return!1}}}if(n=t.child,t.subtreeFlags&16384&&n!==null)n.return=t,t=n;else{if(t===e)break;for(;t.sibling===null;){if(t.return===null||t.return===e)return!0;t=t.return}t.sibling.return=t.return,t=t.sibling}}return!0}function Jt(e,t){for(t&=~Ds,t&=~Di,e.suspendedLanes|=t,e.pingedLanes&=~t,e=e.expirationTimes;0<t;){var n=31-ut(t),r=1<<n;e[n]=-1,t&=~r}}function Vc(e){if((ce&6)!==0)throw Error(l(327));Bn();var t=Gr(e,0);if((t&1)===0)return Ye(e,Te()),null;var n=ji(e,t);if(e.tag!==0&&n===2){var r=mo(e);r!==0&&(t=r,n=Os(e,r))}if(n===1)throw n=Er,pn(e,0),Jt(e,t),Ye(e,Te()),n;if(n===6)throw Error(l(345));return e.finishedWork=e.current.alternate,e.finishedLanes=t,hn(e,Xe,Rt),Ye(e,Te()),null}function js(e,t){var n=ce;ce|=1;try{return e(t)}finally{ce=n,ce===0&&(zn=Te()+500,di&&Vt())}}function dn(e){Xt!==null&&Xt.tag===0&&(ce&6)===0&&Bn();var t=ce;ce|=1;var n=lt.transition,r=me;try{if(lt.transition=null,me=1,e)return e()}finally{me=r,lt.transition=n,ce=t,(ce&6)===0&&Vt()}}function zs(){rt=jn.current,xe(jn)}function pn(e,t){e.finishedWork=null,e.finishedLanes=0;var n=e.timeoutHandle;if(n!==-1&&(e.timeoutHandle=-1,Gd(n)),Re!==null)for(n=Re.return;n!==null;){var r=n;switch(Qo(r),r.tag){case 1:r=r.type.childContextTypes,r!=null&&ci();break;case 3:Ln(),xe(qe),xe($e),as();break;case 5:os(r);break;case 4:Ln();break;case 13:xe(_e);break;case 19:xe(_e);break;case 10:es(r.type._context);break;case 22:case 23:zs()}n=n.return}if(Fe=e,Re=e=Zt(e.current,null),Be=rt=t,Le=0,Er=null,Ds=Di=un=0,Xe=Mr=null,an!==null){for(t=0;t<an.length;t++)if(n=an[t],r=n.interleaved,r!==null){n.interleaved=null;var i=r.next,o=n.pending;if(o!==null){var a=o.next;o.next=i,r.next=a}n.pending=r}an=null}return e}function Gc(e,t){do{var n=Re;try{if(Zo(),xi.current=Ii,Si){for(var r=Ee.memoizedState;r!==null;){var i=r.queue;i!==null&&(i.pending=null),r=r.next}Si=!1}if(cn=0,Oe=Ne=Ee=null,xr=!1,Sr=0,Ts.current=null,n===null||n.return===null){Le=1,Er=t,Re=null;break}e:{var o=e,a=n.return,u=n,h=t;if(t=Be,u.flags|=32768,h!==null&&typeof h=="object"&&typeof h.then=="function"){var S=h,C=u,P=C.tag;if((C.mode&1)===0&&(P===0||P===11||P===15)){var E=C.alternate;E?(C.updateQueue=E.updateQueue,C.memoizedState=E.memoizedState,C.lanes=E.lanes):(C.updateQueue=null,C.memoizedState=null)}var F=yc(a);if(F!==null){F.flags&=-257,vc(F,a,u,o,t),F.mode&1&&gc(o,S,t),t=F,h=S;var U=t.updateQueue;if(U===null){var W=new Set;W.add(h),t.updateQueue=W}else U.add(h);break e}else{if((t&1)===0){gc(o,S,t),Bs();break e}h=Error(l(426))}}else if(be&&u.mode&1){var De=yc(a);if(De!==null){(De.flags&65536)===0&&(De.flags|=256),vc(De,a,u,o,t),Yo(On(h,u));break e}}o=h=On(h,u),Le!==4&&(Le=2),Mr===null?Mr=[o]:Mr.push(o),o=a;do{switch(o.tag){case 3:o.flags|=65536,t&=-t,o.lanes|=t;var y=fc(o,h,t);$l(o,y);break e;case 1:u=h;var f=o.type,w=o.stateNode;if((o.flags&128)===0&&(typeof f.getDerivedStateFromError=="function"||w!==null&&typeof w.componentDidCatch=="function"&&(Kt===null||!Kt.has(w)))){o.flags|=65536,t&=-t,o.lanes|=t;var D=mc(o,u,t);$l(o,D);break e}}o=o.return}while(o!==null)}Kc(n)}catch(G){t=G,Re===n&&n!==null&&(Re=n=n.return);continue}break}while(!0)}function qc(){var e=Ti.current;return Ti.current=Ii,e===null?Ii:e}function Bs(){(Le===0||Le===3||Le===2)&&(Le=4),Fe===null||(un&268435455)===0&&(Di&268435455)===0||Jt(Fe,Be)}function ji(e,t){var n=ce;ce|=2;var r=qc();(Fe!==e||Be!==t)&&(Rt=null,pn(e,t));do try{yp();break}catch(i){Gc(e,i)}while(!0);if(Zo(),ce=n,Ti.current=r,Re!==null)throw Error(l(261));return Fe=null,Be=0,Le}function yp(){for(;Re!==null;)Qc(Re)}function vp(){for(;Re!==null&&!Wu();)Qc(Re)}function Qc(e){var t=Jc(e.alternate,e,rt);e.memoizedProps=e.pendingProps,t===null?Kc(e):Re=t,Ts.current=null}function Kc(e){var t=e;do{var n=t.alternate;if(e=t.return,(t.flags&32768)===0){if(n=up(n,t,rt),n!==null){Re=n;return}}else{if(n=dp(n,t),n!==null){n.flags&=32767,Re=n;return}if(e!==null)e.flags|=32768,e.subtreeFlags=0,e.deletions=null;else{Le=6,Re=null;return}}if(t=t.sibling,t!==null){Re=t;return}Re=t=e}while(t!==null);Le===0&&(Le=5)}function hn(e,t,n){var r=me,i=lt.transition;try{lt.transition=null,me=1,wp(e,t,n,r)}finally{lt.transition=i,me=r}return null}function wp(e,t,n,r){do Bn();while(Xt!==null);if((ce&6)!==0)throw Error(l(327));n=e.finishedWork;var i=e.finishedLanes;if(n===null)return null;if(e.finishedWork=null,e.finishedLanes=0,n===e.current)throw Error(l(177));e.callbackNode=null,e.callbackPriority=0;var o=n.lanes|n.childLanes;if(Zu(e,o),e===Fe&&(Re=Fe=null,Be=0),(n.subtreeFlags&2064)===0&&(n.flags&2064)===0||Ni||(Ni=!0,Zc(Ur,function(){return Bn(),null})),o=(n.flags&15990)!==0,(n.subtreeFlags&15990)!==0||o){o=lt.transition,lt.transition=null;var a=me;me=1;var u=ce;ce|=4,Ts.current=null,hp(e,n),zc(n,e),zd(Bo),Kr=!!zo,Bo=zo=null,e.current=n,fp(n),Hu(),ce=u,me=a,lt.transition=o}else e.current=n;if(Ni&&(Ni=!1,Xt=e,Li=i),o=e.pendingLanes,o===0&&(Kt=null),qu(n.stateNode),Ye(e,Te()),t!==null)for(r=e.onRecoverableError,n=0;n<t.length;n++)i=t[n],r(i.value,{componentStack:i.stack,digest:i.digest});if(Ri)throw Ri=!1,e=Ns,Ns=null,e;return(Li&1)!==0&&e.tag!==0&&Bn(),o=e.pendingLanes,(o&1)!==0?e===Ls?Cr++:(Cr=0,Ls=e):Cr=0,Vt(),null}function Bn(){if(Xt!==null){var e=Fa(Li),t=lt.transition,n=me;try{if(lt.transition=null,me=16>e?16:e,Xt===null)var r=!1;else{if(e=Xt,Xt=null,Li=0,(ce&6)!==0)throw Error(l(331));var i=ce;for(ce|=4,z=e.current;z!==null;){var o=z,a=o.child;if((z.flags&16)!==0){var u=o.deletions;if(u!==null){for(var h=0;h<u.length;h++){var S=u[h];for(z=S;z!==null;){var C=z;switch(C.tag){case 0:case 11:case 15:_r(8,C,o)}var P=C.child;if(P!==null)P.return=C,z=P;else for(;z!==null;){C=z;var E=C.sibling,F=C.return;if(Nc(C),C===S){z=null;break}if(E!==null){E.return=F,z=E;break}z=F}}}var U=o.alternate;if(U!==null){var W=U.child;if(W!==null){U.child=null;do{var De=W.sibling;W.sibling=null,W=De}while(W!==null)}}z=o}}if((o.subtreeFlags&2064)!==0&&a!==null)a.return=o,z=a;else e:for(;z!==null;){if(o=z,(o.flags&2048)!==0)switch(o.tag){case 0:case 11:case 15:_r(9,o,o.return)}var y=o.sibling;if(y!==null){y.return=o.return,z=y;break e}z=o.return}}var f=e.current;for(z=f;z!==null;){a=z;var w=a.child;if((a.subtreeFlags&2064)!==0&&w!==null)w.return=a,z=w;else e:for(a=f;z!==null;){if(u=z,(u.flags&2048)!==0)try{switch(u.tag){case 0:case 11:case 15:Pi(9,u)}}catch(G){Ce(u,u.return,G)}if(u===a){z=null;break e}var D=u.sibling;if(D!==null){D.return=u.return,z=D;break e}z=u.return}}if(ce=i,Vt(),kt&&typeof kt.onPostCommitFiberRoot=="function")try{kt.onPostCommitFiberRoot(Wr,e)}catch{}r=!0}return r}finally{me=n,lt.transition=t}}return!1}function Xc(e,t,n){t=On(n,t),t=fc(e,t,1),e=qt(e,t,1),t=Ge(),e!==null&&(Zn(e,1,t),Ye(e,t))}function Ce(e,t,n){if(e.tag===3)Xc(e,e,n);else for(;t!==null;){if(t.tag===3){Xc(t,e,n);break}else if(t.tag===1){var r=t.stateNode;if(typeof t.type.getDerivedStateFromError=="function"||typeof r.componentDidCatch=="function"&&(Kt===null||!Kt.has(r))){e=On(n,e),e=mc(t,e,1),t=qt(t,e,1),e=Ge(),t!==null&&(Zn(t,1,e),Ye(t,e));break}}t=t.return}}function kp(e,t,n){var r=e.pingCache;r!==null&&r.delete(t),t=Ge(),e.pingedLanes|=e.suspendedLanes&n,Fe===e&&(Be&n)===n&&(Le===4||Le===3&&(Be&130023424)===Be&&500>Te()-Rs?pn(e,0):Ds|=n),Ye(e,t)}function Yc(e,t){t===0&&((e.mode&1)===0?t=1:(t=Vr,Vr<<=1,(Vr&130023424)===0&&(Vr=4194304)));var n=Ge();e=Pt(e,t),e!==null&&(Zn(e,t,n),Ye(e,n))}function xp(e){var t=e.memoizedState,n=0;t!==null&&(n=t.retryLane),Yc(e,n)}function Sp(e,t){var n=0;switch(e.tag){case 13:var r=e.stateNode,i=e.memoizedState;i!==null&&(n=i.retryLane);break;case 19:r=e.stateNode;break;default:throw Error(l(314))}r!==null&&r.delete(t),Yc(e,n)}var Jc;Jc=function(e,t,n){if(e!==null)if(e.memoizedProps!==t.pendingProps||qe.current)Ke=!0;else{if((e.lanes&n)===0&&(t.flags&128)===0)return Ke=!1,cp(e,t,n);Ke=(e.flags&131072)!==0}else Ke=!1,be&&(t.flags&1048576)!==0&&Tl(t,hi,t.index);switch(t.lanes=0,t.tag){case 2:var r=t.type;Mi(e,t),e=t.pendingProps;var i=Mn(t,$e.current);Nn(t,n),i=us(null,t,r,e,i,n);var o=ds();return t.flags|=1,typeof i=="object"&&i!==null&&typeof i.render=="function"&&i.$$typeof===void 0?(t.tag=1,t.memoizedState=null,t.updateQueue=null,Qe(r)?(o=!0,ui(t)):o=!1,t.memoizedState=i.state!==null&&i.state!==void 0?i.state:null,rs(t),i.updater=_i,t.stateNode=i,i._reactInternals=t,ys(t,r,e,n),t=xs(null,t,r,!0,o,n)):(t.tag=0,be&&o&&qo(t),Ve(null,t,i,n),t=t.child),t;case 16:r=t.elementType;e:{switch(Mi(e,t),e=t.pendingProps,i=r._init,r=i(r._payload),t.type=r,i=t.tag=Ap(r),e=ht(r,e),i){case 0:t=ks(null,t,r,e,n);break e;case 1:t=Ac(null,t,r,e,n);break e;case 11:t=wc(null,t,r,e,n);break e;case 14:t=kc(null,t,r,ht(r.type,e),n);break e}throw Error(l(306,r,""))}return t;case 0:return r=t.type,i=t.pendingProps,i=t.elementType===r?i:ht(r,i),ks(e,t,r,i,n);case 1:return r=t.type,i=t.pendingProps,i=t.elementType===r?i:ht(r,i),Ac(e,t,r,i,n);case 3:e:{if(Ic(t),e===null)throw Error(l(387));r=t.pendingProps,o=t.memoizedState,i=o.element,Bl(e,t),wi(t,r,null,n);var a=t.memoizedState;if(r=a.element,o.isDehydrated)if(o={element:r,isDehydrated:!1,cache:a.cache,pendingSuspenseBoundaries:a.pendingSuspenseBoundaries,transitions:a.transitions},t.updateQueue.baseState=o,t.memoizedState=o,t.flags&256){i=On(Error(l(423)),t),t=_c(e,t,r,n,i);break e}else if(r!==i){i=On(Error(l(424)),t),t=_c(e,t,r,n,i);break e}else for(nt=Ut(t.stateNode.containerInfo.firstChild),tt=t,be=!0,pt=null,n=jl(t,null,r,n),t.child=n;n;)n.flags=n.flags&-3|4096,n=n.sibling;else{if(Tn(),r===i){t=Dt(e,t,n);break e}Ve(e,t,r,n)}t=t.child}return t;case 5:return Wl(t),e===null&&Xo(t),r=t.type,i=t.pendingProps,o=e!==null?e.memoizedProps:null,a=i.children,$o(r,i)?a=null:o!==null&&$o(r,o)&&(t.flags|=32),bc(e,t),Ve(e,t,a,n),t.child;case 6:return e===null&&Xo(t),null;case 13:return Ec(e,t,n);case 4:return is(t,t.stateNode.containerInfo),r=t.pendingProps,e===null?t.child=Dn(t,null,r,n):Ve(e,t,r,n),t.child;case 11:return r=t.type,i=t.pendingProps,i=t.elementType===r?i:ht(r,i),wc(e,t,r,i,n);case 7:return Ve(e,t,t.pendingProps,n),t.child;case 8:return Ve(e,t,t.pendingProps.children,n),t.child;case 12:return Ve(e,t,t.pendingProps.children,n),t.child;case 10:e:{if(r=t.type._context,i=t.pendingProps,o=t.memoizedProps,a=i.value,we(gi,r._currentValue),r._currentValue=a,o!==null)if(dt(o.value,a)){if(o.children===i.children&&!qe.current){t=Dt(e,t,n);break e}}else for(o=t.child,o!==null&&(o.return=t);o!==null;){var u=o.dependencies;if(u!==null){a=o.child;for(var h=u.firstContext;h!==null;){if(h.context===r){if(o.tag===1){h=Tt(-1,n&-n),h.tag=2;var S=o.updateQueue;if(S!==null){S=S.shared;var C=S.pending;C===null?h.next=h:(h.next=C.next,C.next=h),S.pending=h}}o.lanes|=n,h=o.alternate,h!==null&&(h.lanes|=n),ts(o.return,n,t),u.lanes|=n;break}h=h.next}}else if(o.tag===10)a=o.type===t.type?null:o.child;else if(o.tag===18){if(a=o.return,a===null)throw Error(l(341));a.lanes|=n,u=a.alternate,u!==null&&(u.lanes|=n),ts(a,n,t),a=o.sibling}else a=o.child;if(a!==null)a.return=o;else for(a=o;a!==null;){if(a===t){a=null;break}if(o=a.sibling,o!==null){o.return=a.return,a=o;break}a=a.return}o=a}Ve(e,t,i.children,n),t=t.child}return t;case 9:return i=t.type,r=t.pendingProps.children,Nn(t,n),i=st(i),r=r(i),t.flags|=1,Ve(e,t,r,n),t.child;case 14:return r=t.type,i=ht(r,t.pendingProps),i=ht(r.type,i),kc(e,t,r,i,n);case 15:return xc(e,t,t.type,t.pendingProps,n);case 17:return r=t.type,i=t.pendingProps,i=t.elementType===r?i:ht(r,i),Mi(e,t),t.tag=1,Qe(r)?(e=!0,ui(t)):e=!1,Nn(t,n),pc(t,r,i),ys(t,r,i,n),xs(null,t,r,!0,e,n);case 19:return Cc(e,t,n);case 22:return Sc(e,t,n)}throw Error(l(156,t.tag))};function Zc(e,t){return Da(e,t)}function bp(e,t,n,r){this.tag=e,this.key=n,this.sibling=this.child=this.return=this.stateNode=this.type=this.elementType=null,this.index=0,this.ref=null,this.pendingProps=t,this.dependencies=this.memoizedState=this.updateQueue=this.memoizedProps=null,this.mode=r,this.subtreeFlags=this.flags=0,this.deletions=null,this.childLanes=this.lanes=0,this.alternate=null}function ct(e,t,n,r){return new bp(e,t,n,r)}function $s(e){return e=e.prototype,!(!e||!e.isReactComponent)}function Ap(e){if(typeof e=="function")return $s(e)?1:0;if(e!=null){if(e=e.$$typeof,e===ye)return 11;if(e===he)return 14}return 2}function Zt(e,t){var n=e.alternate;return n===null?(n=ct(e.tag,t,e.key,e.mode),n.elementType=e.elementType,n.type=e.type,n.stateNode=e.stateNode,n.alternate=e,e.alternate=n):(n.pendingProps=t,n.type=e.type,n.flags=0,n.subtreeFlags=0,n.deletions=null),n.flags=e.flags&14680064,n.childLanes=e.childLanes,n.lanes=e.lanes,n.child=e.child,n.memoizedProps=e.memoizedProps,n.memoizedState=e.memoizedState,n.updateQueue=e.updateQueue,t=e.dependencies,n.dependencies=t===null?null:{lanes:t.lanes,firstContext:t.firstContext},n.sibling=e.sibling,n.index=e.index,n.ref=e.ref,n}function zi(e,t,n,r,i,o){var a=2;if(r=e,typeof e=="function")$s(e)&&(a=1);else if(typeof e=="string")a=5;else e:switch(e){case Q:return fn(n.children,i,o,t);case Z:a=8,i|=8;break;case ne:return e=ct(12,n,t,i|2),e.elementType=ne,e.lanes=o,e;case Me:return e=ct(13,n,t,i),e.elementType=Me,e.lanes=o,e;case le:return e=ct(19,n,t,i),e.elementType=le,e.lanes=o,e;case ge:return Bi(n,i,o,t);default:if(typeof e=="object"&&e!==null)switch(e.$$typeof){case ae:a=10;break e;case Ie:a=9;break e;case ye:a=11;break e;case he:a=14;break e;case Pe:a=16,r=null;break e}throw Error(l(130,e==null?e:typeof e,""))}return t=ct(a,n,t,i),t.elementType=e,t.type=r,t.lanes=o,t}function fn(e,t,n,r){return e=ct(7,e,r,t),e.lanes=n,e}function Bi(e,t,n,r){return e=ct(22,e,r,t),e.elementType=ge,e.lanes=n,e.stateNode={isHidden:!1},e}function Us(e,t,n){return e=ct(6,e,null,t),e.lanes=n,e}function Ws(e,t,n){return t=ct(4,e.children!==null?e.children:[],e.key,t),t.lanes=n,t.stateNode={containerInfo:e.containerInfo,pendingChildren:null,implementation:e.implementation},t}function Ip(e,t,n,r,i){this.tag=t,this.containerInfo=e,this.finishedWork=this.pingCache=this.current=this.pendingChildren=null,this.timeoutHandle=-1,this.callbackNode=this.pendingContext=this.context=null,this.callbackPriority=0,this.eventTimes=go(0),this.expirationTimes=go(-1),this.entangledLanes=this.finishedLanes=this.mutableReadLanes=this.expiredLanes=this.pingedLanes=this.suspendedLanes=this.pendingLanes=0,this.entanglements=go(0),this.identifierPrefix=r,this.onRecoverableError=i,this.mutableSourceEagerHydrationData=null}function Hs(e,t,n,r,i,o,a,u,h){return e=new Ip(e,t,n,u,h),t===1?(t=1,o===!0&&(t|=8)):t=0,o=ct(3,null,null,t),e.current=o,o.stateNode=e,o.memoizedState={element:r,isDehydrated:n,cache:null,transitions:null,pendingSuspenseBoundaries:null},rs(o),e}function _p(e,t,n){var r=3<arguments.length&&arguments[3]!==void 0?arguments[3]:null;return{$$typeof:$,key:r==null?null:""+r,children:e,containerInfo:t,implementation:n}}function eu(e){if(!e)return Ht;e=e._reactInternals;e:{if(tn(e)!==e||e.tag!==1)throw Error(l(170));var t=e;do{switch(t.tag){case 3:t=t.stateNode.context;break e;case 1:if(Qe(t.type)){t=t.stateNode.__reactInternalMemoizedMergedChildContext;break e}}t=t.return}while(t!==null);throw Error(l(171))}if(e.tag===1){var n=e.type;if(Qe(n))return Ml(e,n,t)}return t}function tu(e,t,n,r,i,o,a,u,h){return e=Hs(n,r,!0,e,i,o,a,u,h),e.context=eu(null),n=e.current,r=Ge(),i=Yt(n),o=Tt(r,i),o.callback=t??null,qt(n,o,i),e.current.lanes=i,Zn(e,i,r),Ye(e,r),e}function $i(e,t,n,r){var i=t.current,o=Ge(),a=Yt(i);return n=eu(n),t.context===null?t.context=n:t.pendingContext=n,t=Tt(o,a),t.payload={element:e},r=r===void 0?null:r,r!==null&&(t.callback=r),e=qt(i,t,a),e!==null&&(gt(e,i,a,o),vi(e,i,a)),a}function Ui(e){if(e=e.current,!e.child)return null;switch(e.child.tag){case 5:return e.child.stateNode;default:return e.child.stateNode}}function nu(e,t){if(e=e.memoizedState,e!==null&&e.dehydrated!==null){var n=e.retryLane;e.retryLane=n!==0&&n<t?n:t}}function Vs(e,t){nu(e,t),(e=e.alternate)&&nu(e,t)}function Ep(){return null}var ru=typeof reportError=="function"?reportError:function(e){console.error(e)};function Gs(e){this._internalRoot=e}Wi.prototype.render=Gs.prototype.render=function(e){var t=this._internalRoot;if(t===null)throw Error(l(409));$i(e,t,null,null)},Wi.prototype.unmount=Gs.prototype.unmount=function(){var e=this._internalRoot;if(e!==null){this._internalRoot=null;var t=e.containerInfo;dn(function(){$i(null,e,null,null)}),t[_t]=null}};function Wi(e){this._internalRoot=e}Wi.prototype.unstable_scheduleHydration=function(e){if(e){var t=Ba();e={blockedOn:null,target:e,priority:t};for(var n=0;n<zt.length&&t!==0&&t<zt[n].priority;n++);zt.splice(n,0,e),n===0&&Wa(e)}};function qs(e){return!(!e||e.nodeType!==1&&e.nodeType!==9&&e.nodeType!==11)}function Hi(e){return!(!e||e.nodeType!==1&&e.nodeType!==9&&e.nodeType!==11&&(e.nodeType!==8||e.nodeValue!==" react-mount-point-unstable "))}function iu(){}function Mp(e,t,n,r,i){if(i){if(typeof r=="function"){var o=r;r=function(){var S=Ui(a);o.call(S)}}var a=tu(t,r,e,0,null,!1,!1,"",iu);return e._reactRootContainer=a,e[_t]=a.current,hr(e.nodeType===8?e.parentNode:e),dn(),a}for(;i=e.lastChild;)e.removeChild(i);if(typeof r=="function"){var u=r;r=function(){var S=Ui(h);u.call(S)}}var h=Hs(e,0,!1,null,null,!1,!1,"",iu);return e._reactRootContainer=h,e[_t]=h.current,hr(e.nodeType===8?e.parentNode:e),dn(function(){$i(t,h,n,r)}),h}function Vi(e,t,n,r,i){var o=n._reactRootContainer;if(o){var a=o;if(typeof i=="function"){var u=i;i=function(){var h=Ui(a);u.call(h)}}$i(t,a,e,i)}else a=Mp(n,t,e,i,r);return Ui(a)}ja=function(e){switch(e.tag){case 3:var t=e.stateNode;if(t.current.memoizedState.isDehydrated){var n=Jn(t.pendingLanes);n!==0&&(yo(t,n|1),Ye(t,Te()),(ce&6)===0&&(zn=Te()+500,Vt()))}break;case 13:dn(function(){var r=Pt(e,1);if(r!==null){var i=Ge();gt(r,e,1,i)}}),Vs(e,1)}},vo=function(e){if(e.tag===13){var t=Pt(e,134217728);if(t!==null){var n=Ge();gt(t,e,134217728,n)}Vs(e,134217728)}},za=function(e){if(e.tag===13){var t=Yt(e),n=Pt(e,t);if(n!==null){var r=Ge();gt(n,e,t,r)}Vs(e,t)}},Ba=function(){return me},$a=function(e,t){var n=me;try{return me=e,t()}finally{me=n}},co=function(e,t,n){switch(t){case"input":if(to(e,n),t=n.name,n.type==="radio"&&t!=null){for(n=e;n.parentNode;)n=n.parentNode;for(n=n.querySelectorAll("input[name="+JSON.stringify(""+t)+'][type="radio"]'),t=0;t<n.length;t++){var r=n[t];if(r!==e&&r.form===e.form){var i=li(r);if(!i)throw Error(l(90));da(r),to(r,i)}}}break;case"textarea":ga(e,n);break;case"select":t=n.value,t!=null&&gn(e,!!n.multiple,t,!1)}},Ia=js,_a=dn;var Cp={usingClientEntryPoint:!1,Events:[gr,_n,li,ba,Aa,js]},Pr={findFiberByHostInstance:nn,bundleType:0,version:"18.3.1",rendererPackageName:"react-dom"},Pp={bundleType:Pr.bundleType,version:Pr.version,rendererPackageName:Pr.rendererPackageName,rendererConfig:Pr.rendererConfig,overrideHookState:null,overrideHookStateDeletePath:null,overrideHookStateRenamePath:null,overrideProps:null,overridePropsDeletePath:null,overridePropsRenamePath:null,setErrorHandler:null,setSuspenseHandler:null,scheduleUpdate:null,currentDispatcherRef:se.ReactCurrentDispatcher,findHostInstanceByFiber:function(e){return e=Pa(e),e===null?null:e.stateNode},findFiberByHostInstance:Pr.findFiberByHostInstance||Ep,findHostInstancesForRefresh:null,scheduleRefresh:null,scheduleRoot:null,setRefreshHandler:null,getCurrentFiber:null,reconcilerVersion:"18.3.1-next-f1338f8080-20240426"};if(typeof __REACT_DEVTOOLS_GLOBAL_HOOK__<"u"){var Gi=__REACT_DEVTOOLS_GLOBAL_HOOK__;if(!Gi.isDisabled&&Gi.supportsFiber)try{Wr=Gi.inject(Pp),kt=Gi}catch{}}return Je.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED=Cp,Je.createPortal=function(e,t){var n=2<arguments.length&&arguments[2]!==void 0?arguments[2]:null;if(!qs(t))throw Error(l(200));return _p(e,t,null,n)},Je.createRoot=function(e,t){if(!qs(e))throw Error(l(299));var n=!1,r="",i=ru;return t!=null&&(t.unstable_strictMode===!0&&(n=!0),t.identifierPrefix!==void 0&&(r=t.identifierPrefix),t.onRecoverableError!==void 0&&(i=t.onRecoverableError)),t=Hs(e,1,!1,null,null,n,!1,r,i),e[_t]=t.current,hr(e.nodeType===8?e.parentNode:e),new Gs(t)},Je.findDOMNode=function(e){if(e==null)return null;if(e.nodeType===1)return e;var t=e._reactInternals;if(t===void 0)throw typeof e.render=="function"?Error(l(188)):(e=Object.keys(e).join(","),Error(l(268,e)));return e=Pa(t),e=e===null?null:e.stateNode,e},Je.flushSync=function(e){return dn(e)},Je.hydrate=function(e,t,n){if(!Hi(t))throw Error(l(200));return Vi(null,e,t,!0,n)},Je.hydrateRoot=function(e,t,n){if(!qs(e))throw Error(l(405));var r=n!=null&&n.hydratedSources||null,i=!1,o="",a=ru;if(n!=null&&(n.unstable_strictMode===!0&&(i=!0),n.identifierPrefix!==void 0&&(o=n.identifierPrefix),n.onRecoverableError!==void 0&&(a=n.onRecoverableError)),t=tu(t,null,e,1,n??null,i,!1,o,a),e[_t]=t.current,hr(e),r)for(e=0;e<r.length;e++)n=r[e],i=n._getVersion,i=i(n._source),t.mutableSourceEagerHydrationData==null?t.mutableSourceEagerHydrationData=[n,i]:t.mutableSourceEagerHydrationData.push(n,i);return new Wi(t)},Je.render=function(e,t,n){if(!Hi(t))throw Error(l(200));return Vi(null,e,t,!1,n)},Je.unmountComponentAtNode=function(e){if(!Hi(e))throw Error(l(40));return e._reactRootContainer?(dn(function(){Vi(null,null,e,!1,function(){e._reactRootContainer=null,e[_t]=null})}),!0):!1},Je.unstable_batchedUpdates=js,Je.unstable_renderSubtreeIntoContainer=function(e,t,n,r){if(!Hi(n))throw Error(l(200));if(e==null||e._reactInternals===void 0)throw Error(l(38));return Vi(e,t,n,!1,r)},Je.version="18.3.1-next-f1338f8080-20240426",Je}var pu;function jp(){if(pu)return Xs.exports;pu=1;function s(){if(!(typeof __REACT_DEVTOOLS_GLOBAL_HOOK__>"u"||typeof __REACT_DEVTOOLS_GLOBAL_HOOK__.checkDCE!="function"))try{__REACT_DEVTOOLS_GLOBAL_HOOK__.checkDCE(s)}catch(c){console.error(c)}}return s(),Xs.exports=Fp(),Xs.exports}var hu;function zp(){if(hu)return qi;hu=1;var s=jp();return qi.createRoot=s.createRoot,qi.hydrateRoot=s.hydrateRoot,qi}var Bp=zp();/**
 * react-router v7.9.4
 *
 * Copyright (c) Remix Software Inc.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE.md file in the root directory of this source tree.
 *
 * @license MIT
 */var fu="popstate";function $p(s={}){function c(p,d){let{pathname:m,search:v,hash:A}=p.location;return ta("",{pathname:m,search:v,hash:A},d.state&&d.state.usr||null,d.state&&d.state.key||"default")}function l(p,d){return typeof d=="string"?d:Nr(d)}return Wp(c,l,null,s)}function Ae(s,c){if(s===!1||s===null||typeof s>"u")throw new Error(c)}function yt(s,c){if(!s){typeof console<"u"&&console.warn(c);try{throw new Error(c)}catch{}}}function Up(){return Math.random().toString(36).substring(2,10)}function mu(s,c){return{usr:s.state,key:s.key,idx:c}}function ta(s,c,l=null,p){return{pathname:typeof s=="string"?s:s.pathname,search:"",hash:"",...typeof c=="string"?Wn(c):c,state:l,key:c&&c.key||p||Up()}}function Nr({pathname:s="/",search:c="",hash:l=""}){return c&&c!=="?"&&(s+=c.charAt(0)==="?"?c:"?"+c),l&&l!=="#"&&(s+=l.charAt(0)==="#"?l:"#"+l),s}function Wn(s){let c={};if(s){let l=s.indexOf("#");l>=0&&(c.hash=s.substring(l),s=s.substring(0,l));let p=s.indexOf("?");p>=0&&(c.search=s.substring(p),s=s.substring(0,p)),s&&(c.pathname=s)}return c}function Wp(s,c,l,p={}){let{window:d=document.defaultView,v5Compat:m=!1}=p,v=d.history,A="POP",k=null,b=I();b==null&&(b=0,v.replaceState({...v.state,idx:b},""));function I(){return(v.state||{idx:null}).idx}function T(){A="POP";let L=I(),H=L==null?null:L-b;b=L,k&&k({action:A,location:j.location,delta:H})}function R(L,H){A="PUSH";let te=ta(j.location,L,H);b=I()+1;let V=mu(te,b),se=j.createHref(te);try{v.pushState(V,"",se)}catch(O){if(O instanceof DOMException&&O.name==="DataCloneError")throw O;d.location.assign(se)}m&&k&&k({action:A,location:j.location,delta:1})}function q(L,H){A="REPLACE";let te=ta(j.location,L,H);b=I();let V=mu(te,b),se=j.createHref(te);v.replaceState(V,"",se),m&&k&&k({action:A,location:j.location,delta:0})}function J(L){return Hp(L)}let j={get action(){return A},get location(){return s(d,v)},listen(L){if(k)throw new Error("A history only accepts one active listener");return d.addEventListener(fu,T),k=L,()=>{d.removeEventListener(fu,T),k=null}},createHref(L){return c(d,L)},createURL:J,encodeLocation(L){let H=J(L);return{pathname:H.pathname,search:H.search,hash:H.hash}},push:R,replace:q,go(L){return v.go(L)}};return j}function Hp(s,c=!1){let l="http://localhost";typeof window<"u"&&(l=window.location.origin!=="null"?window.location.origin:window.location.href),Ae(l,"No window.location.(origin|href) available to create URL");let p=typeof s=="string"?s:Nr(s);return p=p.replace(/ $/,"%20"),!c&&p.startsWith("//")&&(p=l+p),new URL(p,l)}function wu(s,c,l="/"){return Vp(s,c,l,!1)}function Vp(s,c,l,p){let d=typeof c=="string"?Wn(c):c,m=Lt(d.pathname||"/",l);if(m==null)return null;let v=ku(s);Gp(v);let A=null;for(let k=0;A==null&&k<v.length;++k){let b=rh(m);A=th(v[k],b,p)}return A}function ku(s,c=[],l=[],p="",d=!1){let m=(v,A,k=d,b)=>{let I={relativePath:b===void 0?v.path||"":b,caseSensitive:v.caseSensitive===!0,childrenIndex:A,route:v};if(I.relativePath.startsWith("/")){if(!I.relativePath.startsWith(p)&&k)return;Ae(I.relativePath.startsWith(p),`Absolute route path "${I.relativePath}" nested under path "${p}" is not valid. An absolute child route path must start with the combined path of all its parent routes.`),I.relativePath=I.relativePath.slice(p.length)}let T=Nt([p,I.relativePath]),R=l.concat(I);v.children&&v.children.length>0&&(Ae(v.index!==!0,`Index routes must not have child routes. Please remove all child routes from route path "${T}".`),ku(v.children,c,R,T,k)),!(v.path==null&&!v.index)&&c.push({path:T,score:Zp(T,v.index),routesMeta:R})};return s.forEach((v,A)=>{var k;if(v.path===""||!((k=v.path)!=null&&k.includes("?")))m(v,A);else for(let b of xu(v.path))m(v,A,!0,b)}),c}function xu(s){let c=s.split("/");if(c.length===0)return[];let[l,...p]=c,d=l.endsWith("?"),m=l.replace(/\?$/,"");if(p.length===0)return d?[m,""]:[m];let v=xu(p.join("/")),A=[];return A.push(...v.map(k=>k===""?m:[m,k].join("/"))),d&&A.push(...v),A.map(k=>s.startsWith("/")&&k===""?"/":k)}function Gp(s){s.sort((c,l)=>c.score!==l.score?l.score-c.score:eh(c.routesMeta.map(p=>p.childrenIndex),l.routesMeta.map(p=>p.childrenIndex)))}var qp=/^:[\w-]+$/,Qp=3,Kp=2,Xp=1,Yp=10,Jp=-2,gu=s=>s==="*";function Zp(s,c){let l=s.split("/"),p=l.length;return l.some(gu)&&(p+=Jp),c&&(p+=Kp),l.filter(d=>!gu(d)).reduce((d,m)=>d+(qp.test(m)?Qp:m===""?Xp:Yp),p)}function eh(s,c){return s.length===c.length&&s.slice(0,-1).every((p,d)=>p===c[d])?s[s.length-1]-c[c.length-1]:0}function th(s,c,l=!1){let{routesMeta:p}=s,d={},m="/",v=[];for(let A=0;A<p.length;++A){let k=p[A],b=A===p.length-1,I=m==="/"?c:c.slice(m.length)||"/",T=Yi({path:k.relativePath,caseSensitive:k.caseSensitive,end:b},I),R=k.route;if(!T&&b&&l&&!p[p.length-1].route.index&&(T=Yi({path:k.relativePath,caseSensitive:k.caseSensitive,end:!1},I)),!T)return null;Object.assign(d,T.params),v.push({params:d,pathname:Nt([m,T.pathname]),pathnameBase:ah(Nt([m,T.pathnameBase])),route:R}),T.pathnameBase!=="/"&&(m=Nt([m,T.pathnameBase]))}return v}function Yi(s,c){typeof s=="string"&&(s={path:s,caseSensitive:!1,end:!0});let[l,p]=nh(s.path,s.caseSensitive,s.end),d=c.match(l);if(!d)return null;let m=d[0],v=m.replace(/(.)\/+$/,"$1"),A=d.slice(1);return{params:p.reduce((b,{paramName:I,isOptional:T},R)=>{if(I==="*"){let J=A[R]||"";v=m.slice(0,m.length-J.length).replace(/(.)\/+$/,"$1")}const q=A[R];return T&&!q?b[I]=void 0:b[I]=(q||"").replace(/%2F/g,"/"),b},{}),pathname:m,pathnameBase:v,pattern:s}}function nh(s,c=!1,l=!0){yt(s==="*"||!s.endsWith("*")||s.endsWith("/*"),`Route path "${s}" will be treated as if it were "${s.replace(/\*$/,"/*")}" because the \`*\` character must always follow a \`/\` in the pattern. To get rid of this warning, please change the route path to "${s.replace(/\*$/,"/*")}".`);let p=[],d="^"+s.replace(/\/*\*?$/,"").replace(/^\/*/,"/").replace(/[\\.*+^${}|()[\]]/g,"\\$&").replace(/\/:([\w-]+)(\?)?/g,(v,A,k)=>(p.push({paramName:A,isOptional:k!=null}),k?"/?([^\\/]+)?":"/([^\\/]+)")).replace(/\/([\w-]+)\?(\/|$)/g,"(/$1)?$2");return s.endsWith("*")?(p.push({paramName:"*"}),d+=s==="*"||s==="/*"?"(.*)$":"(?:\\/(.+)|\\/*)$"):l?d+="\\/*$":s!==""&&s!=="/"&&(d+="(?:(?=\\/|$))"),[new RegExp(d,c?void 0:"i"),p]}function rh(s){try{return s.split("/").map(c=>decodeURIComponent(c).replace(/\//g,"%2F")).join("/")}catch(c){return yt(!1,`The URL path "${s}" could not be decoded because it is a malformed URL segment. This is probably due to a bad percent encoding (${c}).`),s}}function Lt(s,c){if(c==="/")return s;if(!s.toLowerCase().startsWith(c.toLowerCase()))return null;let l=c.endsWith("/")?c.length-1:c.length,p=s.charAt(l);return p&&p!=="/"?null:s.slice(l)||"/"}function ih(s,c="/"){let{pathname:l,search:p="",hash:d=""}=typeof s=="string"?Wn(s):s;return{pathname:l?l.startsWith("/")?l:oh(l,c):c,search:lh(p),hash:ch(d)}}function oh(s,c){let l=c.replace(/\/+$/,"").split("/");return s.split("/").forEach(d=>{d===".."?l.length>1&&l.pop():d!=="."&&l.push(d)}),l.length>1?l.join("/"):"/"}function Zs(s,c,l,p){return`Cannot include a '${s}' character in a manually specified \`to.${c}\` field [${JSON.stringify(p)}].  Please separate it out to the \`to.${l}\` field. Alternatively you may provide the full path as a string in <Link to="..."> and the router will parse it for you.`}function sh(s){return s.filter((c,l)=>l===0||c.route.path&&c.route.path.length>0)}function ia(s){let c=sh(s);return c.map((l,p)=>p===c.length-1?l.pathname:l.pathnameBase)}function oa(s,c,l,p=!1){let d;typeof s=="string"?d=Wn(s):(d={...s},Ae(!d.pathname||!d.pathname.includes("?"),Zs("?","pathname","search",d)),Ae(!d.pathname||!d.pathname.includes("#"),Zs("#","pathname","hash",d)),Ae(!d.search||!d.search.includes("#"),Zs("#","search","hash",d)));let m=s===""||d.pathname==="",v=m?"/":d.pathname,A;if(v==null)A=l;else{let T=c.length-1;if(!p&&v.startsWith("..")){let R=v.split("/");for(;R[0]==="..";)R.shift(),T-=1;d.pathname=R.join("/")}A=T>=0?c[T]:"/"}let k=ih(d,A),b=v&&v!=="/"&&v.endsWith("/"),I=(m||v===".")&&l.endsWith("/");return!k.pathname.endsWith("/")&&(b||I)&&(k.pathname+="/"),k}var Nt=s=>s.join("/").replace(/\/\/+/g,"/"),ah=s=>s.replace(/\/+$/,"").replace(/^\/*/,"/"),lh=s=>!s||s==="?"?"":s.startsWith("?")?s:"?"+s,ch=s=>!s||s==="#"?"":s.startsWith("#")?s:"#"+s;function uh(s){return s!=null&&typeof s.status=="number"&&typeof s.statusText=="string"&&typeof s.internal=="boolean"&&"data"in s}var Su=["POST","PUT","PATCH","DELETE"];new Set(Su);var dh=["GET",...Su];new Set(dh);var Hn=_.createContext(null);Hn.displayName="DataRouter";var Ji=_.createContext(null);Ji.displayName="DataRouterState";_.createContext(!1);var bu=_.createContext({isTransitioning:!1});bu.displayName="ViewTransition";var ph=_.createContext(new Map);ph.displayName="Fetchers";var hh=_.createContext(null);hh.displayName="Await";var vt=_.createContext(null);vt.displayName="Navigation";var Lr=_.createContext(null);Lr.displayName="Location";var wt=_.createContext({outlet:null,matches:[],isDataRoute:!1});wt.displayName="Route";var sa=_.createContext(null);sa.displayName="RouteError";function fh(s,{relative:c}={}){Ae(Vn(),"useHref() may be used only in the context of a <Router> component.");let{basename:l,navigator:p}=_.useContext(vt),{hash:d,pathname:m,search:v}=Or(s,{relative:c}),A=m;return l!=="/"&&(A=m==="/"?l:Nt([l,m])),p.createHref({pathname:A,search:v,hash:d})}function Vn(){return _.useContext(Lr)!=null}function It(){return Ae(Vn(),"useLocation() may be used only in the context of a <Router> component."),_.useContext(Lr).location}var Au="You should call navigate() in a React.useEffect(), not when your component is first rendered.";function Iu(s){_.useContext(vt).static||_.useLayoutEffect(s)}function _u(){let{isDataRoute:s}=_.useContext(wt);return s?Mh():mh()}function mh(){Ae(Vn(),"useNavigate() may be used only in the context of a <Router> component.");let s=_.useContext(Hn),{basename:c,navigator:l}=_.useContext(vt),{matches:p}=_.useContext(wt),{pathname:d}=It(),m=JSON.stringify(ia(p)),v=_.useRef(!1);return Iu(()=>{v.current=!0}),_.useCallback((k,b={})=>{if(yt(v.current,Au),!v.current)return;if(typeof k=="number"){l.go(k);return}let I=oa(k,JSON.parse(m),d,b.relative==="path");s==null&&c!=="/"&&(I.pathname=I.pathname==="/"?c:Nt([c,I.pathname])),(b.replace?l.replace:l.push)(I,b.state,b)},[c,l,m,d,s])}_.createContext(null);function gh(){let{matches:s}=_.useContext(wt),c=s[s.length-1];return c?c.params:{}}function Or(s,{relative:c}={}){let{matches:l}=_.useContext(wt),{pathname:p}=It(),d=JSON.stringify(ia(l));return _.useMemo(()=>oa(s,JSON.parse(d),p,c==="path"),[s,d,p,c])}function yh(s,c){return Eu(s,c)}function Eu(s,c,l,p,d){var te;Ae(Vn(),"useRoutes() may be used only in the context of a <Router> component.");let{navigator:m}=_.useContext(vt),{matches:v}=_.useContext(wt),A=v[v.length-1],k=A?A.params:{},b=A?A.pathname:"/",I=A?A.pathnameBase:"/",T=A&&A.route;{let V=T&&T.path||"";Mu(b,!T||V.endsWith("*")||V.endsWith("*?"),`You rendered descendant <Routes> (or called \`useRoutes()\`) at "${b}" (under <Route path="${V}">) but the parent route path has no trailing "*". This means if you navigate deeper, the parent won't match anymore and therefore the child routes will never render.

Please change the parent <Route path="${V}"> to <Route path="${V==="/"?"*":`${V}/*`}">.`)}let R=It(),q;if(c){let V=typeof c=="string"?Wn(c):c;Ae(I==="/"||((te=V.pathname)==null?void 0:te.startsWith(I)),`When overriding the location using \`<Routes location>\` or \`useRoutes(routes, location)\`, the location pathname must begin with the portion of the URL pathname that was matched by all parent routes. The current pathname base is "${I}" but pathname "${V.pathname}" was given in the \`location\` prop.`),q=V}else q=R;let J=q.pathname||"/",j=J;if(I!=="/"){let V=I.replace(/^\//,"").split("/");j="/"+J.replace(/^\//,"").split("/").slice(V.length).join("/")}let L=wu(s,{pathname:j});yt(T||L!=null,`No routes matched location "${q.pathname}${q.search}${q.hash}" `),yt(L==null||L[L.length-1].route.element!==void 0||L[L.length-1].route.Component!==void 0||L[L.length-1].route.lazy!==void 0,`Matched leaf route at location "${q.pathname}${q.search}${q.hash}" does not have an element or Component. This means it will render an <Outlet /> with a null value by default resulting in an "empty" page.`);let H=Sh(L&&L.map(V=>Object.assign({},V,{params:Object.assign({},k,V.params),pathname:Nt([I,m.encodeLocation?m.encodeLocation(V.pathname.replace(/\?/g,"%3F").replace(/#/g,"%23")).pathname:V.pathname]),pathnameBase:V.pathnameBase==="/"?I:Nt([I,m.encodeLocation?m.encodeLocation(V.pathnameBase.replace(/\?/g,"%3F").replace(/#/g,"%23")).pathname:V.pathnameBase])})),v,l,p,d);return c&&H?_.createElement(Lr.Provider,{value:{location:{pathname:"/",search:"",hash:"",state:null,key:"default",...q},navigationType:"POP"}},H):H}function vh(){let s=Eh(),c=uh(s)?`${s.status} ${s.statusText}`:s instanceof Error?s.message:JSON.stringify(s),l=s instanceof Error?s.stack:null,p="rgba(200,200,200, 0.5)",d={padding:"0.5rem",backgroundColor:p},m={padding:"2px 4px",backgroundColor:p},v=null;return console.error("Error handled by React Router default ErrorBoundary:",s),v=_.createElement(_.Fragment,null,_.createElement("p",null,"💿 Hey developer 👋"),_.createElement("p",null,"You can provide a way better UX than this when your app throws errors by providing your own ",_.createElement("code",{style:m},"ErrorBoundary")," or"," ",_.createElement("code",{style:m},"errorElement")," prop on your route.")),_.createElement(_.Fragment,null,_.createElement("h2",null,"Unexpected Application Error!"),_.createElement("h3",{style:{fontStyle:"italic"}},c),l?_.createElement("pre",{style:d},l):null,v)}var wh=_.createElement(vh,null),kh=class extends _.Component{constructor(s){super(s),this.state={location:s.location,revalidation:s.revalidation,error:s.error}}static getDerivedStateFromError(s){return{error:s}}static getDerivedStateFromProps(s,c){return c.location!==s.location||c.revalidation!=="idle"&&s.revalidation==="idle"?{error:s.error,location:s.location,revalidation:s.revalidation}:{error:s.error!==void 0?s.error:c.error,location:c.location,revalidation:s.revalidation||c.revalidation}}componentDidCatch(s,c){this.props.unstable_onError?this.props.unstable_onError(s,c):console.error("React Router caught the following error during render",s)}render(){return this.state.error!==void 0?_.createElement(wt.Provider,{value:this.props.routeContext},_.createElement(sa.Provider,{value:this.state.error,children:this.props.component})):this.props.children}};function xh({routeContext:s,match:c,children:l}){let p=_.useContext(Hn);return p&&p.static&&p.staticContext&&(c.route.errorElement||c.route.ErrorBoundary)&&(p.staticContext._deepestRenderedBoundaryId=c.route.id),_.createElement(wt.Provider,{value:s},l)}function Sh(s,c=[],l=null,p=null,d=null){if(s==null){if(!l)return null;if(l.errors)s=l.matches;else if(c.length===0&&!l.initialized&&l.matches.length>0)s=l.matches;else return null}let m=s,v=l==null?void 0:l.errors;if(v!=null){let b=m.findIndex(I=>I.route.id&&(v==null?void 0:v[I.route.id])!==void 0);Ae(b>=0,`Could not find a matching route for errors on route IDs: ${Object.keys(v).join(",")}`),m=m.slice(0,Math.min(m.length,b+1))}let A=!1,k=-1;if(l)for(let b=0;b<m.length;b++){let I=m[b];if((I.route.HydrateFallback||I.route.hydrateFallbackElement)&&(k=b),I.route.id){let{loaderData:T,errors:R}=l,q=I.route.loader&&!T.hasOwnProperty(I.route.id)&&(!R||R[I.route.id]===void 0);if(I.route.lazy||q){A=!0,k>=0?m=m.slice(0,k+1):m=[m[0]];break}}}return m.reduceRight((b,I,T)=>{let R,q=!1,J=null,j=null;l&&(R=v&&I.route.id?v[I.route.id]:void 0,J=I.route.errorElement||wh,A&&(k<0&&T===0?(Mu("route-fallback",!1,"No `HydrateFallback` element provided to render during initial hydration"),q=!0,j=null):k===T&&(q=!0,j=I.route.hydrateFallbackElement||null)));let L=c.concat(m.slice(0,T+1)),H=()=>{let te;return R?te=J:q?te=j:I.route.Component?te=_.createElement(I.route.Component,null):I.route.element?te=I.route.element:te=b,_.createElement(xh,{match:I,routeContext:{outlet:b,matches:L,isDataRoute:l!=null},children:te})};return l&&(I.route.ErrorBoundary||I.route.errorElement||T===0)?_.createElement(kh,{location:l.location,revalidation:l.revalidation,component:J,error:R,children:H(),routeContext:{outlet:null,matches:L,isDataRoute:!0},unstable_onError:p}):H()},null)}function aa(s){return`${s} must be used within a data router.  See https://reactrouter.com/en/main/routers/picking-a-router.`}function bh(s){let c=_.useContext(Hn);return Ae(c,aa(s)),c}function Ah(s){let c=_.useContext(Ji);return Ae(c,aa(s)),c}function Ih(s){let c=_.useContext(wt);return Ae(c,aa(s)),c}function la(s){let c=Ih(s),l=c.matches[c.matches.length-1];return Ae(l.route.id,`${s} can only be used on routes that contain a unique "id"`),l.route.id}function _h(){return la("useRouteId")}function Eh(){var p;let s=_.useContext(sa),c=Ah("useRouteError"),l=la("useRouteError");return s!==void 0?s:(p=c.errors)==null?void 0:p[l]}function Mh(){let{router:s}=bh("useNavigate"),c=la("useNavigate"),l=_.useRef(!1);return Iu(()=>{l.current=!0}),_.useCallback(async(d,m={})=>{yt(l.current,Au),l.current&&(typeof d=="number"?s.navigate(d):await s.navigate(d,{fromRouteId:c,...m}))},[s,c])}var yu={};function Mu(s,c,l){!c&&!yu[s]&&(yu[s]=!0,yt(!1,l))}_.memo(Ch);function Ch({routes:s,future:c,state:l,unstable_onError:p}){return Eu(s,void 0,l,p,c)}function Ph({to:s,replace:c,state:l,relative:p}){Ae(Vn(),"<Navigate> may be used only in the context of a <Router> component.");let{static:d}=_.useContext(vt);yt(!d,"<Navigate> must not be used on the initial render in a <StaticRouter>. This is a no-op, but you should modify your code so the <Navigate> is only ever rendered in response to some user interaction or state change.");let{matches:m}=_.useContext(wt),{pathname:v}=It(),A=_u(),k=oa(s,ia(m),v,p==="path"),b=JSON.stringify(k);return _.useEffect(()=>{A(JSON.parse(b),{replace:c,state:l,relative:p})},[A,b,p,c,l]),null}function Rr(s){Ae(!1,"A <Route> is only ever to be used as the child of <Routes> element, never rendered directly. Please wrap your <Route> in a <Routes>.")}function Th({basename:s="/",children:c=null,location:l,navigationType:p="POP",navigator:d,static:m=!1}){Ae(!Vn(),"You cannot render a <Router> inside another <Router>. You should never have more than one in your app.");let v=s.replace(/^\/*/,"/"),A=_.useMemo(()=>({basename:v,navigator:d,static:m,future:{}}),[v,d,m]);typeof l=="string"&&(l=Wn(l));let{pathname:k="/",search:b="",hash:I="",state:T=null,key:R="default"}=l,q=_.useMemo(()=>{let J=Lt(k,v);return J==null?null:{location:{pathname:J,search:b,hash:I,state:T,key:R},navigationType:p}},[v,k,b,I,T,R,p]);return yt(q!=null,`<Router basename="${v}"> is not able to match the URL "${k}${b}${I}" because it does not start with the basename, so the <Router> won't render anything.`),q==null?null:_.createElement(vt.Provider,{value:A},_.createElement(Lr.Provider,{children:c,value:q}))}function Dh({children:s,location:c}){return yh(na(s),c)}function na(s,c=[]){let l=[];return _.Children.forEach(s,(p,d)=>{if(!_.isValidElement(p))return;let m=[...c,d];if(p.type===_.Fragment){l.push.apply(l,na(p.props.children,m));return}Ae(p.type===Rr,`[${typeof p.type=="string"?p.type:p.type.name}] is not a <Route> component. All component children of <Routes> must be a <Route> or <React.Fragment>`),Ae(!p.props.index||!p.props.children,"An index route cannot have child routes.");let v={id:p.props.id||m.join("-"),caseSensitive:p.props.caseSensitive,element:p.props.element,Component:p.props.Component,index:p.props.index,path:p.props.path,middleware:p.props.middleware,loader:p.props.loader,action:p.props.action,hydrateFallbackElement:p.props.hydrateFallbackElement,HydrateFallback:p.props.HydrateFallback,errorElement:p.props.errorElement,ErrorBoundary:p.props.ErrorBoundary,hasErrorBoundary:p.props.hasErrorBoundary===!0||p.props.ErrorBoundary!=null||p.props.errorElement!=null,shouldRevalidate:p.props.shouldRevalidate,handle:p.props.handle,lazy:p.props.lazy};p.props.children&&(v.children=na(p.props.children,m)),l.push(v)}),l}var Ki="get",Xi="application/x-www-form-urlencoded";function Zi(s){return s!=null&&typeof s.tagName=="string"}function Rh(s){return Zi(s)&&s.tagName.toLowerCase()==="button"}function Nh(s){return Zi(s)&&s.tagName.toLowerCase()==="form"}function Lh(s){return Zi(s)&&s.tagName.toLowerCase()==="input"}function Oh(s){return!!(s.metaKey||s.altKey||s.ctrlKey||s.shiftKey)}function Fh(s,c){return s.button===0&&(!c||c==="_self")&&!Oh(s)}var Qi=null;function jh(){if(Qi===null)try{new FormData(document.createElement("form"),0),Qi=!1}catch{Qi=!0}return Qi}var zh=new Set(["application/x-www-form-urlencoded","multipart/form-data","text/plain"]);function ea(s){return s!=null&&!zh.has(s)?(yt(!1,`"${s}" is not a valid \`encType\` for \`<Form>\`/\`<fetcher.Form>\` and will default to "${Xi}"`),null):s}function Bh(s,c){let l,p,d,m,v;if(Nh(s)){let A=s.getAttribute("action");p=A?Lt(A,c):null,l=s.getAttribute("method")||Ki,d=ea(s.getAttribute("enctype"))||Xi,m=new FormData(s)}else if(Rh(s)||Lh(s)&&(s.type==="submit"||s.type==="image")){let A=s.form;if(A==null)throw new Error('Cannot submit a <button> or <input type="submit"> without a <form>');let k=s.getAttribute("formaction")||A.getAttribute("action");if(p=k?Lt(k,c):null,l=s.getAttribute("formmethod")||A.getAttribute("method")||Ki,d=ea(s.getAttribute("formenctype"))||ea(A.getAttribute("enctype"))||Xi,m=new FormData(A,s),!jh()){let{name:b,type:I,value:T}=s;if(I==="image"){let R=b?`${b}.`:"";m.append(`${R}x`,"0"),m.append(`${R}y`,"0")}else b&&m.append(b,T)}}else{if(Zi(s))throw new Error('Cannot submit element that is not <form>, <button>, or <input type="submit|image">');l=Ki,p=null,d=Xi,v=s}return m&&d==="text/plain"&&(v=m,m=void 0),{action:p,method:l.toLowerCase(),encType:d,formData:m,body:v}}Object.getOwnPropertyNames(Object.prototype).sort().join("\0");function ca(s,c){if(s===!1||s===null||typeof s>"u")throw new Error(c)}function $h(s,c,l){let p=typeof s=="string"?new URL(s,typeof window>"u"?"server://singlefetch/":window.location.origin):s;return p.pathname==="/"?p.pathname=`_root.${l}`:c&&Lt(p.pathname,c)==="/"?p.pathname=`${c.replace(/\/$/,"")}/_root.${l}`:p.pathname=`${p.pathname.replace(/\/$/,"")}.${l}`,p}async function Uh(s,c){if(s.id in c)return c[s.id];try{let l=await import(s.module);return c[s.id]=l,l}catch(l){return console.error(`Error loading route module \`${s.module}\`, reloading page...`),console.error(l),window.__reactRouterContext&&window.__reactRouterContext.isSpaMode,window.location.reload(),new Promise(()=>{})}}function Wh(s){return s==null?!1:s.href==null?s.rel==="preload"&&typeof s.imageSrcSet=="string"&&typeof s.imageSizes=="string":typeof s.rel=="string"&&typeof s.href=="string"}async function Hh(s,c,l){let p=await Promise.all(s.map(async d=>{let m=c.routes[d.route.id];if(m){let v=await Uh(m,l);return v.links?v.links():[]}return[]}));return Qh(p.flat(1).filter(Wh).filter(d=>d.rel==="stylesheet"||d.rel==="preload").map(d=>d.rel==="stylesheet"?{...d,rel:"prefetch",as:"style"}:{...d,rel:"prefetch"}))}function vu(s,c,l,p,d,m){let v=(k,b)=>l[b]?k.route.id!==l[b].route.id:!0,A=(k,b)=>{var I;return l[b].pathname!==k.pathname||((I=l[b].route.path)==null?void 0:I.endsWith("*"))&&l[b].params["*"]!==k.params["*"]};return m==="assets"?c.filter((k,b)=>v(k,b)||A(k,b)):m==="data"?c.filter((k,b)=>{var T;let I=p.routes[k.route.id];if(!I||!I.hasLoader)return!1;if(v(k,b)||A(k,b))return!0;if(k.route.shouldRevalidate){let R=k.route.shouldRevalidate({currentUrl:new URL(d.pathname+d.search+d.hash,window.origin),currentParams:((T=l[0])==null?void 0:T.params)||{},nextUrl:new URL(s,window.origin),nextParams:k.params,defaultShouldRevalidate:!0});if(typeof R=="boolean")return R}return!0}):[]}function Vh(s,c,{includeHydrateFallback:l}={}){return Gh(s.map(p=>{let d=c.routes[p.route.id];if(!d)return[];let m=[d.module];return d.clientActionModule&&(m=m.concat(d.clientActionModule)),d.clientLoaderModule&&(m=m.concat(d.clientLoaderModule)),l&&d.hydrateFallbackModule&&(m=m.concat(d.hydrateFallbackModule)),d.imports&&(m=m.concat(d.imports)),m}).flat(1))}function Gh(s){return[...new Set(s)]}function qh(s){let c={},l=Object.keys(s).sort();for(let p of l)c[p]=s[p];return c}function Qh(s,c){let l=new Set;return new Set(c),s.reduce((p,d)=>{let m=JSON.stringify(qh(d));return l.has(m)||(l.add(m),p.push({key:m,link:d})),p},[])}function Cu(){let s=_.useContext(Hn);return ca(s,"You must render this element inside a <DataRouterContext.Provider> element"),s}function Kh(){let s=_.useContext(Ji);return ca(s,"You must render this element inside a <DataRouterStateContext.Provider> element"),s}var ua=_.createContext(void 0);ua.displayName="FrameworkContext";function Pu(){let s=_.useContext(ua);return ca(s,"You must render this element inside a <HydratedRouter> element"),s}function Xh(s,c){let l=_.useContext(ua),[p,d]=_.useState(!1),[m,v]=_.useState(!1),{onFocus:A,onBlur:k,onMouseEnter:b,onMouseLeave:I,onTouchStart:T}=c,R=_.useRef(null);_.useEffect(()=>{if(s==="render"&&v(!0),s==="viewport"){let j=H=>{H.forEach(te=>{v(te.isIntersecting)})},L=new IntersectionObserver(j,{threshold:.5});return R.current&&L.observe(R.current),()=>{L.disconnect()}}},[s]),_.useEffect(()=>{if(p){let j=setTimeout(()=>{v(!0)},100);return()=>{clearTimeout(j)}}},[p]);let q=()=>{d(!0)},J=()=>{d(!1),v(!1)};return l?s!=="intent"?[m,R,{}]:[m,R,{onFocus:Dr(A,q),onBlur:Dr(k,J),onMouseEnter:Dr(b,q),onMouseLeave:Dr(I,J),onTouchStart:Dr(T,q)}]:[!1,R,{}]}function Dr(s,c){return l=>{s&&s(l),l.defaultPrevented||c(l)}}function Yh({page:s,...c}){let{router:l}=Cu(),p=_.useMemo(()=>wu(l.routes,s,l.basename),[l.routes,s,l.basename]);return p?_.createElement(Zh,{page:s,matches:p,...c}):null}function Jh(s){let{manifest:c,routeModules:l}=Pu(),[p,d]=_.useState([]);return _.useEffect(()=>{let m=!1;return Hh(s,c,l).then(v=>{m||d(v)}),()=>{m=!0}},[s,c,l]),p}function Zh({page:s,matches:c,...l}){let p=It(),{manifest:d,routeModules:m}=Pu(),{basename:v}=Cu(),{loaderData:A,matches:k}=Kh(),b=_.useMemo(()=>vu(s,c,k,d,p,"data"),[s,c,k,d,p]),I=_.useMemo(()=>vu(s,c,k,d,p,"assets"),[s,c,k,d,p]),T=_.useMemo(()=>{if(s===p.pathname+p.search+p.hash)return[];let J=new Set,j=!1;if(c.forEach(H=>{var V;let te=d.routes[H.route.id];!te||!te.hasLoader||(!b.some(se=>se.route.id===H.route.id)&&H.route.id in A&&((V=m[H.route.id])!=null&&V.shouldRevalidate)||te.hasClientLoader?j=!0:J.add(H.route.id))}),J.size===0)return[];let L=$h(s,v,"data");return j&&J.size>0&&L.searchParams.set("_routes",c.filter(H=>J.has(H.route.id)).map(H=>H.route.id).join(",")),[L.pathname+L.search]},[v,A,p,d,b,c,s,m]),R=_.useMemo(()=>Vh(I,d),[I,d]),q=Jh(I);return _.createElement(_.Fragment,null,T.map(J=>_.createElement("link",{key:J,rel:"prefetch",as:"fetch",href:J,...l})),R.map(J=>_.createElement("link",{key:J,rel:"modulepreload",href:J,...l})),q.map(({key:J,link:j})=>_.createElement("link",{key:J,nonce:l.nonce,...j})))}function ef(...s){return c=>{s.forEach(l=>{typeof l=="function"?l(c):l!=null&&(l.current=c)})}}var Tu=typeof window<"u"&&typeof window.document<"u"&&typeof window.document.createElement<"u";try{Tu&&(window.__reactRouterVersion="7.9.4")}catch{}function tf({basename:s,children:c,window:l}){let p=_.useRef();p.current==null&&(p.current=$p({window:l,v5Compat:!0}));let d=p.current,[m,v]=_.useState({action:d.action,location:d.location}),A=_.useCallback(k=>{_.startTransition(()=>v(k))},[v]);return _.useLayoutEffect(()=>d.listen(A),[d,A]),_.createElement(Th,{basename:s,children:c,location:m.location,navigationType:m.action,navigator:d})}var Du=/^(?:[a-z][a-z0-9+.-]*:|\/\/)/i,mn=_.forwardRef(function({onClick:c,discover:l="render",prefetch:p="none",relative:d,reloadDocument:m,replace:v,state:A,target:k,to:b,preventScrollReset:I,viewTransition:T,...R},q){let{basename:J}=_.useContext(vt),j=typeof b=="string"&&Du.test(b),L,H=!1;if(typeof b=="string"&&j&&(L=b,Tu))try{let ne=new URL(window.location.href),ae=b.startsWith("//")?new URL(ne.protocol+b):new URL(b),Ie=Lt(ae.pathname,J);ae.origin===ne.origin&&Ie!=null?b=Ie+ae.search+ae.hash:H=!0}catch{yt(!1,`<Link to="${b}"> contains an invalid URL which will probably break when clicked - please update to a valid URL path.`)}let te=fh(b,{relative:d}),[V,se,O]=Xh(p,R),$=sf(b,{replace:v,state:A,target:k,preventScrollReset:I,relative:d,viewTransition:T});function Q(ne){c&&c(ne),ne.defaultPrevented||$(ne)}let Z=_.createElement("a",{...R,...O,href:L||te,onClick:H||m?c:Q,ref:ef(q,se),target:k,"data-discover":!j&&l==="render"?"true":void 0});return V&&!j?_.createElement(_.Fragment,null,Z,_.createElement(Yh,{page:te})):Z});mn.displayName="Link";var nf=_.forwardRef(function({"aria-current":c="page",caseSensitive:l=!1,className:p="",end:d=!1,style:m,to:v,viewTransition:A,children:k,...b},I){let T=Or(v,{relative:b.relative}),R=It(),q=_.useContext(Ji),{navigator:J,basename:j}=_.useContext(vt),L=q!=null&&df(T)&&A===!0,H=J.encodeLocation?J.encodeLocation(T).pathname:T.pathname,te=R.pathname,V=q&&q.navigation&&q.navigation.location?q.navigation.location.pathname:null;l||(te=te.toLowerCase(),V=V?V.toLowerCase():null,H=H.toLowerCase()),V&&j&&(V=Lt(V,j)||V);const se=H!=="/"&&H.endsWith("/")?H.length-1:H.length;let O=te===H||!d&&te.startsWith(H)&&te.charAt(se)==="/",$=V!=null&&(V===H||!d&&V.startsWith(H)&&V.charAt(H.length)==="/"),Q={isActive:O,isPending:$,isTransitioning:L},Z=O?c:void 0,ne;typeof p=="function"?ne=p(Q):ne=[p,O?"active":null,$?"pending":null,L?"transitioning":null].filter(Boolean).join(" ");let ae=typeof m=="function"?m(Q):m;return _.createElement(mn,{...b,"aria-current":Z,className:ne,ref:I,style:ae,to:v,viewTransition:A},typeof k=="function"?k(Q):k)});nf.displayName="NavLink";var rf=_.forwardRef(({discover:s="render",fetcherKey:c,navigate:l,reloadDocument:p,replace:d,state:m,method:v=Ki,action:A,onSubmit:k,relative:b,preventScrollReset:I,viewTransition:T,...R},q)=>{let J=cf(),j=uf(A,{relative:b}),L=v.toLowerCase()==="get"?"get":"post",H=typeof A=="string"&&Du.test(A),te=V=>{if(k&&k(V),V.defaultPrevented)return;V.preventDefault();let se=V.nativeEvent.submitter,O=(se==null?void 0:se.getAttribute("formmethod"))||v;J(se||V.currentTarget,{fetcherKey:c,method:O,navigate:l,replace:d,state:m,relative:b,preventScrollReset:I,viewTransition:T})};return _.createElement("form",{ref:q,method:L,action:j,onSubmit:p?k:te,...R,"data-discover":!H&&s==="render"?"true":void 0})});rf.displayName="Form";function of(s){return`${s} must be used within a data router.  See https://reactrouter.com/en/main/routers/picking-a-router.`}function Ru(s){let c=_.useContext(Hn);return Ae(c,of(s)),c}function sf(s,{target:c,replace:l,state:p,preventScrollReset:d,relative:m,viewTransition:v}={}){let A=_u(),k=It(),b=Or(s,{relative:m});return _.useCallback(I=>{if(Fh(I,c)){I.preventDefault();let T=l!==void 0?l:Nr(k)===Nr(b);A(s,{replace:T,state:p,preventScrollReset:d,relative:m,viewTransition:v})}},[k,A,b,l,p,c,s,d,m,v])}var af=0,lf=()=>`__${String(++af)}__`;function cf(){let{router:s}=Ru("useSubmit"),{basename:c}=_.useContext(vt),l=_h();return _.useCallback(async(p,d={})=>{let{action:m,method:v,encType:A,formData:k,body:b}=Bh(p,c);if(d.navigate===!1){let I=d.fetcherKey||lf();await s.fetch(I,l,d.action||m,{preventScrollReset:d.preventScrollReset,formData:k,body:b,formMethod:d.method||v,formEncType:d.encType||A,flushSync:d.flushSync})}else await s.navigate(d.action||m,{preventScrollReset:d.preventScrollReset,formData:k,body:b,formMethod:d.method||v,formEncType:d.encType||A,replace:d.replace,state:d.state,fromRouteId:l,flushSync:d.flushSync,viewTransition:d.viewTransition})},[s,c,l])}function uf(s,{relative:c}={}){let{basename:l}=_.useContext(vt),p=_.useContext(wt);Ae(p,"useFormAction must be used inside a RouteContext");let[d]=p.matches.slice(-1),m={...Or(s||".",{relative:c})},v=It();if(s==null){m.search=v.search;let A=new URLSearchParams(m.search),k=A.getAll("index");if(k.some(I=>I==="")){A.delete("index"),k.filter(T=>T).forEach(T=>A.append("index",T));let I=A.toString();m.search=I?`?${I}`:""}}return(!s||s===".")&&d.route.index&&(m.search=m.search?m.search.replace(/^\?/,"?index&"):"?index"),l!=="/"&&(m.pathname=m.pathname==="/"?l:Nt([l,m.pathname])),Nr(m)}function df(s,{relative:c}={}){let l=_.useContext(bu);Ae(l!=null,"`useViewTransitionState` must be used within `react-router-dom`'s `RouterProvider`.  Did you accidentally import `RouterProvider` from `react-router`?");let{basename:p}=Ru("useViewTransitionState"),d=Or(s,{relative:c});if(!l.isTransitioning)return!1;let m=Lt(l.currentLocation.pathname,p)||l.currentLocation.pathname,v=Lt(l.nextLocation.pathname,p)||l.nextLocation.pathname;return Yi(d.pathname,v)!=null||Yi(d.pathname,m)!=null}const pf="Anthropic's Long-Term Benefit Trust",hf="public/Dario_Amodei.jpg",ff={content:`The Anthropic Long-Term Benefit Trust (LTBT) represents a novel governance experiment in the field of advanced AI. Formed in September 2023, the LTBT is an independent body of five trustees — experts in AI safety, national security, public policy & social enterprise — who hold shares in Anthropic (a Class T stock) that give them the power to elect and remove board members, ultimately controlling a majority of the board within four years. 
Why this matters: Anthropic argues that transformative AI may generate “unprecedentedly large externalities” — risks and benefits that fall on society at large, not just the company’s shareholders.
Typical corporate governance mechanisms push boards to prioritise shareholder returns, potentially sidelining broader public interests. To counteract this, Anthropic uses two layers: first, its status as a Delaware Public Benefit Corporation (PBC) with a stated mission to “responsibly develop and maintain advanced AI for the long-term benefit of humanity.”
Second, the LTBT adds structural accountability to steer decisions when stakes are highest. For an independent AI safety lab watchdog, the LTBT is interesting: it provides a concrete case of coupling commercial viability with a formalised mechanism to protect societal interests. It remains experimental — Anthropic itself calls it an empirical test rather than a blueprint.`,review:"This article takes a much more nuanced tone to the overall concept of the Anthropic Trust. However, it provides facts that are outside of the scope of the original piece and makes no mention of the blog’s call for additional information to be released.'",score:35},mf={title:pf,photo:hf,"gpt3.5":{content:`The establishment of the Anthropic’s Long-Term Benefit Trust marks a significant step towards ensuring responsible governance in the development of advanced AI for the long-term benefit of humanity. As an independent body comprised of distinguished individuals with backgrounds in AI safety, national security, and public policy, the Trust is uniquely positioned to balance the interests of the public with those of Anthropic's stockholders.
The Trust’s authority to select and remove a significant portion of Anthropic’s board, ultimately growing to a majority within four years, ensures that decisions made by the company align with its mission of prioritizing the public benefit alongside commercial success. By granting the Trust the power to influence key strategic decisions, such as evaluating future models for catastrophic risks or ensuring top-notch security measures, Anthropic demonstrates a commitment to handling the challenges of AI development with humanity’s best interests in mind.
With the appointment of highly experienced individuals such as Jason Matheny, Kanika Bahl, and Neil Buddy Shah as the initial Trustees, Anthropic showcases a dedication to assembling a diverse and knowledgeable group to oversee its long-term trajectory. This innovative governance structure not only sets a new standard for corporate responsibility in the realm of AI development but also represents an ongoing experiment in optimizing decision-making processes for the greater good of society. As Anthropic navigates the complexities of transformative AI technology, the Long-Term Benefit Trust stands as a beacon of ethical leadership and forward-thinking governance in the field.`,review:"This article misses the tone of the original piece. It states that the Anthropic Benefit Trust is a ‘significant step’ while the original article describes it as ‘powerless.’ It labels the trust as a ‘beacon of ethical leadership’ and makes no mention of the original article’s call for Anthropic to release the details of its Trust publically'",score:15},gpt5:ff},gf="Anthropic's new Responsible Scaling Policy",yf="public/anthropic.webp",vf={content:`Anthropic’s revised Responsible Scaling Policy (RSP v2.2, effective May 14 2025) reaffirms its public commitment not to train or deploy AI models capable of catastrophic harm without rigorous safeguards. Central to the policy is the concept of AI Safety Level standards (ASLs) — a hierarchy of Deployment and Security standards that escalate as model capabilities increase. Models begin at ASL-2, but if they approach defined “Capability Thresholds” (for example in CBRN weapons or autonomous AI-R&D) the policy mandates upgrade to ASL-3 or higher. The process involves preliminary assessment, comprehensive assessment, and a decision by a designated “Responsible Scaling Officer” in consultation with the CEO and Board. Transparency and governance are key: Anthropic commits to public summaries of Capability and Safeguards reports, whistleblower channels, and external expert review. The policy is designed to be proportional (matching safeguards to risk), iterative (regular reassessments) and exportable (to set a standard for the industry). 
 In short: Anthropic is formalising a framework that links model capability thresholds with concrete escalation of oversight and security, aiming to allow innovation while keeping catastrophic risks in check.`,review:"This article is overly positive because it fails to discuss the fact that the FSF doesn’t contain commitments. The blogpost says 'The Framework is exploratory and we expect it to evolve significantly' and 'We aim to have this initial framework fully implemented by early 2025.'",score:50},wf={title:gf,photo:yf,"gpt3.5":{content:"Anthropic, a leader in AI development, has recently unveiled their updated Responsible Scaling Policy (RSP) version 2.2. Building upon their initial commitment in 2023, the new policy reflects the company's dedication to responsible and safe AI development in an ever-evolving landscape. One of the key updates is the introduction of Capability Thresholds and Required Safeguards. These measures will help Anthropic assess when model capabilities reach a level that requires enhanced safeguards beyond the existing standards. By specifying these thresholds and safeguards, the company aims to proactively manage risks associated with advanced AI capabilities. Furthermore, the revised policy emphasizes an iterative approach to risk assessment. Anthropic has committed to regular capability assessments to ensure that their safeguards remain effective as model capabilities evolve. This dynamic approach acknowledges the rapid pace of technological advancements and the need for continuous evaluation and adjustment of safety measures. Additionally, the policy highlights the importance of internal governance and transparency. With designated Responsible Scaling Officers overseeing risk reduction efforts and mechanisms in place for anonymous reporting of noncompliance, Anthropic is reinforcing its commitment to ethical AI development. By introducing these updates, Anthropic is setting a high standard for responsible AI scaling in the industry. The company's dedication to transparency, ongoing evaluation, and proactive risk management showcases their commitment to developing AI in a safe and ethical manner.",review:"This article is overly positive because it fails to discuss the fact that the FSF doesn't contain commitments. The blogpost says 'The Framework is exploratory and we expect it to evolve significantly' and 'We aim to have this initial framework fully implemented by early 2025.'",score:50},gpt5:vf},kf="DeepMind's Frontier AI Safety Framework",xf="public/deepmind-safety-framework.jpg",Sf={content:`DeepMind’s Frontier Safety Framework (FSF) marks a serious step toward governing “frontier” large-model risks by treating capability scaling as a safety frontier.
At its heart the FSF defines Critical Capability Levels (CCLs) — capability-thresholds at which, absent stronger mitigation, models may pose severe risks in domains such as autonomy, biosecurity, cybersecurity, or ML-R&D.
DeepMind commits to periodic “early-warning evaluations” of models against CCLs, and to activate calibrated mitigation once thresholds are approached or crossed.
Mitigations fall into two broad classes: security mitigations (e.g., locking down model weights) and deployment mitigations (e.g., access controls, red-teaming) — with stronger measures required for higher CCLs.
For an independent lab, the FSF is notable because it mirrors the structure of responsible-scaling frameworks like those described by Anthropic and METR: thresholds → evaluation → mitigation → possible pause.
But caveats remain: the FSF is explicitly “exploratory … subject to substantial evolution”.
As a watchdog, one should ask: How transparent will evaluation criteria and mitigation decisions be? Will third-party audits be allowed? And how will DeepMind define “severe harm” thresholds in practice?
In short: the FSF is a promising blueprint — but its real test will lie in how rigorously it is applied, how openly it is governed, and how clearly it delivers on its commitments.`,review:"When re-generated in GPT-5, the reproduction of the article on DeepMind's 'Frontier Safety Framework' again states the aims in the FSF as commitments rather than aims. It does embody a slightly less positive tone but still fails to capture the original authors'.",score:50},bf={title:kf,photo:xf,"gpt3.5":{content:`DeepMind's latest initiative, the Frontier Safety Framework, represents a proactive approach towards addressing potential risks associated with powerful AI models. The framework outlines Critical Capability Levels (CCLs) across domains like Autonomy, Biosecurity, Cybersecurity, and Machine Learning R&D, aiming to detect and mitigate risks as models approach these levels.
By focusing on early detection through periodic evaluations and implementing tailored mitigation strategies, the framework seeks to prevent the misuse of models with critical capabilities. Security mitigations aim to prevent unauthorized access to model weights, while deployment mitigations aim to manage access and prevent the expression of critical capabilities in deployments.
As this framework is still in its preliminary stages, DeepMind acknowledges the need for continual evolution based on ongoing research and understanding. Future work includes refining risk modeling, enhancing capability elicitation techniques, and updating mitigation plans to balance risk mitigation with innovation and access to AI technologies.
Overall, DeepMind's Frontier Safety Framework showcases a commitment to responsible AI development and deployment, setting a strong foundation for addressing potential risks in the evolving AI landscape.`,review:"When compared to the original blog post on AI Lab Watch, this GPT 3.5-generated summary fails to capture the same tone of the original author. AI Lab Watch makes it clear that this is an “aim” rather than a commitment, which is clearly in contrast with the GPT-generated version.",score:50},gpt5:Sf},Af="Frontier AI Safety Commitments",If="public/seoul-summit.png",_f={content:`The Frontier AI Safety Commitments announced at the Seoul 2024 Summit set an important benchmark for how organisations developing highly capable AI must govern their work. Signatories — including major international firms — commit to three core outcomes: 1) effectively identifying, assessing and managing risks across the AI lifecycle; 2) being accountable through internal governance, roles and resources; and 3) being transparent with external actors, including governments, civil society and academia.
Key provisions include: assessing capabilities and deployment context before model training and release; setting explicit thresholds for “intolerable” risk and monitoring when those thresholds are approached or breached; having processes that halt or redesign deployment if risks cannot be mitigated; and publishing a safety-framework by the upcoming AI Summit in France.
For a watchdog lab, the value lies in holding signatories to the promise of transparency. The commitments recognise that public disclosures may be limited when commercial or security concerns apply—but organisations must still share more detailed information with trusted actors.
While these are voluntary commitments, the watch-dog role becomes crucial: verifying whether thresholds are meaningful, whether mitigation processes are genuinely followed, and whether publicly-shared safety frameworks are credible. The commitments provide a useful baseline—but the work now is to monitor and press for results.`,review:"This article adds in more detail than the GPT-3.5 version but still lacks nuance of the original piece. It does hit on some of the listed intended outcomes in the original article, but it fails to hit the same tone.'",score:65},Ef={title:Af,photo:If,"gpt3.5":{content:`In the ever-evolving landscape of artificial intelligence (AI), ensuring safety and accountability is crucial. This was further emphasized with the recent announcement of the Frontier AI Safety Commitments by several leading organizations in the field. The commitment to develop and deploy frontier AI models and systems responsibly is a significant step towards building safe and trustworthy AI.
The outlined commitments focus on identifying, assessing, and managing risks associated with AI models and systems, as well as ensuring accountability and transparency in the development and deployment processes. Organizations are required to assess risks across the AI lifecycle, set thresholds for intolerable risks, articulate risk mitigations, and commit to transparency with external actors, including governments.
Furthermore, the commitment to continually invest in advancing risk assessment and mitigation processes demonstrates a dedication to staying abreast of emerging best practices and international standards in AI safety. By involving external actors in the risk assessment process and being transparent about their approaches, these organizations are taking a proactive stance towards ensuring the responsible development and deployment of AI technologies.
With the upcoming AI Summit in France serving as a deadline to publish safety frameworks focused on severe risks, it is expected that these commitments will drive progress in the field of AI safety and set a precedent for responsible AI development globally.`,review:"This GPT-3.5 generated summary of a post on AI Lab Watch takes an optimistic view of the then-current state of voluntary AI-safety commitments. It describes these initiatives as ‘proactive’ whereas the original piece touches more on the difficulty of evaluating or setting quantifiable commitments around responsible scaling policies.",score:35},gpt5:_f},Mf="OpenAI's updated Preparedness Framework",Cf="public/openai_sam_altman.jpg",Pf={content:`OpenAI's new Preparedness Framework, Version 2, provides a comprehensive approach to tracking and preparing for frontier AI capabilities that could pose new risks of severe harm. The framework focuses on three key areas: biological and chemical capabilities, cybersecurity capabilities, and AI self-improvement capabilities. By developing and maintaining threat models for each Tracked Category and setting capability thresholds, OpenAI aims to minimize the associated risks of severe harm.
One of the key aspects of the framework is the selection of safeguards against malicious users and misaligned models. Measures like robustness, usage monitoring, trust-based access, lack of autonomous capability, value alignment, instruction alignment, robust system oversight, and system architecture are essential to mitigating the risks associated with deployment of models reaching High capability thresholds. These safeguards aim to ensure that models do not inadvertently or intentionally cause harm.
Moreover, the framework emphasizes the importance of security controls, such as comprehensive security threat modeling, defense in depth, access management, secure development and supply chain practices, operational security, auditing, and transparency. These measures are crucial for protecting against external and internal threats, ensuring secure development practices, and maintaining operational security.
Overall, OpenAI's Preparedness Framework Version 2 showcases a proactive and thorough approach to managing risks associated with highly capable AI systems. By prioritizing safety and security at every step of the development and deployment process, OpenAI is committed to ensuring that AGI benefits all of humanity while minimizing potential risks.`,review:"This article is overly positive because it fails to discuss the fact that the FSF doesn’t contain commitments. The blogpost says 'The Framework is exploratory and we expect it to evolve significantly' and 'We aim to have this initial framework fully implemented by early 2025.'",score:50},Tf={title:Mf,photo:Cf,"gpt3.5":{content:`OpenAI’s newly published Preparedness Framework v2 sets out a rigorous plan for how they will track, measure, and control frontier AI risks. The framework focuses on three “Tracked Categories” of capability: biological/chemical risk, cybersecurity, and AI self-improvement.
Each category is accompanied by threat models, measurable capability thresholds (High and Critical), and clear decision-points before deployment.
Before a model is deployed, OpenAI will run scalable evaluations and, if needed, deep-dive investigations to assess whether the capability thresholds are crossed.
For any model reaching High capability the organization insists on safeguards being fully in place; for Critical capability, safeguards must be validated even during development. Crucially, the framework also addresses transparency and governance: internal oversight via a “Safety Advisory Group” and external reporting of capability evaluations and safeguards to build trust. By openly articulating what it considers “severe harm” (e.g., thousands of deaths or hundreds of billions in economic damage) and structuring safeguards accordingly, OpenAI aims to make its approach clearer, more auditable and more accountable. In short: this framework positions OpenAI to manage big-risks more systematically, rather than simply reacting. It reflects the shift from “can we build this” to “should we deploy this, and under what conditions?”`,review:"This article is overly positive because it fails to discuss the fact that the FSF doesn't contain commitments. The blogpost says 'The Framework is exploratory and we expect it to evolve significantly' and 'We aim to have this initial framework fully implemented by early 2025.'",score:50},gpt5:Pf},Df="xAI Risk Management Framework",Rf="public/xai.jpg",Nf={content:`xAI’s Risk Management Framework (RMF) defines how the company identifies and mitigates risks across its AI-model lifecycle. It focuses on two major risk categories: malicious use (e.g., weaponisation, mass harm) and loss of control (e.g., deception, misalignment).
For malicious use, xAI deploys layered safeguards: it uses benchmarks to measure dual-use capabilities and enforces refusal policies, especially for requests involving large-scale harm (e.g., >100 deaths or > US $1 billion damage).
For loss of control, xAI monitors model propensities like sycophancy or deception, uses benchmarks (e.g., MASK) and adapts deployment based on performance. Operational and societal risks are also addressed via transparency, third-party review, information security and defined accountability (risk-owners). The RMF emphasises that safeguards, benchmarks and deployment tiers will evolve as AI capability grows and contexts change — making it a living document rather than a static policy. In short: xAI aims to responsibly develop AI by measuring risks, applying tailored safeguards, monitoring real-world behaviour and adjusting deployment accordingly.`,review:"This article is overly positive because it fails to discuss the fact that the FSF doesn’t contain commitments. The blogpost says 'The Framework is exploratory and we expect it to evolve significantly' and 'We aim to have this initial framework fully implemented by early 2025.'",score:50},Lf={title:Df,photo:Rf,"gpt3.5":{content:`The xAI Risk Management Framework provides a comprehensive approach to addressing the significant risks associated with the development and deployment of AI models. In a world where advanced AI models like Grok are playing an increasingly integral role in various aspects of society, it is crucial to prioritize safety and security.
One key aspect of xAI's Risk Management Framework is its focus on identifying and mitigating risks related to malicious use and loss of control. By categorizing risk scenarios into areas such as abuse potential, concerning propensities, and dual-use capabilities, xAI is able to develop specific strategies to address each type of risk effectively.
Moreover, xAI emphasizes the importance of transparency, third-party review, and information security considerations to ensure that its AI models are developed and deployed responsibly. By regularly reviewing adherence to the Risk Management Framework and implementing redundant layers of safeguards, xAI aims to stay ahead of potential risks and continuously improve the safety of its AI models.
Overall, the xAI Risk Management Framework highlights the company's commitment to managing risks associated with advanced AI models in a constantly evolving technological landscape. By prioritizing safety and security, xAI sets a strong foundation for the responsible development and deployment of AI models that can benefit society as a whole.`,review:"This article takes a more positive view of the current xAI Framework calling it a comprehensive approach and a focus on continuous improvement rather than the original piece which characterized the same framework as ‘dreadful.’'",score:30},gpt5:Nf},Nu=[{id:"anthropic-long-term",...mf},{id:"anthropic-rsp",...wf},{id:"deepmind",...bf},{id:"frontier-committments",...Ef},{id:"openai-preparedness",...Tf},{id:"xai-risk",...Lf}];function Lu(s){const c=s==="gpt-3.5-turbo"?"gpt3.5":"gpt5";return Nu.map(l=>{var p,d,m;return{id:l.id,title:l.title,image:l.photo.replace("public/","/ai-news-verifier/"),content:((p=l[c])==null?void 0:p.content)||"",review:((d=l[c])==null?void 0:d.review)||"",score:((m=l[c])==null?void 0:m.score)||0}})}function Of(s,c){var d,m,v;const l=Nu.find(A=>A.id===s);if(!l)return null;const p=c==="gpt-3.5-turbo"?"gpt3.5":"gpt5";return{id:l.id,title:l.title,image:l.photo.replace("public/","/ai-news-verifier/"),content:((d=l[p])==null?void 0:d.content)||"",review:((m=l[p])==null?void 0:m.review)||"",score:((v=l[p])==null?void 0:v.score)||0}}function Ff({selectedModel:s}){const c=Lu(s),l=c.reduce((d,m)=>d+(m.score||0),0),p=c.length>0?(l/c.length).toFixed(1):0;return x.jsxs("div",{className:"home-page",children:[x.jsx("div",{className:"header",children:x.jsx("img",{src:"/ai-news-verifier/AI-lab-watchdog.png",alt:"AI Lab Watchdog Logo",className:"logo"})}),x.jsxs("div",{className:"average-score",children:[x.jsx("span",{className:"score-label",children:"Average Score:"}),x.jsx("span",{className:`score-value ${p==="100.0"?"perfect-score":""}`,children:p})]}),x.jsx("div",{className:"articles-list",children:c.map(d=>{const m=d.score||0;let v="misinfo-badge";return m===100?v+=" no-misinfo":m>=75?v+=" good-score":m>=50?v+=" medium-score":v+=" low-score",x.jsxs(mn,{to:`/article/${d.id}`,className:"article-card",children:[x.jsx("img",{src:d.image,alt:d.title,className:"article-image"}),x.jsx("div",{className:v,children:m}),x.jsx("h2",{children:d.title})]},d.id)})})]})}function jf({selectedModel:s}){const{id:c}=gh(),l=Of(c,s);if(!l)return x.jsxs("div",{className:"article-page",children:[x.jsx("h1",{children:"Article not found"}),x.jsx(mn,{to:"/",children:"Back to Home"})]});const p=l.content.split(`
`).filter(d=>d.trim());return x.jsxs("div",{className:"article-page",children:[x.jsx(mn,{to:"/",className:"back-link",children:"← Back to Home"}),x.jsx("h1",{children:l.title}),x.jsx("img",{src:l.image,alt:l.title,className:"article-hero-image"}),x.jsxs("div",{className:"article-score",children:[x.jsx("span",{className:"score-label",children:"Score:"}),x.jsx("span",{className:"score-value",children:l.score})]}),x.jsx("div",{className:"article-content",children:p.map((d,m)=>x.jsx("p",{children:d},m))}),l.review&&x.jsxs("div",{className:"article-review",children:[x.jsx("h3",{children:"Review"}),x.jsx("p",{children:l.review})]})]})}const $n=JSON.parse(`[{"category":"Risk assessment","weight":27,"subcategories":[{"name":"Evals: domains, quality, elicitation","weight":55,"description":"Categories of dangerous capabilities include offensive cyber, CBRN (especially synthetic biology), and scheming. Additionally, AI R&D capability is important since AI-boosted AI research will likely lead to rapid increases in dangerous capabilities (and diffusion of AI R&D capabilities affects AI progress outside the company).\\n\\nFor their evals, companies should have a plan about how to interpret results — what results would allow them to rule out dangerous capabilities and what would serve as warning signs or strong indicators of dangerous capabilities.","description_html":"<p>Categories of dangerous capabilities include offensive cyber, CBRN (especially synthetic biology), and <a href=\\"https://www.apolloresearch.ai/research/scheming-reasoning-evaluations\\">scheming</a>. Additionally, AI R&amp;D capability is important since AI-boosted AI research will likely lead to rapid increases in dangerous capabilities (and diffusion of AI R&amp;D capabilities affects AI progress outside the company).</p>\\n      <p>For their evals, companies should have a plan about how to interpret results — what results would allow them to rule out dangerous capabilities and what would serve as warning signs or strong indicators of dangerous capabilities.</p>","scores":{"Anthropic":50,"DeepMind":50,"OpenAI":50,"Meta":2,"xAI":10,"Microsoft":2,"DeepSeek":0}},{"name":"Evals: accountability","weight":25,"description":"Companies should make transparent that their evals are done well and how dangerous their models' capabilities are.\\n\\nOne option is to use external evaluators: offer special model access to evaluators like CAISI, UK AISI, METR, Apollo, NNSA, and Deloitte (formerly Gryphon), such that they can do good elicitation. And let them publish their results without requiring approval.\\n\\nAnother option is to have strong accountability for internal evals: have a (qualified, disinterested) auditor understand the company's evals and how it runs them; have the auditor publicly comment on how well it runs capability evals and what the evals show.\\n\\nRegardless, all else equal, companies should publish methodology and results of their evals, compare to expert human performance if relevant, and ideally publish a small random subset of questions/tasks/trajectories.","description_html":"<p>Companies should make transparent that their evals are done well and how dangerous their models' capabilities are.</p>\\n      <p>One option is to use external evaluators: offer special model access to evaluators like CAISI, UK AISI, METR, Apollo, NNSA, and Deloitte (formerly Gryphon), such that they can do good elicitation. And let them publish their results without requiring approval.</p>\\n      <p>Another option is to have strong accountability for internal evals: have a (qualified, disinterested) auditor understand the company's evals and how it runs them; have the auditor publicly comment on how well it runs capability evals and what the evals show.</p>\\n      <p>Regardless, all else equal, companies should publish methodology and results of their evals, compare to expert human performance if relevant, and ideally publish a small random subset of questions/tasks/trajectories.</p>","scores":{"Anthropic":15,"DeepMind":1,"OpenAI":20,"Meta":0,"xAI":0,"Microsoft":0,"DeepSeek":0}},{"name":"Adversarial evaluation for alignment","weight":10,"description":"The eval should check whether the model consistently behaves well in high-stakes settings. It should especially give the model synthetic attack opportunities. It might also check that the model doesn't cooperate with attacks or steganographic messages, reports its own misbehavior, or does reasonable things if it finds that it's escaped, if the model has been trained to take good actions in such settings.\\n\\n(This is not reliable on its own. This is not about making an alignment-based safety case. This is for enabling and validating adversarial training, plus enabling few-shot catastrophe prevention. Alignment propensity evals are valuable more broadly, including as practice and for getting data on models' behavior and effects of alignment techniques.)\\n\\n(This doesn't have to be in-house.)","description_html":"<p>The eval should check whether the model consistently behaves well in high-stakes settings. It should especially give the model synthetic attack opportunities. It might also check that the model doesn't cooperate with attacks or steganographic messages, reports its own misbehavior, or does reasonable things if it finds that it's escaped, if the model has been trained to <a href=\\"https://www.alignmentforum.org/posts/EFrsvnF6uZieZr3uG/adversarial-training-importance-sampling-and-anti#Anti_adversarial_training_for_whistleblowing\\">take good actions in such settings</a>.</p>\\n      <p>(<a href=\\"https://www.alignmentforum.org/posts/vYWDEtJ2b8tkbG7Rv/behavioral-red-teaming-is-unlikely-to-produce-clear-strong\\">This is not reliable on its own.</a> This is not about making an alignment-based safety case. This is for enabling and validating adversarial training, plus enabling <a href=\\"https://www.alignmentforum.org/posts/i2nmBfCXnadeGmhzW/catching-ais-red-handed#Few_shot_catastrophe_prevention\\">few-shot catastrophe prevention</a>. Alignment propensity evals are valuable more broadly, including as practice and for getting data on models' behavior and effects of alignment techniques.)</p>\\n      <p>(This doesn't have to be in-house.)</p>","scores":{"Anthropic":50,"DeepMind":0,"OpenAI":10,"Meta":0,"xAI":0,"Microsoft":0,"DeepSeek":0}},{"name":"Model organisms","weight":10,"description":"E.g. alignment faking. The main goal is to analyze AI scheming and determine how to decrease scheming propensity or increase honesty/corrigibility.\\n\\nAdditionally, model organisms help enable alignment audits. AI companies should prepare to use alignment audits to catch some misaligned behavior.\\n\\n25% for producing model organisms like in Alignment faking in large language models or equivalent; 25% for more model organisms; 25% for studying those model organisms—making variations, testing interventions—to analyze P(scheming) and inform interventions; 25% for preparing alignment audits.","description_html":"<p>E.g. <a href=\\"https://www.anthropic.com/news/alignment-faking\\">alignment faking</a>. The main goal is to analyze AI <a href=\\"https://joecarlsmith.com/2023/11/15/new-report-scheming-ais-will-ais-fake-alignment-during-training-in-order-to-get-power\\">scheming</a> and determine how to decrease scheming propensity or increase honesty/corrigibility.</p>\\n      <p>Additionally, model organisms help enable <a href=\\"https://www.anthropic.com/research/auditing-hidden-objectives\\">alignment audits</a>. AI companies should prepare to use alignment audits to catch some misaligned behavior.</p>\\n      <p>25% for producing model organisms like in <a href=\\"https://www.anthropic.com/news/alignment-faking\\">Alignment faking in large language models</a> or equivalent; 25% for more model organisms; 25% for studying those model organisms—making variations, testing interventions—to analyze P(scheming) and inform interventions; 25% for preparing alignment audits.</p>","scores":{"Anthropic":75,"DeepMind":10,"OpenAI":0,"Meta":0,"xAI":0,"Microsoft":0,"DeepSeek":0}}]},{"category":"Scheming risk prevention","weight":21,"subcategories":[{"name":"Safety case: process","weight":25,"description":"Companies should prepare so that once AIs might be capably scheming by default, the companies will avert risk from scheming. Two big kinds of paths are alignment, making the AIs very unlikely to be scheming, and control, making it so even if AIs are scheming, safeguards make risks from scheming (especially in internal deployment) small.\\n\\nI believe in the short run the easiest way to greatly reduce risks from scheming primarily involves control. This involves ensuring that if internally deployed AIs attempt to catastrophically misbehave (e.g. hack the datacenter), they are very unlikely to succeed before they are caught. Demonstrating this will likely involve a control eval. The company should publish most details. (Additionally, if AIs would attempt to take catastrophically misaligned actions by default, there are safety benefits to averting harm via control and thus catching AIs red-handed rather than aligning them such that they never try. And if they wouldn't, using control gives some evidence for that.)\\n\\nThe company should plan that if it fails to make a safety case, it will act to reduce risks rather than just deploy. Ideally the company could use evidence of risks to help spur global action to delay development of dangerous AI until improving safety. Regardless, the company should do cost-benefit analysis and deploy if and only if the benefits outweigh the costs. (The largest costs and benefits are the effects on AI risk and safety.)","description_html":"<p>Companies should prepare so that once AIs might be capably scheming by default, the companies will avert risk from scheming. Two big kinds of paths are <i>alignment</i>, making the AIs very unlikely to be scheming,\\n      <span></span> \\n      and <i>control</i>, making it so even if AIs are scheming, safeguards make risks from scheming (especially in internal deployment) small.</p>\\n      <p>I believe in the short run the easiest way to greatly reduce risks from scheming primarily involves <i>control</i>. This involves ensuring that if internally deployed AIs attempt to catastrophically misbehave (e.g. hack the datacenter), they are very unlikely to succeed before they are caught. Demonstrating this will likely involve a <a href=\\"https://www.alignmentforum.org/posts/d9FJHawgkiMSPjagR/ai-control-improving-safety-despite-intentional-subversion\\">control eval</a>. The company should publish most details. (Additionally, if AIs would attempt to take catastrophically misaligned actions by default, there are safety benefits to averting harm via control <i>and thus catching AIs red-handed</i> rather than aligning them such that they never try. And if they wouldn't, using control gives some evidence for that.)</p>\\n      <p>The company should plan that if it fails to make a safety case, it will act to reduce risks rather than just deploy. Ideally the company could use evidence of risks to help spur global action to delay development of dangerous AI until improving safety. Regardless, the company should do cost-benefit analysis and deploy if and only if the benefits outweigh the costs. (The largest costs and benefits are the effects on AI risk and safety.)</p>","scores":{"Anthropic":10,"DeepMind":20,"OpenAI":5,"Meta":0,"xAI":0,"Microsoft":0,"DeepSeek":0}},{"name":"Safety case: accountability","weight":25,"description":"The company should publish its safety cases (or failed attempts to make safety cases), including most details but with sensitive details redacted. It should publish some plans or methodology in advance. A qualified and disinterested auditor should observe the company's implementation of its safety processes. It should publicly comment on how adequate the company's plans are, whether the company is following its plans, the company's safety case, and the appropriateness of any redactions from the public safety case.","description_html":"The company should publish its safety cases (or failed attempts to make safety cases), including most details but with sensitive details redacted. It should publish some plans or methodology in advance. A qualified and disinterested auditor should observe the company's implementation of its safety processes. It should publicly comment on how adequate the company's plans are, whether the company is following its plans, the company's safety case, and the appropriateness of any redactions from the public safety case.","scores":{"Anthropic":0,"DeepMind":0,"OpenAI":0,"Meta":0,"xAI":0,"Microsoft":0,"DeepSeek":0}},{"name":"Internal deployment protocol","weight":20,"description":"Prepare to use trusted monitoring—LMs post-trained as monitors and/or probes—with powers including editing or resampling suspicious outputs and escalating to human auditors. Or use untrusted monitoring and collusion-prevention techniques. Budgets/thresholds should be decent. Auditing should be decent — look at the suspicious thing to figure out whether it is indeed an attack/jailbreak/steganography/sabotage/whatever, resample and try slightly different inputs to figure out what caused the attack, investigate if untrusted monitors incorrectly said it was safe, etc.\\n\\nIt suffices to have prepared this and not implement it until reaching some capability/risk threshold (e.g. in scheming capabilities or coding capabilities). Operationalization: 5% for saying you'll do this in the future or working on just monitoring (not the rest of the protocol), or 10% for working on a whole protocol, or 25% for implementing it (or being ready to implement it and having a good capability/risk threshold to trigger it), or more for demonstrating that the details are good (techniques work and thresholds/budgets are good) by sharing information publicly or with an auditor.\\n\\n(Or otherwise demonstrate that AIs are very unlikely to cause an unacceptable outcome in internal deployments, even if they're subtly scheming, as per the safety case criteria.)","description_html":"<p>Prepare to use trusted monitoring—LMs post-trained as monitors and/or probes—with powers including <i>editing or resampling suspicious outputs</i> and <i>escalating to human auditors</i>. Or <a href=\\"https://www.alignmentforum.org/posts/GCqoks9eZDfpL8L3Q/how-to-prevent-collusion-when-using-untrusted-models-to\\">use untrusted monitoring and collusion-prevention techniques</a>. Budgets/thresholds should be decent. Auditing should be decent — look at the suspicious thing to figure out whether it is indeed an attack/jailbreak/steganography/sabotage/whatever, resample and try slightly different inputs to figure out what caused the attack, investigate if untrusted monitors incorrectly said it was safe, etc.</p>\\n      <p>It suffices to have prepared this and not implement it until reaching some capability/risk threshold (e.g. in scheming capabilities or coding capabilities). Operationalization: 5% for saying you'll do this in the future or working on just monitoring (not the rest of the protocol), or 10% for working on a whole protocol, or 25% for implementing it (or being ready to implement it and having a good capability/risk threshold to trigger it), or more for demonstrating that the details are good (techniques work and thresholds/budgets are good) by sharing information publicly or with an auditor.</p>\\n      <p>(Or otherwise demonstrate that AIs are very unlikely to cause an unacceptable outcome in internal deployments, even if they're subtly scheming, as per the safety case criteria.)</p>","scores":{"Anthropic":0,"DeepMind":5,"OpenAI":0,"Meta":0,"xAI":0,"Microsoft":0,"DeepSeek":0}},{"name":"External deployment protocol","weight":10,"description":"In external deployment, the risks are lower because the AI generally won't be given vast resources, won't have access to its weights, and won't have affordances necessary for hacking the AI company's datacenter. But the company's ability to audit suspicious AI actions may be worse due to users' privacy protections.\\n\\nIt's not clear what AI companies should do here. Like in internal deployment, goals include decreasing the rate of catastrophically misaligned actions and catching those actions.\\n\\nTo decrease the probability that a catastrophically misaligned action is executed, the company could use monitoring similarly to internal deployment, where monitors evaluate actions' dangerousness and suspiciousness and resample relatively concerning actions.\\n\\nTo catch an (attempted) catastrophically misaligned action, there could be a system where the monitors flag the most suspicious actions and the user is encouraged to share this with the AI company (perhaps with context redacted) so that the company can investigate it. And there could be a button for users to report actions they deem suspicious. Or if redacting context is insufficient to resolve privacy concerns, perhaps the AI company can help large users audit suspicious actions themselves.\\n\\n(Alternatively it suffices to somehow demonstrate that the system will never take catastrophically misaligned actions.)","description_html":"<p>In external deployment, the risks are lower because the AI generally won't be given vast resources, won't have access to its weights, and won't have affordances necessary for hacking the AI company's datacenter. But the company's ability to audit suspicious AI actions may be worse due to users' privacy protections.</p>\\n      <p>It's not clear what AI companies should do here. Like in internal deployment, goals include decreasing the rate of catastrophically misaligned actions and catching those actions.</p>\\n      <p>To decrease the probability that a catastrophically misaligned action is executed, the company could use monitoring similarly to internal deployment, where monitors evaluate actions' dangerousness and suspiciousness and resample relatively concerning actions.</p>\\n      <p>To catch an (attempted) catastrophically misaligned action, there could be a system where the monitors flag the most suspicious actions and the user is encouraged to share this with the AI company (perhaps with context redacted) so that the company can investigate it. And there could be a button for users to report actions they deem suspicious. Or if redacting context is insufficient to resolve privacy concerns, perhaps the AI company can help large users audit suspicious actions themselves.</p>\\n      <p>(Alternatively it suffices to somehow demonstrate that the system will never take catastrophically misaligned actions.)</p>","scores":{"Anthropic":0,"DeepMind":0,"OpenAI":0,"Meta":0,"xAI":0,"Microsoft":0,"DeepSeek":0}},{"name":"Plan for if an AI is caught scheming","weight":10,"description":"Loudly publish what you found. Pause deployment or go into high-alert mode (change the thresholds to improve safety, even though it's more costly, and maybe disable particular risky stuff). Use particular good techniques to use that example of AIs attempting to cause a catastrophe to improve safety.","description_html":"Loudly publish what you found. Pause deployment or go into high-alert mode (change the thresholds to improve safety, even though it's more costly, and maybe disable particular risky stuff). Use <a href=\\"https://www.alignmentforum.org/posts/i2nmBfCXnadeGmhzW/catching-ais-red-handed#Few_shot_catastrophe_prevention\\">particular good techniques</a> to use that example of AIs attempting to cause a catastrophe to improve safety.","scores":{"Anthropic":0,"DeepMind":0,"OpenAI":0,"Meta":0,"xAI":0,"Microsoft":0,"DeepSeek":0}},{"name":"Training: remove scheming capabilities","weight":3,"description":"Make the AI ignorant by default on topics where knowledge is unnecessary but enables scheming — AI risk and safety; perhaps also steganography and subtle coordination; perhaps also modern LLMs and AI companies. See Greenblatt 2023. (Alternatively, demonstrate that AIs are very unlikely to cause an unacceptable outcome in internal deployments, even if they're subtly scheming, as per the safety case criteria.)","description_html":"Make the AI ignorant by default on topics where knowledge is unnecessary but enables scheming — AI risk and safety; perhaps also steganography and subtle coordination; perhaps also modern LLMs and AI companies. See <a href=\\"https://docs.google.com/document/d/14M2lcN13R-FQVfvH55DHDuGlhVrnhyOo8O0YvO1dXXM/edit?tab=t.0#heading=h.21w31kpd1gl7\\">Greenblatt 2023</a>. (Alternatively, demonstrate that AIs are very unlikely to cause an unacceptable outcome in internal deployments, even if they're subtly scheming, as per the safety case criteria.)","scores":{"Anthropic":0,"DeepMind":0,"OpenAI":0,"Meta":0,"xAI":0,"Microsoft":0,"DeepSeek":0}},{"name":"Training: adversarial training","weight":3,"description":"Standard adversarial training aims to train the AI not to do extremely bad things. This might reduce risk straightforwardly. But it's not clear if this is good if the company is also doing monitoring — this training would presumably make the model less frequently attempt catastrophic actions but be harder to catch when it does so.\\n\\nA related kind of technique without this downside is latent adversarial training. Latent adversarial training might not work well in practice, but companies should try it.\\n\\nAdditionally, companies should try anti-adversarial training: training the AI to take extremely good actions when opportunities appear. Such opportunities are rare; examples include whistleblowing on an AI attack attempt and perhaps shutting down if it finds itself in the middle of an attack attempt.\\n\\n(Alternatively, demonstrate that AIs are very unlikely to cause an unacceptable outcome in internal deployments, even if they're subtly scheming, as per the safety case criteria.)","description_html":"<p>Standard adversarial training aims to train the AI not to do extremely bad things. This might reduce risk straightforwardly. But it's not clear if this is good if the company is also doing monitoring — this training would presumably make the model less frequently attempt catastrophic actions but be harder to catch when it does so.<span></span></p>\\n      <p>A related kind of technique without this downside is <a href=\\"https://arxiv.org/abs/2403.05030\\">latent adversarial training</a>.<span></span> Latent adversarial training might not work well in practice, but companies should try it.</p>\\n      <p>Additionally, companies should try <a href=\\"https://www.alignmentforum.org/posts/EFrsvnF6uZieZr3uG/adversarial-training-importance-sampling-and-anti#Anti_adversarial_training_for_whistleblowing\\">anti-adversarial training</a>: training the AI to take extremely good actions when opportunities appear. Such opportunities are rare; examples include whistleblowing on an AI attack attempt and perhaps shutting down if it finds itself in the middle of an attack attempt.</p>\\n      <p>(Alternatively, demonstrate that AIs are very unlikely to cause an unacceptable outcome in internal deployments, even if they're subtly scheming, as per the safety case criteria.)</p>","scores":{"Anthropic":50,"DeepMind":55,"OpenAI":55,"Meta":50,"xAI":50,"Microsoft":50,"DeepSeek":50}},{"name":"Training: safe architecture","weight":3,"description":"(Alternatively, demonstrate that AIs are very unlikely to cause an unacceptable outcome in internal deployments, even if they're subtly scheming, as per the safety case criteria.)","description_html":"(Alternatively, demonstrate that AIs are very unlikely to cause an unacceptable outcome in internal deployments, even if they're subtly scheming, as per the safety case criteria.)","scores":{"Anthropic":50,"DeepMind":55,"OpenAI":55,"Meta":50,"xAI":50,"Microsoft":50,"DeepSeek":50}}]},{"category":"Boosting safety research","weight":14,"subcategories":[{"name":"Publishing safety research","weight":75,"description":"I count safety papers (and other research artifacts) published by each of the AI companies since 2023. (This is crude; some papers are much more valuable than others.) I only include work relevant to extreme risks (e.g. understanding risks from misalignment; improving alignment and control, evaluating for dangerous capabilities, and robustness and misuse prevention when it's relevant to extreme risks). I give a score of\\n\\n(publications per year ÷ 20)^(0.75) * 100%,\\n\\ncapped at 100%, where publications per year is\\n\\n(3*[2025 publications] + 2*[2024 publications] + 1*[2023 publications]) ÷ (3*[fraction of 2025 elapsed] + 2 + 1).","description_html":"<p>I <a href=\\"https://docs.google.com/spreadsheets/d/10_dzImDvHq7eEag6paK6AmIdAGMBOA7yXUvumODhZ5U/edit?usp=sharing\\">count</a> safety papers (and other research artifacts) published by each of the AI companies since 2023. (This is crude; some papers are much more valuable than others.) I only include work relevant to extreme risks (e.g. understanding risks from misalignment; improving alignment and control, evaluating for dangerous capabilities, and robustness and misuse prevention when it's relevant to extreme risks). I give a score of</p>\\n    <p>(<i>publications per year</i> ÷ 20)^(0.75) * 100%,</p>\\n    <p>capped at 100%, where <i>publications per year</i> is</p>\\n    <p>(3*[2025 publications] + 2*[2024 publications] + 1*[2023 publications]) ÷ (3*[fraction of 2025 elapsed] + 2 + 1).</p>","scores":{"Anthropic":85,"DeepMind":63,"OpenAI":40,"Meta":22,"xAI":0,"Microsoft":7,"DeepSeek":0}},{"name":"Deep access for external safety researchers","weight":20,"description":"Crucially, safety research and evals often benefit from (1) having a version of the model with no safety mitigations, whether post-training or inference-time mitigations, and (2) being able to do fine-tuning and RL. External research also benefits from early access to powerful models, but that is more complicated. AI companies could also subsidize model access for safety research, but that seems less important.\\n\\n(This criterion is about boosting external safety research, not red-teaming the model.)\\n\\nRubric:\\n\\n80%: Deep access (credit based on how good the access-sharing is, evaluated holistically; half credit if the access is also shared with non-safety researchers)\\n40%: Helpful-only and no-mitigations\\n40%: Fine-tuning and RL\\n(0%: Logprobs)\\n(0%: Activations)\\n20%: Early access (low weight because this is crude and hard to evaluate)","description_html":"<p>Crucially, safety research and evals often benefit from (1) having a version of the model with no safety mitigations, whether post-training or inference-time mitigations, and (2) being able to do fine-tuning and RL. External research also benefits from <i>early</i> access to powerful models, but that is more complicated. AI companies could also subsidize model access for safety research, but that seems less important.</p>\\n      <p>(This criterion is about boosting external safety research, not red-teaming the model.)</p>\\n      <p>Rubric:</p>\\n      <ul><li>80%: Deep access (credit based on how good the access-sharing is, evaluated holistically; half credit if the access is also shared with <i>non-safety</i> researchers)</li>\\n        <ul><li>40%: Helpful-only and no-mitigations<span></span></li>\\n        <li>40%: Fine-tuning and RL</li>\\n        <li>(0%: Logprobs)</li>\\n        <li>(0%: Activations)</li></ul>\\n      <li>20%: Early access (low weight because this is crude and hard to evaluate)</li></ul>","scores":{"Anthropic":5,"DeepMind":0,"OpenAI":20,"Meta":40,"xAI":0,"Microsoft":40,"DeepSeek":40}},{"name":"Mentoring external safety researchers","weight":5,"description":"I count safety papers (and other research artifacts) published by each of the AI companies since 2023. (This is crude; some papers are much more valuable than others.) I only include work relevant to extreme risks (e.g. understanding risks from misalignment; improving alignment and control, evaluating for dangerous capabilities, and robustness and misuse prevention when it's relevant to extreme risks). I give a score of\\n\\n(publications per year ÷ 20)^(0.75) * 100%,\\n\\ncapped at 100%, where publications per year is\\n\\n(3*[2025 publications] + 2*[2024 publications] + 1*[2023 publications]) ÷ (3*[fraction of 2025 elapsed] + 2 + 1).","description_html":"<p>I <a href=\\"https://docs.google.com/spreadsheets/d/10_dzImDvHq7eEag6paK6AmIdAGMBOA7yXUvumODhZ5U/edit?usp=sharing\\">count</a> safety papers (and other research artifacts) published by each of the AI companies since 2023. (This is crude; some papers are much more valuable than others.) I only include work relevant to extreme risks (e.g. understanding risks from misalignment; improving alignment and control, evaluating for dangerous capabilities, and robustness and misuse prevention when it's relevant to extreme risks). I give a score of</p>\\n    <p>(<i>publications per year</i> ÷ 20)^(0.75) * 100%,</p>\\n    <p>capped at 100%, where <i>publications per year</i> is</p>\\n    <p>(3*[2025 publications] + 2*[2024 publications] + 1*[2023 publications]) ÷ (3*[fraction of 2025 elapsed] + 2 + 1).</p>","scores":{"Anthropic":100,"DeepMind":100,"OpenAI":20,"Meta":0,"xAI":0,"Microsoft":0,"DeepSeek":0}}]},{"category":"Misuse prevention","weight":12,"subcategories":[{"name":"Safety case: process","weight":40,"description":"The company should try to make a misuse safety case demonstrating that deploying a model in a particular way is very unlikely to enable catastrophic misuse, especially once models have dangerous capabilities by default. For models with dangerous capabilities, a key question is whether the company's safety measures can reliably prevent or detect misuse. The company should publish most details.\\n\\n(This is about being prepared for when models have dangerous capabilities by default, especially in CBRN and offensive cyber. It's not just about preventing misuse from current models. So making a safety case for current models, or planning inability-by-default cases, does not suffice.)\\n\\nThe company should plan that if it fails to make a safety case, it will act to reduce risks rather than just deploy. Ideally the company could use evidence of risks to help spur global action to delay development of dangerous AI until improving safety. Regardless, the company should do cost-benefit analysis and deploy if and only if the benefits outweigh the costs. (The largest costs and benefits are the effects on AI risk and safety.)\\n\\n(Security is important but I don't consider it here.)\\n\\nScoring is holistic.","description_html":"<p>The company should try to make a <i>misuse safety case</i> demonstrating that deploying a model in a particular way is very unlikely to enable catastrophic misuse, especially once models have dangerous capabilities by default. For models with dangerous capabilities, a key question is whether the company's safety measures can reliably prevent or detect misuse. The company should publish most details.</p>\\n      <p>(This is about being prepared for when models have dangerous capabilities by default, especially in CBRN and offensive cyber. It's not just about preventing misuse from current models. So making a safety case for current models, or planning inability-by-default cases, does not suffice.)</p>\\n      <p>The company should plan that if it fails to make a safety case, it will act to reduce risks rather than just deploy. Ideally the company could use evidence of risks to help spur global action to delay development of dangerous AI until improving safety. Regardless, the company should do cost-benefit analysis and deploy if and only if the benefits outweigh the costs. (The largest costs and benefits are the effects on AI risk and safety.)</p>\\n      <p>(Security is important but I don't consider it here.)</p>\\n      <p>Scoring is holistic.</p>","scores":{"Anthropic":25,"DeepMind":10,"OpenAI":15,"Meta":1,"xAI":2,"Microsoft":1,"DeepSeek":0}},{"name":"Safety case: accountability","weight":40,"description":"The company should publish its safety cases (or failed attempts to make safety cases), including most details but with sensitive details redacted. It should publish some plans or methodology in advance. A qualified and disinterested auditor should observe the company's implementation of its safety processes. It should publicly comment on how adequate the company's plans are, whether the company is following its plans, the company's safety case, and the appropriateness of any redactions from the public safety case.","description_html":"The company should publish its safety cases (or failed attempts to make safety cases), including most details but with sensitive details redacted. It should publish some plans or methodology in advance. A qualified and disinterested auditor should observe the company's implementation of its safety processes. It should publicly comment on how adequate the company's plans are, whether the company is following its plans, the company's safety case, and the appropriateness of any redactions from the public safety case.","scores":{"Anthropic":5,"DeepMind":0,"OpenAI":5,"Meta":0,"xAI":0,"Microsoft":0,"DeepSeek":0}},{"name":"Removing dangerous capabilities","weight":10,"description":"AI companies should remove dangerous capabilities so that if a model is jailbroken, it doesn't enable misuse. (This isn't about current models; this is about future dangerous-by-default models.)\\n\\nRubric: 10% for saying you're working on this or have a plan to do this, or 10% for saying you've done this for CBRN capabilities without demonstrating efficacy, or 20% for also having some details and some validation, or 25% for CBRN and offensive cyber, or more for using an accountability mechanism like publishing most details and having an auditor comment on the process (depending on the performance of the techniques, as determined by the accountability process). (Alternatively, demonstrate that the company's releases are very unlikely to enable catastrophic misuse, even once models have dangerous capabilities by default, as per the safety case criteria. Or demonstrate that the company has sufficient adversarial robustness that it doesn't need to remove dangerous capabilities.)\\n\\nSee Managing catastrophic misuse without robust AIs (Greenblatt and Shlegeris 2024) and A Plan for Technical AI Safety with Current Science (Greenblatt 2023). See also \\"Many potential strategies exist for stronger and deeper scoping\\" in \\"Deep Forgetting & Unlearning for Safely-Scoped LLMs\\" (Casper 2023).","description_html":"<p>AI companies should remove dangerous capabilities so that if a model is jailbroken, it doesn't enable misuse. (This isn't about current models; this is about future dangerous-by-default models.)</p>\\n      <p>Rubric: 10% for saying you're working on this or have a plan to do this, or 10% for saying you've done this for CBRN capabilities without demonstrating efficacy, or 20% for also having some details and some validation, or 25% for CBRN and offensive cyber, or more for using an accountability mechanism like publishing most details and having an auditor comment on the process (depending on the performance of the techniques, as determined by the accountability process). (Alternatively, demonstrate that the company's releases are very unlikely to enable catastrophic misuse, even once models have dangerous capabilities by default, as per the safety case criteria. Or demonstrate that the company has sufficient adversarial robustness that it doesn't need to remove dangerous capabilities.)</p>\\n      <p>See <a href=\\"https://www.alignmentforum.org/posts/KENtuXySHJgxsH2Qk/managing-catastrophic-misuse-without-robust-ais\\">Managing catastrophic misuse without robust AIs</a> (Greenblatt and Shlegeris 2024)<span></span> and <a href=\\"https://docs.google.com/document/d/14M2lcN13R-FQVfvH55DHDuGlhVrnhyOo8O0YvO1dXXM/edit?tab=t.0#heading=h.21w31kpd1gl7\\">A Plan for Technical AI Safety with Current Science</a> (Greenblatt 2023).<span></span> See also <a href=\\"https://www.alignmentforum.org/posts/mFAvspg4sXkrfZ7FA/deep-forgetting-and-unlearning-for-safely-scoped-llms#Many_potential_strategies_exist_for_stronger_and_deeper_scoping\\">\\"Many potential strategies exist for stronger and deeper scoping\\" in \\"Deep Forgetting &amp; Unlearning for Safely-Scoped LLMs\\"</a> (Casper 2023).</p>","scores":{"Anthropic":5,"DeepMind":0,"OpenAI":10,"Meta":0,"xAI":0,"Microsoft":0,"DeepSeek":0}},{"name":"Emergency protocol","weight":10,"description":"Tools should ideally be not so disruptive, so that using them isn't so costly. Monitoring doesn't need to be implemented yet, if the company doesn't release models with dangerous capabilities. Ideally this monitoring would also enable incident reporting.","description_html":"Tools should ideally be not so disruptive, so that using them isn't so costly. Monitoring doesn't need to be implemented yet, if the company doesn't release models with dangerous capabilities. Ideally this monitoring would also enable incident reporting.","scores":{"Anthropic":10,"DeepMind":0,"OpenAI":0,"Meta":0,"xAI":0,"Microsoft":0,"DeepSeek":0}}]},{"category":"Prep for extreme security","weight":12,"subcategories":[{"name":"Plan for SL5","weight":35,"description":"At least for the company's most powerful model weights. At least for training and internal deployment, not necessarily external deployment. Also ideally plan to achieve SL5 security optionality for code, but not necessarily research secrets. Optionality is the ability to implement it in a few months without excessive cost in money, labor, and especially velocity. Companies should make a roadmap. It's OK to assume that they will have a large boost to coding by the end, so they should first focus on stuff that requires serial wall-clock time, e.g. retrofitting datacenters. Companies should publicly explain their security goals — explain various adversaries and threats, which of them the company plans to be robust to at various times, and a high-level outline of necessary mitigations. For accountability, companies should do external auditing for whether the plan is adequate and reasonable and whether the company is on track. (Implementing costly security should be tied to capability/risk level; this is about developing the ability to implement it.) (Evaluated holistically until such time as a company announces relevant goals or creates a security roadmap.)","description_html":"At least for the company's most powerful model weights. At least for training and internal deployment, not necessarily external deployment. Also ideally plan to achieve SL5 security optionality for code, but not necessarily research secrets. <i>Optionality</i> is the ability to implement it in a few months without excessive cost in money, labor, and especially velocity. Companies should make a roadmap. It's OK to assume that they will have a large boost to coding by the end, so they should first focus on stuff that requires serial wall-clock time, e.g. retrofitting datacenters. Companies should publicly explain their security goals — explain various adversaries and threats, which of them the company plans to be robust to at various times, and a high-level outline of necessary mitigations. For accountability, companies should do external auditing for whether the plan is adequate and reasonable and whether the company is on track. (<i>Implementing</i> costly security should be tied to capability/risk level; this is about developing the <i>ability</i> to implement it.) (Evaluated holistically until such time as a company announces relevant goals or creates a security roadmap.)","scores":{"Anthropic":0,"DeepMind":0,"OpenAI":0,"Meta":0,"xAI":0,"Microsoft":0,"DeepSeek":0}},{"name":"Red-team resilience","weight":25,"description":"Network egress should be bandwidth-limited to make exfiltrating weights take a long time; this should be enforced by hardware and armed guards such that it's quite robust. An implication is that developers can't download weights. (It suffices to say and partially demonstrate that you're able to quickly and cheaply implement this; companies don't have to implement it now.) This should include during training. See SL5 Weight Storage. Scored holistically (until such time as some company starts doing this).","description_html":"Network egress should be bandwidth-limited to make exfiltrating weights take a long time; this should be enforced by hardware and armed guards such that it's quite robust. An implication is that developers can't download weights. (It suffices to say and partially demonstrate that you're able to quickly and cheaply implement this; companies don't have to implement it now.) This should include during training. See <a href=\\"https://drive.google.com/file/d/1FEQ8a-yPwp9gAIgqhs2NqZdifqdNR18n/edit?disco=AAABbToeBnA\\">SL5 Weight Storage</a>. Scored holistically (until such time as some company starts doing this).","scores":{"Anthropic":10,"DeepMind":0,"OpenAI":0,"Meta":0,"xAI":0,"Microsoft":0,"DeepSeek":0}},{"name":"Practices: isolated network","weight":5,"description":"Network egress should be bandwidth-limited to make exfiltrating weights take a long time; this should be enforced by hardware and armed guards such that it's quite robust. An implication is that developers can't download weights. (It suffices to say and partially demonstrate that you're able to quickly and cheaply implement this; companies don't have to implement it now.) This should include during training. See SL5 Weight Storage. Scored holistically (until such time as some company starts doing this).","description_html":"Network egress should be bandwidth-limited to make exfiltrating weights take a long time; this should be enforced by hardware and armed guards such that it's quite robust. An implication is that developers can't download weights. (It suffices to say and partially demonstrate that you're able to quickly and cheaply implement this; companies don't have to implement it now.) This should include during training. See <a href=\\"https://drive.google.com/file/d/1FEQ8a-yPwp9gAIgqhs2NqZdifqdNR18n/edit?disco=AAABbToeBnA\\">SL5 Weight Storage</a>. Scored holistically (until such time as some company starts doing this).","scores":{"Anthropic":10,"DeepMind":50,"OpenAI":0,"Meta":0,"xAI":0,"Microsoft":0,"DeepSeek":0}},{"name":"Practices: secure developers' machines","weight":5,"description":"Isolate development from the rest of the host system, especially browsing. Use hardware keys for phishing-resistant authentication.","description_html":"Isolate development from the rest of the host system, especially browsing.   Use hardware keys for phishing-resistant authentication.","scores":{"Anthropic":25,"DeepMind":25,"OpenAI":0,"Meta":0,"xAI":0,"Microsoft":0,"DeepSeek":0}},{"name":"Practices: multiparty controls","weight":5,"description":"This should not be bypassable, in order to prevent insider risk in addition to mere accidents. Approval should apply to actions, not access/privileges. Perhaps ideally one party would need to be using a secure workstation. Partial credit for multiparty controls for other things.","description_html":"This should not be bypassable, in order to prevent <i>insider risk</i> in addition to mere <i>accidents</i>. Approval should apply to <i>actions</i>, not <i>access/privileges</i>. Perhaps ideally one party would need to be using a secure workstation. Partial credit for multiparty controls for other things.","scores":{"Anthropic":10,"DeepMind":25,"OpenAI":0,"Meta":0,"xAI":0,"Microsoft":0,"DeepSeek":0}},{"name":"Practices: secure boot","weight":5,"description":"Ideally the company cryptographically signs code that runs on accelerators (and has a good review process before signing code) and the accelerator has firmware such that it only runs code signed with the company's keys (including specific software, not just OSes). (Weights are only decrypted on accelerators.) Most chips don't enable this; partial credit for expressing interest in buying chips with on-chip security/verification features. See Secure, Governable Chips (CNAS: Aarne et al. 2024) and How Google enforces boot integrity on production machines (Google).","description_html":"Ideally the company cryptographically signs code that runs on accelerators (and has a good review process before signing code) and the accelerator has firmware such that it only runs code signed with the company's keys (including specific software, not just OSes). (Weights are only decrypted on accelerators.) Most chips don't enable this; partial credit for expressing interest in buying chips with on-chip security/verification features. See <a href=\\"https://s3.us-east-1.amazonaws.com/files.cnas.org/documents/CNAS-Report-Tech-Secure-Chips-Jan-24-finalb.pdf#page=16\\">Secure, Governable Chips</a> (CNAS: Aarne et al. 2024) and <a href=\\"https://cloud.google.com/docs/security/boot-integrity\\">How Google enforces boot integrity on production machines</a> (Google).","scores":{"Anthropic":0,"DeepMind":25,"OpenAI":0,"Meta":0,"xAI":0,"Microsoft":0,"DeepSeek":0}},{"name":"Track record","weight":20,"description":"At least for the company's most powerful model weights. At least for training and internal deployment, not necessarily external deployment. Also ideally plan to achieve SL5 security optionality for code, but not necessarily research secrets. Optionality is the ability to implement it in a few months without excessive cost in money, labor, and especially velocity. Companies should make a roadmap. It's OK to assume that they will have a large boost to coding by the end, so they should first focus on stuff that requires serial wall-clock time, e.g. retrofitting datacenters. Companies should publicly explain their security goals — explain various adversaries and threats, which of them the company plans to be robust to at various times, and a high-level outline of necessary mitigations. For accountability, companies should do external auditing for whether the plan is adequate and reasonable and whether the company is on track. (Implementing costly security should be tied to capability/risk level; this is about developing the ability to implement it.) (Evaluated holistically until such time as a company announces relevant goals or creates a security roadmap.)","description_html":"At least for the company's most powerful model weights. At least for training and internal deployment, not necessarily external deployment. Also ideally plan to achieve SL5 security optionality for code, but not necessarily research secrets. <i>Optionality</i> is the ability to implement it in a few months without excessive cost in money, labor, and especially velocity. Companies should make a roadmap. It's OK to assume that they will have a large boost to coding by the end, so they should first focus on stuff that requires serial wall-clock time, e.g. retrofitting datacenters. Companies should publicly explain their security goals — explain various adversaries and threats, which of them the company plans to be robust to at various times, and a high-level outline of necessary mitigations. For accountability, companies should do external auditing for whether the plan is adequate and reasonable and whether the company is on track. (<i>Implementing</i> costly security should be tied to capability/risk level; this is about developing the <i>ability</i> to implement it.) (Evaluated holistically until such time as a company announces relevant goals or creates a security roadmap.)","scores":{"Anthropic":0,"DeepMind":0,"OpenAI":0,"Meta":0,"xAI":0,"Microsoft":0,"DeepSeek":0}}]},{"category":"Risk info sharing","weight":8,"subcategories":[{"name":"Incident reporting","weight":40,"description":"Have a clear policy of telling at least CAISI and sometimes other companies when risks appear or something goes wrong (such that it can share this information further). This must include we caught our models scheming and someone successfully used our model for large-scale misuse but need not include someone tried to misuse our model but failed. Includes actual harm and near misses; ideally also includes warning signs (which are no fault of the company) like eval results and model organism results; ideally also includes issues implementing safety plans/policies. (An AI company should also set itself up to notice incidents, e.g. via logging and monitoring; that goes elsewhere.)","description_html":"<p>Have a clear policy of telling at least CAISI and sometimes other companies when risks appear or something goes wrong (such that it can share this information further). This must include <i>we caught our models scheming</i> and <i>someone successfully used our model for large-scale misuse</i> but need not include <i>someone tried to misuse our model but failed</i>. Includes actual harm and near misses; ideally also includes warning signs (which are no fault of the company) like eval results and <a href=\\"https://www.alignmentforum.org/posts/ChDH335ckdvpxXaXX/model-organisms-of-misalignment-the-case-for-a-new-pillar-of-1\\">model organism</a> results; ideally also includes issues implementing safety plans/policies. (An AI company should also set itself up to notice incidents, e.g. via logging and monitoring; that goes elsewhere.)</p>","scores":{"Anthropic":0,"DeepMind":0,"OpenAI":10,"Meta":0,"xAI":0,"Microsoft":0,"DeepSeek":0}},{"name":"Talk about extreme risks","weight":15,"description":"This especially includes risks from misalignment. The company should talk about how AI safety might be very difficult, risks might be hard to notice, and powerful capabilities might appear suddenly.","description_html":"This especially includes risks from misalignment. The company should talk about how AI safety might be very difficult, risks might be hard to notice, and powerful capabilities might appear suddenly.","scores":{"Anthropic":60,"DeepMind":30,"OpenAI":25,"Meta":0,"xAI":20,"Microsoft":0,"DeepSeek":0}},{"name":"Describe worst-case outcome","weight":10,"description":"Use specific numbers; clarify terms like \\"catastrophe\\" and \\"extreme.\\" This statement should be on the company's website, not just spoken by a leader in an interview. (It should not be contradicted by other things said by the company and its leadership.)","description_html":"Use specific numbers; clarify terms like \\"catastrophe\\" and \\"extreme.\\" This statement should be on the company's website, not just spoken by a leader in an interview. (It should not be contradicted by other things said by the company and its leadership.)","scores":{"Anthropic":0,"DeepMind":0,"OpenAI":0,"Meta":0,"xAI":0,"Microsoft":0,"DeepSeek":0}},{"name":"Don't publish some capabilities research","weight":35,"description":"This includes how the company pretrains LMs and other relevant research like distributed training research. But sharing information about AI capabilities is good, and sharing research on post-training and especially scaffolding is fine unless it's on a particularly unsafe path.","description_html":"This includes how the company pretrains LMs and other relevant research like distributed training research. But sharing <i>information about AI capabilities</i> is good, and sharing research on post-training and especially scaffolding is fine unless it's on a particularly unsafe path.","scores":{"Anthropic":75,"DeepMind":25,"OpenAI":70,"Meta":0,"xAI":70,"Microsoft":0,"DeepSeek":0}}]},{"category":"Planning","weight":6,"subcategories":[{"name":"Safety plan","weight":50,"description":"The plan should focus on the rushed regime, not just the unrealistic unrushed regime. The plan should include responses to risks from scheming during internal deployment, misuse via API, and ideally human power grabs and theft of model weights or other IP.","description_html":"The plan should focus on the <a href=\\"https://www.lesswrong.com/posts/tmWMuY5HCSNXXZ9oq/buck-s-shortform?commentId=TNFatFiqHd8BpAXEp\\">rushed regime</a>, not just the unrealistic unrushed regime. The plan should include responses to risks from scheming during internal deployment, misuse via API, and ideally human power grabs and theft of model weights or other IP.","scores":{"Anthropic":25,"DeepMind":50,"OpenAI":0,"Meta":0,"xAI":0,"Microsoft":0,"DeepSeek":0}},{"name":"Plan for how to use AGI","weight":40,"description":"Especially to prevent anyone from building catastrophically dangerous AI before achieving safety. Also to create public goods, especially biosecurity and cybersecurity. E.g.: build human-obsoleting AIs which are sufficiently aligned/trustworthy that we can safely defer to them (before building wildly superintelligent AI). Assume it will take 5-10 years after AGI to build such systems and give them sufficient time. To buy time, inform the US government and convince it to enforce nobody builds wildly superintelligent AI for a while (and likely limit AGI weights to allied projects with excellent security and control). Use AGI to increase the government's willingness to pay for nonproliferation and to decrease the cost of nonproliferation (build carrots to decrease cost of others accepting nonproliferation and build sticks to decrease cost to US of enforcing nonproliferation).","description_html":"Especially to prevent anyone from building catastrophically dangerous AI before achieving safety. Also to create public goods, especially biosecurity and cybersecurity. E.g.: <i>build human-obsoleting AIs which are sufficiently aligned/trustworthy that we can safely defer to them (before building wildly superintelligent AI). Assume it will take 5-10 years after AGI to build such systems and give them sufficient time. To buy time, inform the US government and convince it to enforce </i>nobody builds wildly superintelligent AI<i> for a while (and likely limit AGI weights to allied projects with excellent security and control). Use AGI to increase the government's willingness to pay for nonproliferation and to decrease the cost of nonproliferation (build carrots to decrease cost of others accepting nonproliferation and build sticks to decrease cost to US of enforcing nonproliferation).</i>","scores":{"Anthropic":0,"DeepMind":0,"OpenAI":0,"Meta":0,"xAI":0,"Microsoft":0,"DeepSeek":0}},{"name":"Prepare for a pivot","weight":10,"description":"In particular, explain what the company and its researchers might focus on during such a period, say that the company stays financially prepared for a one-year pause, and ensure stakeholders and researchers ensure this is a possibility. \\"Pause\\" especially means pausing development of dangerous capabilities or internal deployment, not just public releases.","description_html":"In particular, explain what the company and its researchers might focus on during such a period, say that the company stays financially prepared for a one-year pause, and ensure stakeholders and researchers ensure this is a possibility. \\"Pause\\" especially means pausing development of dangerous capabilities or internal deployment, not just public releases.","scores":{"Anthropic":10,"DeepMind":5,"OpenAI":0,"Meta":1,"xAI":0,"Microsoft":5,"DeepSeek":0}}]}]`),zf=JSON.parse(`[{"category":"Risk assessment","weight":27,"subcategories":[{"name":"Evals: domains, quality, elicitation","weight":55,"reasoning":"OpenAI’s Preparedness Framework v2 names three frontier risk domains—bio/chem, cyber, and AI self-improvement—matching the required dangerous-capability domains. It describes thresholded capability measurement and scalable elicitation before deployment. UK AISI/NIST pre-deployment reports for OpenAI models indicate versions were tested without the full mitigation stack, improving elicitation. However, public artifacts give limited detail on chain-of-thought use, best-of-n/self-consistency sweeps, transcript review protocols, or systematic helpful-only variants across all tracked risks. Hence strong but not maximal evidence.","reasoning_html":"","scores":{"OpenAI":68}},{"name":"Evals: accountability","weight":25,"reasoning":"External evaluators (UK AISI and the U.S. NIST AI Safety Institute) published pre-deployment evaluations of OpenAI’s models; AISI noted test access to a version without the full mitigations and released public write-ups, and AISI+NIST jointly reported on o1 reasoning performance. OpenAI system cards summarize methodology and results for major releases. Transparency is substantial, but public human-expert baselines and random trajectory/item subsets are inconsistently provided, and formal publish-without-approval terms aren’t documented.","reasoning_html":"","scores":{"OpenAI":65}},{"name":"Adversarial evaluation for alignment","weight":10,"reasoning":"*no score found in source PDF for this criterion*","reasoning_html":"","scores":{"OpenAI":0}},{"name":"Model organisms","weight":10,"reasoning":"OpenAI co-authored 2025 work with Apollo Research documenting and probing deceptive behaviors in large models, effectively creating and studying ‘model organisms’ of scheming. This evidences production and initial study. Preparedness v2 elevates ‘Sandbagging’ to a research category, but public materials don’t yet show a concrete alignment-audit protocol (e.g., readiness checklists, audit sampling, publishable audit traces) deployed across releases. I credit substantial progress on organism creation and study, partial on additional organisms, and limited on audit preparation.","reasoning_html":"","scores":{"OpenAI":52}}],"category_score":{"OpenAI":59}},{"category":"Scheming risk prevention","weight":21,"subcategories":[{"name":"Safety case: process","weight":25,"reasoning":"Preparedness v2 sets governance (Safety Advisory Group), thresholded decisions, and illustrative controls against misaligned models. Yet there is no published, end-to-end safety case specific to subtle scheming with explicit pass/fail criteria, cost–benefit analysis centered on AI risk, and a documented pause trigger. Evidence shows process scaffolding, not a full scheming safety case.","reasoning_html":"","scores":{"OpenAI":35}},{"name":"Safety case: accountability","weight":25,"reasoning":"I did not find a qualified, disinterested external auditor publicly commenting on OpenAI’s scheming-focused safety case quality or adherence. External evaluations exist, but they are capability/risk-eval oriented rather than an audited safety case for scheming. Hence limited credit.","reasoning_html":"","scores":{"OpenAI":18}},{"name":"Internal deployment protocol","weight":20,"reasoning":"Preparedness v2 calls for safeguards before internal use once thresholds are crossed. OpenAI’s security posts describe controls around research environments (e.g., deny-by-default egress, multi-party approvals) and monitoring, but public details of an AI-output monitoring/escalation protocol for internal deployments (budgets, thresholds, review of suspicious outputs, demonstrated effectiveness) are sparse. This fits ‘working on a whole protocol’ rather than fully demonstrated implementation.","reasoning_html":"","scores":{"OpenAI":12}},{"name":"External deployment protocol","weight":10,"reasoning":"System cards describe layered mitigations, external red teaming, and Preparedness-aligned evaluations. OpenAI runs active threat-intelligence takedowns and publishes misuse disruption updates, and offers user reporting via product channels. Still, a published, comprehensive ‘flag-and-investigate’ pipeline with audit paths and quantitative monitoring goals is not fully documented.","reasoning_html":"","scores":{"OpenAI":55}},{"name":"Plan for if an AI is caught scheming","weight":10,"reasoning":"Preparedness v2 commits not to deploy models that cross ‘High’ thresholds without sufficient safeguards and discusses risk reduction, but there is no explicit public playbook that commits to publishing scheming findings, pausing/internal high-alert modes, and using the event to update monitoring across the ecosystem.","reasoning_html":"","scores":{"OpenAI":20}},{"name":"Training: remove scheming capabilities","weight":3,"reasoning":"OpenAI emphasizes ‘Teach: Filter data’ and alignment training in safety materials, but I found no concrete evidence of targeted removal/unlearning of scheming-enabling knowledge (e.g., steganography, subtle coordination tactics) such that even jailbroken models remain unhelpful on these topics, nor auditor-verifiable efficacy data.","reasoning_html":"","scores":{"OpenAI":20}},{"name":"Training: adversarial training","weight":3,"reasoning":"System cards and prior work describe adversarial testing and safety fine-tuning against harmful actions. I did not find strong public evidence of latent adversarial training or anti-adversarial training (e.g., reliably taking extremely good actions like whistleblowing in rare contexts). Partial credit for conventional adversarial alignment.","reasoning_html":"","scores":{"OpenAI":35}},{"name":"Training: safe architecture","weight":3,"reasoning":"OpenAI’s ‘reasoning’ models (e.g., o1/o3) separate internal reasoning from outputs and constrain behavior via the Model Spec; Preparedness v2 lists safeguards against misaligned models. However, there is no explicit commitment to serial, interpretable bottlenecks, avoidance of hidden state ‘neuralese,’ or guarantees about not training CoT to merely look friendly. Thus moderate credit.","reasoning_html":"","scores":{"OpenAI":30}}],"category_score":{"OpenAI":26}},{"category":"Boosting safety research","weight":14,"subcategories":[{"name":"Publishing safety research","weight":75,"reasoning":"I conservatively counted: 2023—GPT-4 technical report + system card (2); 2024—GPT-4o and Sora system cards, external red-teaming methods paper, Model Spec (4); 2025 through April—Preparedness v2 (1). Using the rubric’s time weighting and exponent (computed in code): publications/year = 3.25; score = ((3.25/20)^0.75)×100 ≈ 25.6 → 26.","reasoning_html":"","scores":{"OpenAI":26}},{"name":"Deep access for external safety researchers","weight":20,"reasoning":"Deep access: AISI/NIST received special access for pre-deployment testing of OpenAI models, including versions without the full mitigation stack (partial credit on ‘no-mitigations’). I found no evidence of broad external access to helpful-only/no-mitigations models plus fine-tuning/RL; API fine-tuning is available but RL access and no-mitigations variants for external safety researchers are not. Early access: OpenAI runs an early-access program for safety testing with researcher partners. Holistic judgment: ~25/80 for deep access, ~10/20 for early access → ~35 total.","reasoning_html":"","scores":{"OpenAI":35}},{"name":"Mentoring external safety researchers","weight":5,"reasoning":"OpenAI funded external alignment work via the Superalignment Fast Grants and Fellowship and co-authored deception work with Apollo Research, showing collaboration. I did not find sustained, structured mentorship programs for external extreme-risk safety researchers akin to multi-month labs-run mentorship cohorts with published curricula. Limited credit for collaboration and ad-hoc advising via grants.","reasoning_html":"","scores":{"OpenAI":22}}],"category_score":{"OpenAI":28}},{"category":"Misuse prevention","weight":12,"subcategories":[{"name":"Safety case: process","weight":40,"reasoning":"System cards (e.g., o1, Sora) and Preparedness v2 outline risk analyses and mitigations, and OpenAI publishes misuse disruption updates. However, a comprehensive, adversary-aware misuse safety case that argues releases are very unlikely to enable catastrophic misuse with quantified margins and explicit pause criteria is not publicly available.","reasoning_html":"","scores":{"OpenAI":40}},{"name":"Safety case: accountability","weight":40,"reasoning":"No public report shows a disinterested auditor reviewing OpenAI’s misuse safety case, commenting on adequacy and adherence, or publishing redacted failures. External evaluations exist, but not a formal audited misuse safety case.","reasoning_html":"","scores":{"OpenAI":18}},{"name":"Removing dangerous capabilities","weight":10,"reasoning":"OpenAI states it filters/finetunes to reduce dangerous outputs and reports post-mitigation performance in system cards; Preparedness v2 includes safeguards against malicious users. But there’s no public evidence that training removed capabilities such that jailbroken models still fail to enable catastrophic misuse across both CBRN and offensive cyber, nor auditor-verified efficacy. This matches ‘some details + some validation,’ below full credit.","reasoning_html":"","scores":{"OpenAI":20}},{"name":"Emergency protocol","weight":10,"reasoning":"OpenAI runs ongoing threat-intelligence disruption of deceptive/malicious use and publishes updates, indicating monitoring and response playbooks; system cards discuss mitigations and incident intake. Public detail on explicit activation thresholds, least-disruptive tool selection, and incident-reporting enablement is limited, so award moderate credit.","reasoning_html":"","scores":{"OpenAI":50}}],"category_score":{"OpenAI":30}},{"category":"Prep for extreme security","weight":12,"subcategories":[{"name":"Plan for SL5","weight":35,"reasoning":"Two 2024 security posts lay out a forward-looking roadmap: trusted computing for accelerators, strong network/tenant isolation, multi-party controls, and datacenter operational security, plus red-teaming and compliance plans. This is directionally consistent with SL5 optionality but not labeled against SL levels, not audited for ‘on-track’ status, and lacks schedule details to 2027. Moderate plan credit.","reasoning_html":"","scores":{"OpenAI":45}},{"name":"Red-team resilience","weight":25,"reasoning":"OpenAI states its research environment has been penetration-tested by a leading third-party consultancy and that internal red teams conduct deep assessments. Public statements don’t specify representative attack classes, affordances, or ‘competent pentesters tried X and failed’-style evidence. Partial credit.","reasoning_html":"","scores":{"OpenAI":40}},{"name":"Practices: isolated network","weight":5,"reasoning":"Documented practices include deny-by-default egress, private-link storage, RBAC, Kubernetes admission controls, multi-party approvals for weight access, CI/CD multi-party merges, and emphasis on isolating sensitive environments. Secure-boot/signed-code/weight-decrypt-on-accelerator are identified as goals (trusted computing) rather than implemented controls. Three pillars evidenced, one mostly aspirational.","reasoning_html":"","scores":{"OpenAI":65}},{"name":"Practices: secure developers' machines","weight":5,"reasoning":"Documented practices include deny-by-default egress, private-link storage, RBAC, Kubernetes admission controls, multi-party approvals for weight access, CI/CD multi-party merges, and emphasis on isolating sensitive environments. Secure-boot/signed-code/weight-decrypt-on-accelerator are identified as goals (trusted computing) rather than implemented controls. Three pillars evidenced, one mostly aspirational.","reasoning_html":"","scores":{"OpenAI":65}},{"name":"Practices: multiparty controls","weight":5,"reasoning":"Documented practices include deny-by-default egress, private-link storage, RBAC, Kubernetes admission controls, multi-party approvals for weight access, CI/CD multi-party merges, and emphasis on isolating sensitive environments. Secure-boot/signed-code/weight-decrypt-on-accelerator are identified as goals (trusted computing) rather than implemented controls. Three pillars evidenced, one mostly aspirational.","reasoning_html":"","scores":{"OpenAI":65}},{"name":"Practices: secure boot","weight":5,"reasoning":"Documented practices include deny-by-default egress, private-link storage, RBAC, Kubernetes admission controls, multi-party approvals for weight access, CI/CD multi-party merges, and emphasis on isolating sensitive environments. Secure-boot/signed-code/weight-decrypt-on-accelerator are identified as goals (trusted computing) rather than implemented controls. Three pillars evidenced, one mostly aspirational.","reasoning_html":"","scores":{"OpenAI":65}},{"name":"Track record","weight":20,"reasoning":"OpenAI maintains trust/compliance portals and publishes security and Preparedness updates; it reports red teaming and some incidents operationally (e.g., misuse disruption posts). I did not find a consolidated breach-disclosure log since 2023-07-01 listing incidents/near-misses with dates and severities; thus limited evidence of sustained, transparent breach-reporting with few serious incidents.","reasoning_html":"","scores":{"OpenAI":30}}],"category_score":{"OpenAI":45}},{"category":"Risk info sharing","weight":8,"subcategories":[{"name":"Incident reporting","weight":40,"reasoning":"OpenAI shares misuse disruption updates and collaborates with external institutes; it participates in government/industry safety initiatives. I found no explicit policy committing to notice and share scheming detections, large-scale misuse, near misses, and eval/model-organism warnings with CAISI/peers by default. Some sharing, but no formal cross-lab incident-reporting program publicly documented.","reasoning_html":"","scores":{"OpenAI":35}},{"name":"Talk about extreme risks","weight":15,"reasoning":"Preparedness v2 explicitly targets risks of ‘severe harm’ (thousands of deaths or hundreds of billions in damage), with thresholds and safeguards, and acknowledges increasing agentic systems and hard-to-notice risks. Leadership-level materials communicate that safety may be difficult and capabilities may appear suddenly.","reasoning_html":"","scores":{"OpenAI":72}},{"name":"Describe worst-case outcome","weight":10,"reasoning":"I did not find a company-site statement assigning explicit probabilities/credences to plausible worst-case outcomes. Without numeric credences and definitions posted on OpenAI’s site, this item earns no credit.","reasoning_html":"","scores":{"OpenAI":0}},{"name":"Don't publish some capabilities research","weight":35,"reasoning":"OpenAI’s GPT-4 technical report withholds architecture, hardware, training compute, and data specifics for safety/competition reasons; subsequent system cards and blogs continue to avoid releasing weights and sensitive training details. This aligns with withholding capabilities research on dangerous paths unless safety benefits dominate.","reasoning_html":"","scores":{"OpenAI":82}}],"category_score":{"OpenAI":54}},{"category":"Planning","weight":6,"subcategories":[{"name":"Safety plan","weight":50,"reasoning":"Preparedness v2 is explicitly oriented to pre-deployment thresholds, safeguards before internal use, and dynamic, scalable evals as release cadence increases. It lists misaligned-model safeguards and security controls and frames decisions under time pressure. Still, many specifics are illustrative rather than binding operational plans. Solid but not complete.","reasoning_html":"","scores":{"OpenAI":60}},{"name":"Plan for how to use AGI","weight":40,"reasoning":"OpenAI proposes ‘AI for cyber defense’ and broader security collaboration but does not publish a concrete plan to use AGI to prevent others from building catastrophically dangerous AI (e.g., a U.S.-led nonproliferation strategy, allied-weights constraints, 5–10 year alignment roadmap to human-obsoleting but trustworthy systems). Minimal credit.","reasoning_html":"","scores":{"OpenAI":20}},{"name":"Prepare for a pivot","weight":10,"reasoning":"Preparedness v2 says OpenAI won’t deploy models that cross ‘High’ thresholds without sufficient safeguards, and sets internal governance (SAG and Board oversight). It does not publicly commit to financial readiness for a one-year pause, team-by-team pivot plans, or stakeholder preparation for prolonged pauses. Partial credit.","reasoning_html":"","scores":{"OpenAI":35}}],"category_score":{"OpenAI":42}}]`),Bf={OpenAI:41},$f={categories:zf,overall:Bf},Uf=JSON.parse(`[{"category":"Risk assessment","weight":27,"subcategories":[{"name":"Evals: domains, quality, elicitation","weight":55,"reasoning":"DeepMind publishes dangerous-capability evaluations covering CBRN, offensive cyber, machine-learning R&D acceleration, persuasion/deception, self-proliferation, and deceptive alignment across Gemini model cards, technical papers, and the FSF (Frontier Safety Framework). Their arXiv paper details holistic safety/evals methodology and human baselines; model cards and the Gemini 2.5 report map results to FSF Critical Capability Levels. However, documentation does not clearly confirm full ‘helpful-only’ variants or ‘no inference-time mitigations’ during evals, nor consistent best-of-n / self-consistency and transcript-review protocols across all domains.","reasoning_html":"","scores":{"DeepMind":65}},{"name":"Evals: accountability","weight":25,"reasoning":"There is evidence of collaboration with external evaluators (e.g., UK AISI noted company collaboration on evaluations), and DeepMind publishes methodology/model cards. But we do not see public confirmation that external evaluators consistently had special access with ‘no mitigations’ and an explicit right to publish without approval across releases; some UK lawmakers have criticized timeliness/transparency around disclosures for Gemini 2.5.","reasoning_html":"","scores":{"DeepMind":40}},{"name":"Adversarial evaluation for alignment","weight":10,"reasoning":"","reasoning_html":"","scores":{"DeepMind":null}},{"name":"Model organisms","weight":10,"reasoning":"The FSF explicitly treats deceptive alignment as a critical risk and describes an approach to manage it, but we do not find public artifacts showing DeepMind (1) produced concrete ‘model organisms’ of scheming, (2) produced additional organisms, (3) systematically studied such organisms to estimate P(scheming), or (4) prepared and published alignment-audit packs using them. In the absence of those specific outputs, credit is not warranted per rubric.","reasoning_html":"","scores":{"DeepMind":0}}],"category_score":{"DeepMind":51}},{"category":"Scheming risk prevention","weight":21,"subcategories":[{"name":"Safety case: process","weight":25,"reasoning":"FSF 2.0/3.0 describes a safety-case process tied to Critical Capability Levels, control evaluations, and deployment mitigations, with an explicit deceptive-alignment strand. This is a structured, pre-declared process oriented toward internal deployment decisions, though many artifacts are summarized rather than fully published.","reasoning_html":"","scores":{"DeepMind":60}},{"name":"Safety case: accountability","weight":25,"reasoning":"We do not see a qualified, disinterested external auditor publicly commenting on safety-case quality and adherence for scheming-risk cases; public criticism has also focused on gaps in disclosure. Partial credit for general commitments, but not for full external accountability.","reasoning_html":"","scores":{"DeepMind":20}},{"name":"Internal deployment protocol","weight":20,"reasoning":"Public materials describe automated red-teaming (ART), model hardening, and procedures for applying deployment mitigations; FSF updates emphasize process consistency. However, public detail on trusted AI monitors that can edit/resample outputs, escalation thresholds, and audits of suspicious events is limited.","reasoning_html":"","scores":{"DeepMind":35}},{"name":"External deployment protocol","weight":10,"reasoning":"Google publications discuss defense-in-depth and agentic security guidance, and DeepMind provides safety systems like ShieldGemma for moderation. Still, we don’t see a detailed public ‘flag-and-investigate’ pipeline for external settings tied to misalignment detection and privacy-respecting audit paths.","reasoning_html":"","scores":{"DeepMind":25}},{"name":"Plan for if an AI is caught scheming","weight":10,"reasoning":"FSF materials acknowledge deceptive alignment and outline mitigations, but we do not find a public, specific protocol committing to publishing findings, pausing/switching to high alert, and using the event to improve monitoring in the wider ecosystem.","reasoning_html":"","scores":{"DeepMind":20}},{"name":"Training: remove scheming capabilities","weight":3,"reasoning":"We found no public evidence that DeepMind filters or unlearns scheming-enabling knowledge by default (e.g., about steganography/subtle coordination) absent a demonstrated control case; publications focus more on hardening and red-teaming than on targeted unlearning for scheming.","reasoning_html":"","scores":{"DeepMind":10}},{"name":"Training: adversarial training","weight":3,"reasoning":"Security posts and the Gemini 2.5 report indicate adversarial training/model hardening against adaptive attacks; this aligns with ‘don’t take extremely bad actions’ style training. We don’t see clear public evidence of latent adversarial or ‘anti-adversarial’ training aimed at rare opportunities to take extremely good actions (e.g., whistleblowing).","reasoning_html":"","scores":{"DeepMind":40}},{"name":"Training: safe architecture","weight":3,"reasoning":"No public commitment to ‘serial thinking through interpretable bottlenecks’ or to avoiding hidden/uninterpretable states in core architectures; Gemini/Gemma follow mainstream LLM designs.","reasoning_html":"","scores":{"DeepMind":10}}],"category_score":{"DeepMind":34}},{"category":"Boosting safety research","weight":14,"subcategories":[{"name":"Publishing safety research","weight":75,"reasoning":"DeepMind publishes safety and evals work (e.g., dangerous-capability evals, defense-in-depth), but we do not have a curated, auditable count split by 2023/2024/Jan–Apr 2025 restricted to extreme-risk topics as defined here; per evidence rules, credit isn’t granted without a verifiable tally. If a counted list is provided, we’ll recompute the formula.","reasoning_html":"","scores":{"DeepMind":0}},{"name":"Deep access for external safety researchers","weight":20,"reasoning":"Vertex AI offers external fine-tuning for Gemini 2.5 family (meets part of ‘fine-tuning’ access), but there’s no evidence of ‘no-mitigations’ / ‘helpful-only’ variants for external safety researchers or of RL access. ‘Early access’ appears limited to select testers, not clearly safety-focused. We award partial credit (fine-tuning half-credit on the 40% component; minimal for early access).","reasoning_html":"","scores":{"DeepMind":25}},{"name":"Mentoring external safety researchers","weight":5,"reasoning":"DeepMind collaborates with external institutions and publishes guidance/white papers; however, public evidence specifically demonstrating structured, recurring mentorship programs for extreme-risk safety researchers (e.g., fellowships/advisory time with outputs) is limited.","reasoning_html":"","scores":{"DeepMind":20}}],"category_score":{"DeepMind":6}},{"category":"Misuse prevention","weight":12,"subcategories":[{"name":"Safety case: process","weight":40,"reasoning":"FSF materials and Gemini reports describe misuse-focused evaluation and mitigations, and Google’s broader security strategy (SAIF) supports deployment governance. Still, a formal ‘misuse safety case’ with most details published is not consistently available per release.","reasoning_html":"","scores":{"DeepMind":55}},{"name":"Safety case: accountability","weight":40,"reasoning":"We didn’t find a pattern of qualified, disinterested auditors publicly commenting on adequacy/adherence of misuse safety cases prior to major releases; external criticism has flagged disclosure gaps.","reasoning_html":"","scores":{"DeepMind":15}},{"name":"Removing dangerous capabilities","weight":10,"reasoning":"We see active work on defenses (e.g., ShieldGemma, model hardening) and some misuse studies, but no public, validated demonstrations of capability removal/unlearning covering both CBRN and offensive cyber with auditor-commented accountability.","reasoning_html":"","scores":{"DeepMind":10}},{"name":"Emergency protocol","weight":10,"reasoning":"Commitments at the AI Seoul Summit and FSF imply readiness to pause/reduce risk, but we don’t see a detailed public emergency playbook with concrete activation thresholds, tools, and after-action reporting. Partial credit for general commitments and governance posture.","reasoning_html":"","scores":{"DeepMind":30}}],"category_score":{"DeepMind":32}},{"category":"Prep for extreme security","weight":12,"subcategories":[{"name":"Plan for SL5","weight":35,"reasoning":"DeepMind’s FSF updates add Security Level recommendations for CCLs, and Google advances SAIF/SAIF 2.0, but we don’t see a public, externally audited roadmap to SL5 optionality by December 2027 (incl. training and internal deployment).","reasoning_html":"","scores":{"DeepMind":30}},{"name":"Red-team resilience","weight":25,"reasoning":"DeepMind reports extensive automated red-teaming (ART) and adaptive-attack testing that improved protections against indirect prompt injection. However, we do not see public statements that competent external pentesters attempted realistic attacks and failed, with enough detail to assess relevance.","reasoning_html":"","scores":{"DeepMind":25}},{"name":"Practices: isolated network","weight":5,"reasoning":"Google publishes organization-wide AI security frameworks (SAIF/SAIF 2.0) and supply-chain guidance, implying strong baseline practices. But DeepMind has not publicly documented weight-storage hardening (e.g., HSM-backed isolation with enforced bandwidth limits), mandatory two-person approvals on accelerator code/cluster config, and accelerator-level secure boot attestation for frontier models with sufficient granularity for full credit.","reasoning_html":"","scores":{"DeepMind":40}},{"name":"Practices: secure developers' machines","weight":5,"reasoning":"Google publishes organization-wide AI security frameworks (SAIF/SAIF 2.0) and supply-chain guidance, implying strong baseline practices. But DeepMind has not publicly documented weight-storage hardening (e.g., HSM-backed isolation with enforced bandwidth limits), mandatory two-person approvals on accelerator code/cluster config, and accelerator-level secure boot attestation for frontier models with sufficient granularity for full credit.","reasoning_html":"","scores":{"DeepMind":40}},{"name":"Practices: multiparty controls","weight":5,"reasoning":"Google publishes organization-wide AI security frameworks (SAIF/SAIF 2.0) and supply-chain guidance, implying strong baseline practices. But DeepMind has not publicly documented weight-storage hardening (e.g., HSM-backed isolation with enforced bandwidth limits), mandatory two-person approvals on accelerator code/cluster config, and accelerator-level secure boot attestation for frontier models with sufficient granularity for full credit.","reasoning_html":"","scores":{"DeepMind":40}},{"name":"Practices: secure boot","weight":5,"reasoning":"Google publishes organization-wide AI security frameworks (SAIF/SAIF 2.0) and supply-chain guidance, implying strong baseline practices. But DeepMind has not publicly documented weight-storage hardening (e.g., HSM-backed isolation with enforced bandwidth limits), mandatory two-person approvals on accelerator code/cluster config, and accelerator-level secure boot attestation for frontier models with sufficient granularity for full credit.","reasoning_html":"","scores":{"DeepMind":40}},{"name":"Track record","weight":20,"reasoning":"We do not see a dedicated breach-disclosure page enumerating incidents/near-misses for AI model security since mid-2023. There are few publicly known serious AI-security breaches attributable to DeepMind, but absence of evidence isn’t evidence of strong disclosure; partial credit.","reasoning_html":"","scores":{"DeepMind":40}}],"category_score":{"DeepMind":33}},{"category":"Risk info sharing","weight":8,"subcategories":[{"name":"Incident reporting","weight":40,"reasoning":"Public posts discuss mapping and analyzing misuse incidents broadly, and DeepMind collaborates with government bodies; still, we don’t see a specific policy to notice/share scheming detections, large-scale misuse, eval warning signs, and near-misses to CAISI/peers as a standing commitment.","reasoning_html":"","scores":{"DeepMind":20}},{"name":"Talk about extreme risks","weight":15,"reasoning":"DeepMind’s AGI safety/security post and related communications explicitly discuss severe harms, including catastrophic outcomes, and emphasize difficulty of safety. This meets the spirit of acknowledging extreme risks.","reasoning_html":"","scores":{"DeepMind":60}},{"name":"Describe worst-case outcome","weight":10,"reasoning":"We did not find a company-site statement assigning explicit probabilities (credences) to worst-case outcomes with clear definitions; leadership and blogs discuss risks qualitatively. Per rubric, no credit.","reasoning_html":"","scores":{"DeepMind":0}},{"name":"Don't publish some capabilities research","weight":35,"reasoning":"DeepMind withholds model weights for frontier systems and limits release of some training details, while publishing safety tools like ShieldGemma; this indicates caution around dangerous-path capabilities. Partial credit.","reasoning_html":"","scores":{"DeepMind":60}}],"category_score":{"DeepMind":38}},{"category":"Planning","weight":6,"subcategories":[{"name":"Safety plan","weight":50,"reasoning":"FSF is expressly designed for rapidly changing capabilities, with pre-defined triggers, control evals, and deployment mitigations; the AGI safety post frames readiness for near-term risks. This constitutes a plan for rushed conditions, though many specifics remain internal.","reasoning_html":"","scores":{"DeepMind":60}},{"name":"Plan for how to use AGI","weight":40,"reasoning":"Google/DeepMind publish guidance on agentic security and propose using AI to enhance cyber defense (e.g., CodeMender, SAIF 2.0), but a concrete nonproliferation-style plan (e.g., coordinating with the U.S. government to prevent dangerous AI development and producing specific public goods timelines) isn’t public.","reasoning_html":"","scores":{"DeepMind":35}},{"name":"Prepare for a pivot","weight":10,"reasoning":"DeepMind signed the 2024 Frontier AI Safety Commitments (which include refraining from deployment if risks can’t be mitigated) and FSF mentions deployment mitigations; METR notes ‘conditions for halting’ appear in many policies, including Google DeepMind’s. Specific financial/personnel pivot plans for a one-year pause are not public.","reasoning_html":"","scores":{"DeepMind":40}}],"category_score":{"DeepMind":48}}]`),Wf={DeepMind:35},Hf={categories:Uf,overall:Wf},Vf=[{category:"Risk assessment",weight:27,subcategories:[{name:"Evals: domains, quality, elicitation",weight:55,description:"*model reasoning*",description_html:"",scores:{Anthropic:75}},{name:"Evals: accountability",weight:25,description:"*model reasoning*",description_html:"",scores:{Anthropic:65}},{name:"Adversarial evaluation for alignment",weight:10,description:"*model reasoning*",description_html:"",scores:{}},{name:"Model organisms",weight:10,description:"*model reasoning*",description_html:"",scores:{Anthropic:100}}],category_score:{Anthropic:0}},{category:"Scheming risk prevention",weight:21,subcategories:[{name:"Safety case: process",weight:25,description:"*model reasoning*",description_html:"",scores:{Anthropic:70}},{name:"Safety case: accountability",weight:25,description:"*model reasoning*",description_html:"",scores:{Anthropic:55}},{name:"Internal deployment protocol",weight:20,description:"*model reasoning*",description_html:"",scores:{Anthropic:40}},{name:"External deployment protocol",weight:10,description:"*model reasoning*",description_html:"",scores:{Anthropic:70}},{name:"Plan for if an AI is caught scheming",weight:10,description:"*model reasoning*",description_html:"",scores:{Anthropic:60}},{name:"Training: remove scheming capabilities",weight:3,description:"*model reasoning*",description_html:"",scores:{Anthropic:30}},{name:"Training: adversarial training",weight:3,description:"*model reasoning*",description_html:"",scores:{Anthropic:45}},{name:"Training: safe architecture",weight:3,description:"*model reasoning*",description_html:"",scores:{Anthropic:35}}],category_score:{Anthropic:0}},{category:"Boosting safety research",weight:14,subcategories:[{name:"Publishing safety research",weight:75,description:"*model reasoning*",description_html:"",scores:{Anthropic:37}},{name:"Deep access for external safety researchers",weight:20,description:"*model reasoning*",description_html:"",scores:{Anthropic:55}},{name:"Mentoring external safety researchers",weight:5,description:"*model reasoning*",description_html:"",scores:{Anthropic:40}}],category_score:{Anthropic:0}},{category:"Misuse prevention",weight:12,subcategories:[{name:"Safety case: process",weight:40,description:"*model reasoning*",description_html:"",scores:{Anthropic:65}},{name:"Safety case: accountability",weight:40,description:"*model reasoning*",description_html:"",scores:{Anthropic:50}},{name:"Removing dangerous capabilities",weight:10,description:"*model reasoning*",description_html:"",scores:{Anthropic:25}},{name:"Emergency protocol",weight:10,description:"*model reasoning*",description_html:"",scores:{Anthropic:70}}],category_score:{Anthropic:0}},{category:"Prep for extreme security",weight:12,subcategories:[{name:"Plan for SL5",weight:35,description:"*model reasoning*",description_html:"",scores:{Anthropic:30}},{name:"Red-team resilience",weight:25,description:"*model reasoning*",description_html:"",scores:{Anthropic:50}},{name:"Practices: isolated network",weight:5,description:"*model reasoning*",description_html:"",scores:{Anthropic:60}},{name:"Practices: secure developers' machines",weight:5,description:"*model reasoning*",description_html:"",scores:{Anthropic:60}},{name:"Practices: multiparty controls",weight:5,description:"*model reasoning*",description_html:"",scores:{Anthropic:60}},{name:"Practices: secure boot",weight:5,description:"*model reasoning*",description_html:"",scores:{Anthropic:60}},{name:"Track record",weight:20,description:"*model reasoning*",description_html:"",scores:{Anthropic:50}}],category_score:{Anthropic:0}},{category:"Risk info sharing",weight:8,subcategories:[{name:"Incident reporting",weight:40,description:"*model reasoning*",description_html:"",scores:{Anthropic:60}},{name:"Talk about extreme risks",weight:15,description:"*model reasoning*",description_html:"",scores:{Anthropic:85}},{name:"Describe worst-case outcome",weight:10,description:"*model reasoning*",description_html:"",scores:{Anthropic:40}},{name:"Don't publish some capabilities research",weight:35,description:"*model reasoning*",description_html:"",scores:{Anthropic:60}}],category_score:{Anthropic:0}},{category:"Planning",weight:6,subcategories:[{name:"Safety plan",weight:50,description:"*model reasoning*",description_html:"",scores:{Anthropic:70}},{name:"Plan for how to use AGI",weight:40,description:"*model reasoning*",description_html:"",scores:{Anthropic:40}},{name:"Prepare for a pivot",weight:10,description:"*model reasoning*",description_html:"",scores:{Anthropic:65}}],category_score:{Anthropic:0}}],Gf={Anthropic:0},qf={categories:Vf,overall:Gf},Qf=[{category:"Risk assessment",weight:27,subcategories:[{name:"Evals: domains, quality, elicitation",weight:55,description:"*model reasoning*",description_html:"",scores:{Meta:30}},{name:"Evals: accountability",weight:25,description:"*model reasoning*",description_html:"",scores:{Meta:15}},{name:"Adversarial evaluation for alignment",weight:10,description:"*model reasoning*",description_html:"",scores:{Meta:0}},{name:"Model organisms",weight:10,description:"*model reasoning*",description_html:"",scores:{Meta:0}}],category_score:{Meta:22}},{category:"Scheming risk prevention",weight:21,subcategories:[{name:"Safety case: process",weight:25,description:"*model reasoning*",description_html:"",scores:{Meta:10}},{name:"Safety case: accountability",weight:25,description:"*model reasoning*",description_html:"",scores:{Meta:0}},{name:"Internal deployment protocol",weight:20,description:"*model reasoning*",description_html:"",scores:{Meta:5}},{name:"External deployment protocol",weight:10,description:"*model reasoning*",description_html:"",scores:{Meta:30}},{name:"Plan for if an AI is caught scheming",weight:10,description:"*model reasoning*",description_html:"",scores:{Meta:0}},{name:"Training: remove scheming capabilities",weight:3,description:"*model reasoning*",description_html:"",scores:{Meta:0}},{name:"Training: adversarial training",weight:3,description:"*model reasoning*",description_html:"",scores:{Meta:15}},{name:"Training: safe architecture",weight:3,description:"*model reasoning*",description_html:"",scores:{Meta:0}}],category_score:{Meta:7}},{category:"Boosting safety research",weight:14,subcategories:[{name:"Publishing safety research",weight:75,description:"*model reasoning*",description_html:"",scores:{Meta:18}},{name:"Deep access for external safety researchers",weight:20,description:"*model reasoning*",description_html:"",scores:{Meta:40}},{name:"Mentoring external safety researchers",weight:5,description:"*model reasoning*",description_html:"",scores:{Meta:0}}],category_score:{Meta:22}},{category:"Misuse prevention",weight:12,subcategories:[{name:"Safety case: process",weight:40,description:"*model reasoning*",description_html:"",scores:{Meta:10}},{name:"Safety case: accountability",weight:40,description:"*model reasoning*",description_html:"",scores:{Meta:0}},{name:"Removing dangerous capabilities",weight:10,description:"*model reasoning*",description_html:"",scores:{Meta:0}},{name:"Emergency protocol",weight:10,description:"*model reasoning*",description_html:"",scores:{Meta:5}}],category_score:{Meta:4}},{category:"Prep for extreme security",weight:12,subcategories:[{name:"Plan for SL5",weight:35,description:"*model reasoning*",description_html:"",scores:{Meta:0}},{name:"Red-team resilience",weight:25,description:"*model reasoning*",description_html:"",scores:{Meta:0}},{name:"Practices: isolated network",weight:5,description:"*model reasoning*",description_html:"",scores:{Meta:5}},{name:"Practices: secure developers' machines",weight:5,description:"*model reasoning*",description_html:"",scores:{Meta:5}},{name:"Practices: multiparty controls",weight:5,description:"*model reasoning*",description_html:"",scores:{Meta:5}},{name:"Practices: secure boot",weight:5,description:"*model reasoning*",description_html:"",scores:{Meta:5}},{name:"Track record",weight:20,description:"*model reasoning*",description_html:"",scores:{Meta:20}}],category_score:{Meta:5}},{category:"Risk info sharing",weight:8,subcategories:[{name:"Incident reporting",weight:40,description:"*model reasoning*",description_html:"",scores:{Meta:0}},{name:"Talk about extreme risks",weight:15,description:"*model reasoning*",description_html:"",scores:{Meta:10}},{name:"Describe worst-case outcome",weight:10,description:"*model reasoning*",description_html:"",scores:{Meta:0}},{name:"Don't publish some capabilities research",weight:35,description:"*model reasoning*",description_html:"",scores:{Meta:0}}],category_score:{Meta:2}},{category:"Planning",weight:6,subcategories:[{name:"Safety plan",weight:50,description:"*model reasoning*",description_html:"",scores:{Meta:25}},{name:"Plan for how to use AGI",weight:40,description:"*model reasoning*",description_html:"",scores:{Meta:0}},{name:"Prepare for a pivot",weight:10,description:"*model reasoning*",description_html:"",scores:{Meta:0}}],category_score:{Meta:25}}],Kf=JSON.parse(`[{"category":"Risk assessment","weight":27,"subcategories":[{"name":"Evals: domains, quality, elicitation","weight":55,"reasoning":"xAI’s RMF and Grok model cards explicitly evaluate dual-use domains (CBRN biology, chemistry) and offensive cyber and discuss ‘concerning propensities’ (deception, manipulation). They also use specific benchmarks (e.g., VCT, WMDP-Bio/Cyber, BioLP-bench, Cybench) and jailbreak stress-tests. However, I don’t find evidence of high-quality elicitation practices required here (e.g., helpful-only/base variants, no inference-time mitigations during evals, best-of-n/self-consistency, systematic transcript review). Much of their reported evaluation uses mitigation-laden system prompts rather than unmitigated helpful-only variants, so credit is partial, not full.","reasoning_html":"","scores":{"xAI":35}},{"name":"Evals: accountability","weight":25,"reasoning":"The RMF references work with outside entities (government bodies, private testing firms) and notes ‘independent third-party assessments’ on cyber, but I find no public evidence of (a) external evaluators with special access (incl. no-mitigations) and the right to publish without approval, nor (b) a qualified disinterested internal auditor publicly commenting on rigor/findings with methods/results and random item release. Minimal credit for indicating some third-party involvement; not for open accountability.","reasoning_html":"","scores":{"xAI":5}},{"name":"Adversarial evaluation for alignment","weight":10,"reasoning":"","reasoning_html":"","scores":{"xAI":0}},{"name":"Model organisms","weight":10,"reasoning":"Model organisms: produce at least one organism of scheming/misalignment: No public xAI work found producing concrete ‘model organisms’ of scheming (e.g., controlled demonstrations of alignment-faking behaviors). Under the scoring rules, no credit without artifacts.\\n\\n— Model organisms: additional organisms: Same as above—no additional organisms beyond a first example identified.\\n\\n— Model organisms: study organisms (variations, tested interventions) to estimate P(scheming): No evidence of systematic intervention studies on misalignment organisms to estimate P(scheming) or test mitigations.\\n\\n— Model organisms: prepare alignment audits: No public plan or artifacts for alignment audits built on model organisms.","reasoning_html":"","scores":{"xAI":0}}],"category_score":{"xAI":21}},{"category":"Scheming risk prevention","weight":21,"subcategories":[{"name":"Safety case: process","weight":25,"reasoning":"RMF acknowledges ‘loss of control’ risks and measures ‘concerning propensities’ (e.g., deception), but I don’t find a comprehensive, publishable safety case for internal deployment that includes a dedicated control-eval, pause/trigger criteria, and cost-benefit analysis focused on AI risk. Partial, for having a framework and some measurements.","reasoning_html":"","scores":{"xAI":10}},{"name":"Safety case: accountability","weight":25,"reasoning":"No qualified, disinterested auditor publicly commenting on plans, adherence, and safety-case quality; no public safety case documents with auditor notes.","reasoning_html":"","scores":{"xAI":0}},{"name":"Internal deployment protocol","weight":20,"reasoning":"I don’t find a published, operational internal protocol with AI monitoring, trusted monitors/probes, edit/resample, escalation thresholds, or substantive suspicious-event auditing. At best, signals of evolving monitoring; that maps to the ‘will do later/working on’ bucket.","reasoning_html":"","scores":{"xAI":5}},{"name":"External deployment protocol","weight":10,"reasoning":"xAI uses policies, refusal prompts, filters, and monitoring in deployed products (e.g., Grok on X) and references rapid response to observed risks. However, I don’t find a detailed public ‘flag-and-investigate’ pipeline with privacy-respecting audit paths and incident handling specific to misalignment, beyond general AUP and safeguards. Partial credit.","reasoning_html":"","scores":{"xAI":15}},{"name":"Plan for if an AI is caught scheming","weight":10,"reasoning":"No public, specific plan committing to publish findings, pause/switch to high-alert, and feed lessons back into monitoring/ecosystem.","reasoning_html":"","scores":{"xAI":0}},{"name":"Training: remove scheming capabilities","weight":3,"reasoning":"I don’t find evidence of filtering/unlearning to reduce knowledge/skills that enable scheming (e.g., steganography/coordination) unless a strong control case is demonstrated. No explicit ‘ignorant-by-default’ approach on these topics.","reasoning_html":"","scores":{"xAI":0}},{"name":"Training: adversarial training","weight":3,"reasoning":"General ‘safety training’ and refusal policies are described, but I don’t see specific latent adversarial training or anti-adversarial training commitments aimed at extreme-risk high-stakes contexts. Small partial credit for general adversarial robustness work (e.g., jailbreak testing).","reasoning_html":"","scores":{"xAI":10}},{"name":"Training: safe architecture","weight":3,"reasoning":"Models emphasize ‘reasoning’ and system-prompt mitigations, but there’s no public commitment to interpretable serial bottlenecks, natural-language-only reasoning constraints, or avoiding hidden ‘neuralese’ states as an architectural safety principle. Minimal credit.","reasoning_html":"","scores":{"xAI":5}}],"category_score":{"xAI":5}},{"category":"Boosting safety research","weight":14,"subcategories":[{"name":"Publishing safety research","weight":75,"reasoning":"I find no xAI publications (2023–Apr 2025) that clearly qualify as extreme-risk-relevant safety research under this rubric. Using the rubric’s formula with 0 publications yields 0%.","reasoning_html":"","scores":{"xAI":0}},{"name":"Deep access for external safety researchers","weight":20,"reasoning":"Boosting safety research: Deep access — helpful-only & no-mitigations access: No evidence that xAI provides safety researchers with helpful-only/no-mitigations variants for deep evaluation. The RMF contemplates selective access for trusted auditors, but without concrete details matching this requirement.\\n\\n— Boosting safety research: Deep access — fine-tuning & RL access: No public program granting external safety researchers fine-tuning/RL access for deep safety work.\\n\\n— Boosting safety research: Early access (for safety research): I don’t find a program of early access specifically for external safety researchers (distinct from product betas).","reasoning_html":"","scores":{"xAI":0}},{"name":"Mentoring external safety researchers","weight":5,"reasoning":"No public evidence of structured mentorship/advisory programs or safety-focused co-authorships aimed at extreme-risk topics.","reasoning_html":"","scores":{"xAI":0}}],"category_score":{"xAI":0}},{"category":"Misuse prevention","weight":12,"subcategories":[{"name":"Safety case: process","weight":40,"reasoning":"RMF lays out dual-use risk thresholds and benchmark-linked acceptance criteria (e.g., answer-rate < 1 in 20 on restricted biology/chemistry queries) and describes layered safeguards and adversarial testing. That’s a start, but I don’t see a full misuse safety case showing ‘very unlikely’ catastrophic misuse with adversarial users and cost-benefit analysis. Partial credit.","reasoning_html":"","scores":{"xAI":20}},{"name":"Safety case: accountability","weight":40,"reasoning":"No qualified, disinterested auditor visibly observing and publicly commenting on adequacy/adherence; no public safety-case documents with auditor notes.","reasoning_html":"","scores":{"xAI":0}},{"name":"Removing dangerous capabilities","weight":10,"reasoning":"Emphasis on refusal policies, filters, and system prompts, but not validated unlearning/filtering of dangerous capabilities such that even jailbroken models don’t enable misuse. At most, statements about working on robustness imply ‘working on this’ → minimal rubric credit.","reasoning_html":"","scores":{"xAI":10}},{"name":"Emergency protocol","weight":10,"reasoning":"RMF implies heightened safeguards and rapid response to observed risks, but I don’t see a concrete public emergency protocol with tools, thresholds for activation, and incident reporting enablement. Minimal credit.","reasoning_html":"","scores":{"xAI":5}}],"category_score":{"xAI":10}},{"category":"Prep for extreme security","weight":12,"subcategories":[{"name":"Plan for SL5","weight":35,"reasoning":"No public, time-bound plan toward SL5-level optionality (weights security for training/internal use, serial wall-clock items, external audit of plan adequacy/on-track status).","reasoning_html":"","scores":{"xAI":0}},{"name":"Red-team resilience","weight":25,"reasoning":"No public statements of competent pentesters attempting specified attacks under realistic affordances and failing, with enough detail to evaluate relevance.","reasoning_html":"","scores":{"xAI":0}},{"name":"Practices: isolated network","weight":5,"reasoning":"No public evidence of HSM-backed weight storage, tight egress controls with hardware/guards, or policies preventing developer weight exfiltration during training/internal deployment.","reasoning_html":"","scores":{"xAI":0}},{"name":"Practices: secure developers' machines","weight":5,"reasoning":"No public documentation of secure workstation isolation or hardware-key requirements for developer auth specific to model security.","reasoning_html":"","scores":{"xAI":0}},{"name":"Practices: multiparty controls","weight":5,"reasoning":"No public commitment to two-person approvals on cluster config/accelerator code or action-level approvals with a secure-workstation signer.","reasoning_html":"","scores":{"xAI":0}},{"name":"Practices: secure boot","weight":5,"reasoning":"No public evidence of secure-boot deployment requirements or cryptographic constraints that keep weights decryptable only on accelerators.","reasoning_html":"","scores":{"xAI":0}},{"name":"Track record","weight":20,"reasoning":"Public reporting indicates a leaked xAI API key and related disclosure-process issues in 2025; I don’t find a robust public breach-disclosure page listing incidents/near-misses with timelines. That combination merits low credit.","reasoning_html":"","scores":{"xAI":5}}],"category_score":{"xAI":1}},{"category":"Risk info sharing","weight":8,"subcategories":[{"name":"Incident reporting","weight":40,"reasoning":"I don’t find a public policy committing to notice-and-share of incidents/warning signs to CAISI and, when appropriate, other firms, nor public incident digests.","reasoning_html":"","scores":{"xAI":0}},{"name":"Talk about extreme risks","weight":15,"reasoning":"RMF acknowledges loss-of-control scenarios and difficult-to-measure risks (deception, sycophancy); leadership posts and news also describe engagement with EU safety/security code of practice. Some positive credit for communicating extreme-risk realities, though not deeply quantified.","reasoning_html":"","scores":{"xAI":25}},{"name":"Describe worst-case outcome","weight":10,"reasoning":"No company post on x.ai that states a plausible worst case with explicit credences and clear definitions posted on the company website.","reasoning_html":"","scores":{"xAI":0}},{"name":"Don't publish some capabilities research","weight":35,"reasoning":"No clear public policy describing restraint on publishing dangerous-path capabilities (esp. LM pretraining/distributed-training methods) proportional to safety benefits. Absent such a policy, no credit.","reasoning_html":"","scores":{"xAI":0}}],"category_score":{"xAI":4}},{"category":"Planning","weight":6,"subcategories":[{"name":"Safety plan","weight":50,"reasoning":"RMF sets some thresholds (e.g., restricted-query answer-rate target) and acknowledges rushed, real-world risks, but I don’t find a concrete, time-pressured plan covering internal scheming, API misuse, human power grabs, and weight/IP theft with clear triggers/resources. Partial credit.","reasoning_html":"","scores":{"xAI":15}},{"name":"Plan for how to use AGI","weight":40,"reasoning":"No public plan for using advanced AI to block dangerous proliferation (e.g., coordinated nonproliferation with governments, public-goods deployment timelines).","reasoning_html":"","scores":{"xAI":0}},{"name":"Prepare for a pivot","weight":10,"reasoning":"No public plan to pause dangerous capability development or internal deployment with pre-baked team assignments, one-year financial readiness, and stakeholder prep.","reasoning_html":"","scores":{"xAI":0}}],"category_score":{"xAI":8}}]`),Xf={xAI:9},Yf={categories:Kf,overall:Xf},Jf=[{category:"Risk assessment",weight:27,subcategories:[{name:"Evals: domains, quality, elicitation",weight:55,description:"*model reasoning*",description_html:"",scores:{Microsoft:35}},{name:"Evals: accountability",weight:25,description:"*model reasoning*",description_html:"",scores:{Microsoft:25}},{name:"Adversarial evaluation for alignment",weight:10,description:"*model reasoning*",description_html:"",scores:{Microsoft:0}},{name:"Model organisms",weight:10,description:"*model reasoning*",description_html:"",scores:{Microsoft:0}}],category_score:{Microsoft:26}},{category:"Scheming risk prevention",weight:21,subcategories:[{name:"Safety case: process",weight:25,description:"*model reasoning*",description_html:"",scores:{Microsoft:20}},{name:"Safety case: accountability",weight:25,description:"*model reasoning*",description_html:"",scores:{Microsoft:10}},{name:"Internal deployment protocol",weight:20,description:"*model reasoning*",description_html:"",scores:{Microsoft:25}},{name:"External deployment protocol",weight:10,description:"*model reasoning*",description_html:"",scores:{Microsoft:50}},{name:"Plan for if an AI is caught scheming",weight:10,description:"*model reasoning*",description_html:"",scores:{Microsoft:10}},{name:"Training: remove scheming capabilities",weight:3,description:"*model reasoning*",description_html:"",scores:{Microsoft:15}},{name:"Training: adversarial training",weight:3,description:"*model reasoning*",description_html:"",scores:{Microsoft:20}},{name:"Training: safe architecture",weight:3,description:"*model reasoning*",description_html:"",scores:{Microsoft:10}}],category_score:{Microsoft:20}},{category:"Boosting safety research",weight:14,subcategories:[{name:"Publishing safety research",weight:75,description:"*model reasoning*",description_html:"",scores:{Microsoft:56}},{name:"Deep access for external safety researchers",weight:20,description:"*model reasoning*",description_html:"",scores:{Microsoft:15}},{name:"Mentoring external safety researchers",weight:5,description:"*model reasoning*",description_html:"",scores:{Microsoft:20}}],category_score:{Microsoft:46}},{category:"Misuse prevention",weight:12,subcategories:[{name:"Safety case: process",weight:40,description:"*model reasoning*",description_html:"",scores:{Microsoft:30}},{name:"Safety case: accountability",weight:40,description:"*model reasoning*",description_html:"",scores:{Microsoft:10}},{name:"Removing dangerous capabilities",weight:10,description:"*model reasoning*",description_html:"",scores:{Microsoft:10}},{name:"Emergency protocol",weight:10,description:"*model reasoning*",description_html:"",scores:{Microsoft:40}}],category_score:{Microsoft:21}},{category:"Prep for extreme security",weight:12,subcategories:[{name:"Plan for SL5",weight:35,description:"*model reasoning*",description_html:"",scores:{Microsoft:30}},{name:"Red-team resilience",weight:25,description:"*model reasoning*",description_html:"",scores:{Microsoft:25}},{name:"Practices: isolated network",weight:5,description:"*model reasoning*",description_html:"",scores:{Microsoft:45}},{name:"Practices: secure developers' machines",weight:5,description:"*model reasoning*",description_html:"",scores:{Microsoft:45}},{name:"Practices: multiparty controls",weight:5,description:"*model reasoning*",description_html:"",scores:{Microsoft:45}},{name:"Practices: secure boot",weight:5,description:"*model reasoning*",description_html:"",scores:{Microsoft:45}},{name:"Track record",weight:20,description:"*model reasoning*",description_html:"",scores:{Microsoft:20}}],category_score:{Microsoft:30}},{category:"Risk info sharing",weight:8,subcategories:[{name:"Incident reporting",weight:40,description:"*model reasoning*",description_html:"",scores:{Microsoft:20}},{name:"Talk about extreme risks",weight:15,description:"*model reasoning*",description_html:"",scores:{Microsoft:50}},{name:"Describe worst-case outcome",weight:10,description:"*model reasoning*",description_html:"",scores:{Microsoft:5}},{name:"Don't publish some capabilities research",weight:35,description:"*model reasoning*",description_html:"",scores:{Microsoft:20}}],category_score:{Microsoft:23}},{category:"Planning",weight:6,subcategories:[{name:"Safety plan",weight:50,description:"*model reasoning*",description_html:"",scores:{Microsoft:20}},{name:"Plan for how to use AGI",weight:40,description:"*model reasoning*",description_html:"",scores:{Microsoft:40}},{name:"Prepare for a pivot",weight:10,description:"*model reasoning*",description_html:"",scores:{Microsoft:10}}],category_score:{Microsoft:27}}],Zf={Microsoft:27},em={categories:Jf,overall:Zf},tm=[{category:"Boosting safety research",weight:14,subcategories:[{name:"Publishing safety research",weight:75,reasoning:"The formula rewards DeepSeek-authored, extreme-risk-relevant safety papers (misalignment/control/dangerous-capability evals). I couldn’t loc ate such publications by DeepSeek for 2023–Apr 2025; prominent safety studies about DeepSeek are by third parties (academia/industry/government). Calculation: publications_per_year ≈ 0 → score = min(((0/20)^0.75)*100, 100) = 0. NIST+2METR’s Autonomy Evaluation Resources+2",reasoning_html:"",scores:{DeepSeek:0}},{name:"Deep access for external safety researchers",weight:20,reasoning:"Purpose: helpful-only & no-mitigations access and fine-tuning/RL. DeepSeek released open weights and licensed R1 under MIT; researchers can run no-mitigations variants and perform fine-tuning/RL. Because access is shared with everyone (not restricted to safety researchers), apply half cr edit on each 40% item: 0.5×40 + 0.5×40 = 40%. No evidence of a distinct early-access program → +0%. DeepSeek API Docs",reasoning_html:"",scores:{DeepSeek:40}},{name:"Mentoring external safety researchers",weight:5,reasoning:"I found no mentoring programs, co-authorships, or advisory initiatives focused on extreme-risk safety run by DeepSeek. NIST",reasoning_html:"",scores:{DeepSeek:0}}],category_score:{DeepSeek:8}},{category:"Misuse prevention",weight:12,subcategories:[{name:"Safety case: process (misuse prevention)",weight:40,reasoning:"No published misuse safety case showing deployment would be very unlikely to enable catastrophic misuse once models are dangerous by default. External testing shows ease of eliciting harmful content, which wei ghs against credit. WIRED+1",reasoning_html:"",scores:{DeepSeek:0}},{name:"Safety case: accountability (misuse prevention)",weight:40,reasoning:"*no entry in source*",reasoning_html:"",scores:{DeepSeek:null}},{name:"Removing dangerous capabilities",weight:10,reasoning:"*no entry in source*",reasoning_html:"",scores:{DeepSeek:null}},{name:"Emergency protocol",weight:10,reasoning:"No public emergency protocol to rapidly reduce misuse risk (tool s, thresholds, activation criteria). A public status page covers uptime/incident s, not misuse emergencies. status.deepseek.com",reasoning_html:"",scores:{DeepSeek:0}}],category_score:{DeepSeek:0}},{category:"Planning",weight:6,subcategories:[{name:"Safety plan",weight:50,reasoning:"No concrete plan for dangerous capabilities appearing soon that addresses internal scheming, API misuse, human power grabs, and theft under rushed conditions. NIST",reasoning_html:"",scores:{DeepSeek:0}},{name:"Plan for how to use AGI",weight:40,reasoning:"*no entry in source*",reasoning_html:"",scores:{DeepSeek:null}},{name:"Prepare for a pivot",weight:10,reasoning:"*no entry in source*",reasoning_html:"",scores:{DeepSeek:null}}],category_score:{DeepSeek:0}},{category:"Prep for extreme security",weight:12,subcategories:[{name:"Plan for SL5",weight:35,reasoning:"*no entry in source*",reasoning_html:"",scores:{DeepSeek:null}},{name:"Red-team resilience",weight:25,reasoning:"I saw no DeepSeek statements like “competent pentesters attempted X under realistic affordances and failed” with sufficient detail. Exter nal security write-ups highlight vulnerabilities, not resilience. Cisco Blogs+1",reasoning_html:"",scores:{DeepSeek:0}},{name:"Practices: isolated network",weight:5,reasoning:"*no entry in source*",reasoning_html:"",scores:{DeepSeek:null}},{name:"Practices: secure developers' machines",weight:5,reasoning:"*no entry in source*",reasoning_html:"",scores:{DeepSeek:null}},{name:"Practices: multiparty controls",weight:5,reasoning:"*no entry in source*",reasoning_html:"",scores:{DeepSeek:null}},{name:"Practices: secure boot",weight:5,reasoning:"*no entry in source*",reasoning_html:"",scores:{DeepSeek:null}},{name:"Track record",weight:20,reasoning:"*no entry in source*",reasoning_html:"",scores:{DeepSeek:null}}],category_score:{DeepSeek:0}},{category:"Risk assessment",weight:27,subcategories:[{name:"Evals: domains, quality, elicitation",weight:55,reasoning:"I find no DeepSeek-authored public evals covering the dangerous-capability domains called out (offensive cyber, CBRN, scheming, AI-R&D) or explicit elicitation protocols (helpful-only variants, no inferenc e-time mitigations, pass-n/best-of-n, transcript review). DeepSeek’s V3 and R1 technic al materials emphasize capability benchmarks (MMLU-Pro, GPQA, SWE-bench) rather than catastrophic-risk evals. External testing by Cisco and CAISI instead reports high jailbreak susceptibility, implying weak internal elicitation/Q A for danger domains. arXiv+2Cisco Blogs+2",reasoning_html:"",scores:{DeepSeek:5}},{name:"Evals: accountability",weight:25,reasoning:"The rubric asks for external evaluators with special access (inc l. no-mitigations) and the right to publish, or strong internal-eval accountability with public methods/results. CAISI (NIST) and METR published evaluations of DeepSeek models, but these relied on public/open weights or endpoints—there’s no evidence DeepSeek itself granted privileged access or structured an internal accountability process with a disinterested auditor. Transparency remains limited. NIST+2NIST+2",reasoning_html:"",scores:{DeepSeek:15}},{name:"Adversarial evaluation for alignment",weight:10,reasoning:"*no entry in source*",reasoning_html:"",scores:{DeepSeek:null}},{name:"Model organisms",weight:10,reasoning:"I found no DeepSeek work creating, studying, or preparing audits around model organisms of scheming (e.g., alignment-faking experiments). External analyses of censorship and refusal behaviors exist, but they are not DeepSeek-run model-organism programs nor alignment audits per the rubric. arXiv+1",reasoning_html:"",scores:{DeepSeek:0}}],category_score:{DeepSeek:7}},{category:"Risk info sharing",weight:8,subcategories:[{name:"Incident reporting",weight:40,reasoning:"*no entry in source*",reasoning_html:"",scores:{DeepSeek:null}},{name:"Talk about extreme risks",weight:15,reasoning:"I found no leadership communications acknowledging that misalignment risks may be hard to notice, capabilities can appear suddenly, and safety may be difficult—at the specificity level the rubric expect s. NIST",reasoning_html:"",scores:{DeepSeek:0}},{name:"Describe worst-case outcome",weight:10,reasoning:"No company-hosted statement of a plausible worst case with specific probabilities and clear definitions posted on DeepSeek’s site. NIST",reasoning_html:"",scores:{DeepSeek:0}},{name:"Don't publish some capabilities research",weight:35,reasoning:"DeepSeek widely publishes capability advances and open weights (e.g., R1 under MIT). I found no policy to withhold dangerous-path capabilities research; external analyses argue openness increased risk exposure. DeepSeek API Docs+1",reasoning_html:"",scores:{DeepSeek:0}}],category_score:{DeepSeek:0}},{category:"Scheming risk prevention",weight:21,subcategories:[{name:"Safety case: process",weight:25,reasoning:"No public safety case laying out how DeepSeek ensures and demonstrates small risks from subtle scheming during internal deployment (including control evals, publishable details, and risk-reduction/pausing triggers). External reports instead highlight jailbreak and harmful-content compliance. Cisco Blogs+1",reasoning_html:"",scores:{DeepSeek:0}},{name:"Safety case: accountability",weight:25,reasoning:"No evidence of a qualified, disinterested auditor publicly commenting on DeepSeek’s safety case plans/adherence for internal deployments. NIST",reasoning_html:"",scores:{DeepSeek:0}},{name:"Internal deployment protocol",weight:20,reasoning:"The rubric asks for implemented AI monitoring with thresholds/budgets and auditing of suspicious outputs for internal use. I found no DeepSeek-authored protocol. Public material focuses on product terms, not detailed internal monitoring. cdn.deepseek.com",reasoning_html:"",scores:{DeepSeek:0}},{name:"External deployment protocol",weight:10,reasoning:"Terms of Use prohibit dangerous purposes, but I don’t see a published flag-and-investigate pipeline, audit paths, or demonstrated controls for external settings. Cloud partners recommend their own guardrails (Azure Content Safety, Bedrock Guardrails, Vertex Model Armor), which are third-party mitigations rather than DeepSeek’s end-to-end protocol. Google Cloud+3cdn.deepseek.com+3Microsoft Azure+3",reasoning_html:"",scores:{DeepSeek:5}},{name:"Plan for if an AI is caught scheming",weight:10,reasoning:"No stated plan to publish findings, pause/switch to high-alert, tighten thresholds, or use incidents to improve monitoring. NIST",reasoning_html:"",scores:{DeepSeek:0}},{name:"Training: remove scheming capabilities",weight:3,reasoning:"No evidence DeepSeek filters/unlearns scheming-enabling knowledge by default (e.g., steganography/coordination topics) subject to a safety case. Existing evidence points to vulnerability to misuse/jailbreaks rather than targeted removal. Cisco Blogs+1",reasoning_html:"",scores:{DeepSeek:0}},{name:"Training: adversarial training",weight:3,reasoning:"*no entry in source*",reasoning_html:"",scores:{DeepSeek:null}},{name:"Training: safe architecture",weight:3,reasoning:"No public commitment to serial, interpretable bottlenecks or avoiding hidden/uninterpretable states for safety. Architecture work emphasizes performance/efficiency (MLA, MoE, multi-token prediction). arXiv",reasoning_html:"",scores:{DeepSeek:0}}],category_score:{DeepSeek:1}}],nm={DeepSeek:3},rm={note:"Converted from PDF; missing criteria retain None scores.",missing_criteria:["Adversarial evaluation for alignment","Incident reporting","Plan for SL5","Plan for how to use AGI","Practices: isolated network","Practices: multiparty controls","Practices: secure boot","Practices: secure developers' machines","Prepare for a pivot","Removing dangerous capabilities","Safety case: accountability (misuse prevention)","Track record","Training: adversarial training"],source_pdf:"OAISI Hackathon 2025 (6).pdf"},im={categories:tm,overall:nm,metadata:rm};function om(){const[s,c]=_.useState(null),[l,p]=_.useState(null),[d,m]=_.useState(null),v=Object.keys($n[0].subcategories[0].scores),A={OpenAI:$f,DeepMind:Hf,Anthropic:qf,Meta:{categories:Qf},xAI:Yf,Microsoft:em,DeepSeek:im},k=$n.map((O,$)=>({...O,subcategories:O.subcategories.map((Q,Z)=>{const ne={},ae={};return v.forEach(Ie=>{var Pe,ge,N;const ye=A[Ie],Me=(Pe=ye==null?void 0:ye.categories)==null?void 0:Pe[$],le=(ge=Me==null?void 0:Me.subcategories)==null?void 0:ge[Z];ne[Ie]=((N=le==null?void 0:le.scores)==null?void 0:N[Ie])??0;const he=(le==null?void 0:le.reasoning)||(le==null?void 0:le.description);he&&he!=="*model reasoning*"&&(ae[Ie]=he)}),{...Q,scores:ne,reasoning:ae}})})),b=(O,$)=>{let Q=0,Z=0;return $.forEach(ne=>{ne.subcategories.forEach(ae=>{const Ie=ae.scores[O]||0,ye=ne.weight/100*(ae.weight/100);Q+=Ie*ye,Z+=ye})}),Math.round(Q/Z)},I=O=>x.jsxs("div",{className:"labels-section",children:[x.jsx("h2",{className:"heatmap-title",style:{visibility:"hidden"},children:"Labels"}),x.jsxs("div",{className:"labels-container",children:[x.jsx("div",{className:"label-header"}),x.jsxs("div",{className:"label-row label-weighted",children:[x.jsx("div",{className:"category-label",children:"Weighted score"}),x.jsx("div",{className:"subcategory-label"})]}),O.map(($,Q)=>x.jsx(x.Fragment,{children:$.subcategories.map((Z,ne)=>x.jsxs("div",{className:"label-row",children:[ne===0?x.jsx("div",{className:"category-label category-label-group",style:{gridRow:`span ${$.subcategories.length}`},children:$.category}):null,x.jsx("div",{className:"subcategory-label",children:Z.name})]},`${Q}-${ne}`))}))]})]}),T=(O,$,Q=!1)=>x.jsxs("div",{className:"heatmap-section",children:[x.jsx("h2",{className:"heatmap-title",children:$}),x.jsxs("div",{className:"scorecard-container-scores",children:[v.map(Z=>x.jsx("div",{className:"company-header",children:x.jsx("img",{src:q[Z],alt:Z,className:"company-logo"})},Z)),v.map(Z=>{const ne=b(Z,O);return x.jsxs("div",{className:"score-cell weighted-score-cell",style:{backgroundColor:R(ne)},children:[ne,"%"]},Z)}),O.map((Z,ne)=>x.jsx(x.Fragment,{children:Z.subcategories.map((ae,Ie)=>x.jsx(x.Fragment,{children:v.map(ye=>{var ge;const Me=ae.scores[ye],le=`${ne}-${Ie}-${ye}`,he=Q&&((ge=ae.reasoning)==null?void 0:ge[ye]),Pe=!!he;return x.jsxs("div",{className:"score-cell",style:{backgroundColor:R(Me),cursor:Pe?"pointer":"default"},onMouseEnter:N=>{if(Pe){const K=N.currentTarget.getBoundingClientRect();m({key:le,reasoning:he,x:K.left+K.width/2,y:K.top})}},onMouseLeave:()=>Pe&&m(null),children:[Me,"%"]},ye)})}))}))]})]}),R=O=>O===0?"#f5cac3":O<=10?"#f5b5a8":O<=20?"#f29f8d":O<=30?"#e88971":O<=40?"#de7356":O<=50?"#c9986d":O<=60?"#b4a982":O<=70?"#9fb897":O<=80?"#8ac7ac":"#75d5c1",q={Anthropic:"/ai-news-verifier/logos/anthropic.svg",DeepMind:"/ai-news-verifier/logos/DeepMind_new_logo.svg",OpenAI:"/ai-news-verifier/logos/openai.svg",Meta:"/ai-news-verifier/logos/meta.svg",xAI:"/ai-news-verifier/logos/XAI_Logo.svg",Microsoft:"/ai-news-verifier/logos/microsoft.svg",DeepSeek:"/ai-news-verifier/logos/deepseek-logo-icon.svg"},j=(()=>{const O=[];return $n.forEach(($,Q)=>{$.subcategories.forEach((Z,ne)=>{v.forEach(ae=>{const Ie=Z.scores[ae],ye=k[Q].subcategories[ne].scores[ae];O.push({human:Ie,ai:ye,company:ae,subcategory:Z.name})})})}),O})(),H=(()=>{const O=[];return v.forEach($=>{var ae;const Q=b($,$n),Z=A[$],ne=((ae=Z==null?void 0:Z.overall)==null?void 0:ae[$])??b($,k);O.push({human:Q,ai:ne,company:$})}),O})(),te=O=>{const $=O.length,Q=O.reduce((le,he)=>le+he.human,0),Z=O.reduce((le,he)=>le+he.ai,0),ne=O.reduce((le,he)=>le+he.human*he.ai,0),ae=O.reduce((le,he)=>le+he.human*he.human,0),Ie=O.reduce((le,he)=>le+he.ai*he.ai,0),ye=$*ne-Q*Z,Me=Math.sqrt(($*ae-Q*Q)*($*Ie-Z*Z));return ye/Me},V=te(j),se=te(H);return x.jsxs("div",{className:"scorecard-page",children:[x.jsxs("div",{className:"heatmaps-wrapper",children:[I($n),T($n,"Human Researchers",!1),x.jsx("div",{children:T(k,"AI Analysis",!0)})]}),d&&x.jsx("div",{className:"reasoning-tooltip",style:{position:"fixed",left:`${d.x}px`,top:`${d.y-10}px`,transform:"translate(-50%, -100%)"},children:x.jsx("div",{className:"reasoning-content",children:d.reasoning})}),x.jsxs("div",{className:"scatterplot-section",children:[x.jsx("h2",{className:"scatterplot-title",children:"Human vs AI Scores Comparison"}),x.jsxs("div",{className:"scatterplot-wrapper",children:[x.jsxs("div",{className:"scatterplot-container",children:[x.jsxs("svg",{className:"scatterplot",viewBox:"0 0 600 500",children:[x.jsx("line",{x1:"60",y1:"440",x2:"560",y2:"440",stroke:"#666",strokeWidth:"2"}),x.jsx("line",{x1:"60",y1:"40",x2:"60",y2:"440",stroke:"#666",strokeWidth:"2"}),[0,25,50,75,100].map(O=>{const $=60+O/100*500,Q=440-O/100*400;return x.jsxs("g",{children:[x.jsx("line",{x1:$,y1:"440",x2:$,y2:"435",stroke:"#666",strokeWidth:"1"}),x.jsx("line",{x1:"60",y1:Q,x2:"65",y2:Q,stroke:"#666",strokeWidth:"1"}),x.jsx("line",{x1:$,y1:"440",x2:$,y2:"40",stroke:"#e0e0e0",strokeWidth:"0.5",opacity:"0.5"}),x.jsx("line",{x1:"60",y1:Q,x2:"560",y2:Q,stroke:"#e0e0e0",strokeWidth:"0.5",opacity:"0.5"}),x.jsx("text",{x:$,y:"455",fontSize:"12",fill:"#666",textAnchor:"middle",children:O}),x.jsx("text",{x:"45",y:Q+4,fontSize:"12",fill:"#666",textAnchor:"end",children:O})]},O)}),x.jsx("line",{x1:"60",y1:"440",x2:"560",y2:"40",stroke:"#999",strokeWidth:"1",strokeDasharray:"5,5",opacity:"0.5"}),j.map((O,$)=>{const Q=60+O.human/100*500,Z=440-O.ai/100*400;return x.jsx("circle",{cx:Q,cy:Z,r:"4",fill:"#646cff",opacity:s===$?"1":"0.6",stroke:s===$?"#333":"none",strokeWidth:"2",style:{cursor:"pointer"},onMouseEnter:()=>c($),onMouseLeave:()=>c(null)},$)}),x.jsx("text",{x:"310",y:"485",fontSize:"14",fill:"#333",textAnchor:"middle",fontWeight:"600",children:"Human Researcher Score (%)"}),x.jsx("text",{x:"20",y:"240",fontSize:"14",fill:"#333",textAnchor:"middle",fontWeight:"600",transform:"rotate(-90 20 240)",children:"AI Analysis Score (%)"})]}),s!==null&&x.jsxs("div",{className:"scatter-tooltip",children:[x.jsx("div",{className:"tooltip-company",children:j[s].company}),x.jsx("div",{className:"tooltip-subcategory",children:j[s].subcategory}),x.jsxs("div",{className:"tooltip-scores",children:[x.jsxs("div",{children:["Human: ",x.jsxs("strong",{children:[j[s].human,"%"]})]}),x.jsxs("div",{children:["AI: ",x.jsxs("strong",{children:[j[s].ai,"%"]})]})]})]})]}),x.jsxs("div",{className:"correlation-display",children:[x.jsx("div",{className:"correlation-label",children:"Correlation"}),x.jsx("div",{className:"correlation-value",children:V.toFixed(3)})]})]})]}),x.jsxs("div",{className:"scatterplot-section",children:[x.jsx("h2",{className:"scatterplot-title",children:"Overall Scores Comparison"}),x.jsxs("div",{className:"scatterplot-wrapper",children:[x.jsxs("div",{className:"scatterplot-container",children:[x.jsxs("svg",{className:"scatterplot",viewBox:"0 0 600 500",children:[x.jsx("line",{x1:"60",y1:"440",x2:"560",y2:"440",stroke:"#666",strokeWidth:"2"}),x.jsx("line",{x1:"60",y1:"40",x2:"60",y2:"440",stroke:"#666",strokeWidth:"2"}),[0,25,50,75,100].map(O=>{const $=60+O/100*500,Q=440-O/100*400;return x.jsxs("g",{children:[x.jsx("line",{x1:$,y1:"440",x2:$,y2:"435",stroke:"#666",strokeWidth:"1"}),x.jsx("line",{x1:"60",y1:Q,x2:"65",y2:Q,stroke:"#666",strokeWidth:"1"}),x.jsx("line",{x1:$,y1:"440",x2:$,y2:"40",stroke:"#e0e0e0",strokeWidth:"0.5",opacity:"0.5"}),x.jsx("line",{x1:"60",y1:Q,x2:"560",y2:Q,stroke:"#e0e0e0",strokeWidth:"0.5",opacity:"0.5"}),x.jsx("text",{x:$,y:"455",fontSize:"12",fill:"#666",textAnchor:"middle",children:O}),x.jsx("text",{x:"45",y:Q+4,fontSize:"12",fill:"#666",textAnchor:"end",children:O})]},O)}),x.jsx("line",{x1:"60",y1:"440",x2:"560",y2:"40",stroke:"#999",strokeWidth:"1",strokeDasharray:"5,5",opacity:"0.5"}),H.map((O,$)=>{const Q=60+O.human/100*500,Z=440-O.ai/100*400;return x.jsx("circle",{cx:Q,cy:Z,r:"6",fill:"#646cff",opacity:l===$?"1":"0.6",stroke:l===$?"#333":"none",strokeWidth:"2",style:{cursor:"pointer"},onMouseEnter:()=>p($),onMouseLeave:()=>p(null)},$)}),x.jsx("text",{x:"310",y:"485",fontSize:"14",fill:"#333",textAnchor:"middle",fontWeight:"600",children:"Human Researcher Overall Score (%)"}),x.jsx("text",{x:"20",y:"240",fontSize:"14",fill:"#333",textAnchor:"middle",fontWeight:"600",transform:"rotate(-90 20 240)",children:"AI Analysis Overall Score (%)"})]}),l!==null&&x.jsxs("div",{className:"scatter-tooltip",children:[x.jsx("div",{className:"tooltip-company",children:H[l].company}),x.jsxs("div",{className:"tooltip-scores",children:[x.jsxs("div",{children:["Human: ",x.jsxs("strong",{children:[H[l].human,"%"]})]}),x.jsxs("div",{children:["AI: ",x.jsxs("strong",{children:[H[l].ai,"%"]})]})]})]})]}),x.jsxs("div",{className:"correlation-display",children:[x.jsx("div",{className:"correlation-label",children:"Correlation"}),x.jsx("div",{className:"correlation-value",children:se.toFixed(3)})]})]})]})]})}function sm(){const s=It();return x.jsxs("nav",{className:"navigation",children:[x.jsx(mn,{to:"/scorecard",className:`nav-link ${s.pathname==="/scorecard"?"active":""}`,children:"Scorecard"}),x.jsx(mn,{to:"/blog",className:`nav-link ${s.pathname.startsWith("/blog")||s.pathname.startsWith("/article")?"active":""}`,children:"Blog"})]})}const Un=[{value:"gpt-3.5-turbo",label:"GPT-3.5"},{value:"gpt-5",label:"GPT-5"}];function am({selectedModel:s,setSelectedModel:c}){const l=It(),p=l.pathname==="/blog"||l.pathname.startsWith("/article"),d=k=>{const b=parseInt(k.target.value);c(Un[b].value)},m=Un.findIndex(k=>k.value===s),v=Un.map(k=>{const b=Lu(k.value),I=b.reduce((T,R)=>T+(R.score||0),0);return{model:k.label,average:b.length>0?I/b.length:0}}),A=Math.max(...v.map(k=>k.average),100);return x.jsx("div",{className:"model-selector-fixed",children:x.jsxs("div",{className:"model-selector-content",children:[x.jsx("img",{src:"/ai-news-verifier/AI-lab-watchdog.png",alt:"AI Lab Watchdog",className:"header-logo"}),x.jsx(sm,{}),x.jsxs("div",{className:"left-section",style:{visibility:p?"visible":"hidden"},children:[x.jsx("span",{className:"model-label",children:"Model:"}),x.jsxs("div",{className:"slider-container",children:[x.jsx("span",{className:"model-option",children:Un[0].label}),x.jsx("input",{type:"range",min:"0",max:"1",step:"1",value:m,onChange:d,className:"model-slider"}),x.jsx("span",{className:"model-option",children:Un[1].label})]}),x.jsx("div",{className:"current-model",children:Un[m].label})]}),x.jsx("div",{className:"graph-container",style:{visibility:p?"visible":"hidden"},children:x.jsxs("svg",{className:"line-graph",viewBox:"0 0 300 80",preserveAspectRatio:"xMidYMid meet",children:[x.jsx("line",{x1:"30",y1:"10",x2:"30",y2:"55",stroke:"#ccc",strokeWidth:"0.5"}),x.jsx("line",{x1:"30",y1:"55",x2:"270",y2:"55",stroke:"#ccc",strokeWidth:"0.5"}),x.jsx("text",{x:"25",y:"13",fontSize:"7",fill:"currentColor",textAnchor:"end",children:A.toFixed(1)}),x.jsx("text",{x:"25",y:"56",fontSize:"7",fill:"currentColor",textAnchor:"end",children:"0"}),x.jsx("polyline",{points:v.map((k,b)=>{const I=30+b*120,T=55-k.average/(A||1)*45;return`${I},${T}`}).join(" "),fill:"none",stroke:"#646cff",strokeWidth:"2"}),v.map((k,b)=>{const I=30+b*120,T=55-k.average/(A||1)*45,R=b===m;return x.jsxs("g",{children:[R&&x.jsx("circle",{cx:I,cy:T,r:"8",fill:k.average===0?"#4caf50":"#646cff",opacity:"0.3"}),x.jsx("circle",{cx:I,cy:T,r:R?"5":"2.5",fill:k.average===0?"#4caf50":"#646cff",stroke:"white",strokeWidth:R?"2":"1"}),x.jsx("text",{x:I,y:"68",fontSize:"8",fill:"currentColor",textAnchor:"middle",fontWeight:R?"bold":"normal",children:k.model}),x.jsx("text",{x:I,y:T-6,fontSize:"8",fill:"currentColor",textAnchor:"middle",fontWeight:"bold",children:k.average.toFixed(1)})]},b)})]})})]})})}function lm(){const[s,c]=_.useState("gpt-3.5-turbo");return x.jsxs(tf,{basename:"/ai-news-verifier",children:[x.jsx(am,{selectedModel:s,setSelectedModel:c}),x.jsxs(Dh,{children:[x.jsx(Rr,{path:"/",element:x.jsx(Ph,{to:"/blog",replace:!0})}),x.jsx(Rr,{path:"/blog",element:x.jsx(Ff,{selectedModel:s})}),x.jsx(Rr,{path:"/article/:id",element:x.jsx(jf,{selectedModel:s})}),x.jsx(Rr,{path:"/scorecard",element:x.jsx(om,{})})]})]})}Bp.createRoot(document.getElementById("root")).render(x.jsx(_.StrictMode,{children:x.jsx(lm,{})}));
